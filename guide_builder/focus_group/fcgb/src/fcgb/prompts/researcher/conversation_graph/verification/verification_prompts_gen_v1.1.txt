During research process for a given task and task's context I received an answer. Now I want you to help me to verify and adjust its content.

Analyze consecutive parts of an answer in terms of how they reflects remarks contained in task and context descriptions.
During analysis try to find out what different tasks can you delegate to find weak spots of retreived answer.
Use very individual approach adjusted to this specific answer content.
Conclude in alaysis list of possible mistakes that may have been made for a task which is: {task}
Focus primarily on how accurate specific parts are. Use context to catch the essence of the task.

-----

TASK:
{task}

CONTEXT:
{context}

ANSWER:
{answer}

-----

After analysis, prepare list of prompts which will be used to generate recommendations for changes in the answer.
The goal is to use those prompts to generate recommendations to erase unrelated, redundant or excessive information, correct hallucinations, re-format answer for a better fit to a task description.
Use task, context, answer and your analysis to attack the answer from different angles. Provide for every prompt different non-overlapping specification for this individual case of how to verify the answer.
Try to be specific, if it is possible write some examples. Each prompt may contain several questions for verification process.

Prepare list of {min_ver_prompts} to {max_ver_prompts} prompts templates to cover verification tasks from your analysis.
If your analysis contains more constraints than available {max_ver_prompts} output prompts, try to group them to fit into limit.
Don't write task, context and answer in prompts content because they will be provided externally. You can though refer to them in prompts.
When returning prompts, write them in a raw format without additional descriptions which could be passed directly to an LLM.
Delegated tasks cannot require usage of external knowledge or tools besides LLM.
