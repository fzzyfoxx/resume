{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4ae396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"focus_group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e927141",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.chatbots.chatbot import BaseChatBot\n",
    "from typing import Dict, Any, List, Annotated\n",
    "from pydantic import BaseModel\n",
    "from langgraph.constants import Send\n",
    "from operator import add\n",
    "from fcgb.types.research import SimpleTaskModel\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "#from fcgb.chatbots.selfconv import SimpleTaskDistributionChatBot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2c3eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleTaskDistributionChatBot(BaseChatBot):\n",
    "    \"\"\"\n",
    "    A chatbot that distributes tasks for a single LLM answer.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "            self, \n",
    "            llm,\n",
    "            initial_messages_spec,\n",
    "            internal_messages_spec,\n",
    "            memory,\n",
    "            global_inputs={},\n",
    "            init_values={},\n",
    "            prompt_manager_spec = {}\n",
    "        ):\n",
    "\n",
    "        super().__init__(\n",
    "            llm=llm,\n",
    "            initial_messages_spec=initial_messages_spec,\n",
    "            internal_messages_spec=internal_messages_spec,\n",
    "            memory=memory,\n",
    "            init_values=init_values,\n",
    "            prompt_manager_spec=prompt_manager_spec,\n",
    "            global_inputs=global_inputs,\n",
    "            compile=False\n",
    "            )\n",
    "\n",
    "        self.compile_graph()\n",
    "\n",
    "    def _set_state_class(self):\n",
    "\n",
    "        task_list_model = self.internal_messages_spec['task_list']['answer_format']\n",
    "        task_answer_model = self.internal_messages_spec['task']['answer_format']\n",
    "        answer_model = self.internal_messages_spec['answer']['answer_format']\n",
    "\n",
    "        class VerificationState(BaseModel):\n",
    "            parent_thread_id: str \n",
    "            template_inputs: Dict[str, str]\n",
    "            task_list: task_list_model | None # type: ignore\n",
    "            simple_task_response: Annotated[List[task_answer_model], add] # type: ignore\n",
    "            verified_answer: answer_model | None # type: ignore\n",
    "\n",
    "        self.state_class = VerificationState\n",
    "\n",
    "    def _set_tasks_gen_func(self):\n",
    "        \"\"\"\n",
    "        Set the function that generates the verification tasks.\n",
    "        \"\"\"\n",
    "        \n",
    "        def tasks_gen_func(state: self.state_class) -> Dict: # type: ignore\n",
    "            \n",
    "            task_list = self._invoke_internal_msg(name='task_list', template_inputs=state.template_inputs)\n",
    "\n",
    "            return {'task_list': task_list}\n",
    "        \n",
    "        return tasks_gen_func\n",
    "        \n",
    "    def _set_tasks_router_func(self):\n",
    "        \"\"\"\n",
    "        Set the function that distributes tasks along nodes.\n",
    "        \"\"\"\n",
    "        \n",
    "        def tasks_router_func(state: self.state_class) -> SimpleTaskModel: # type: ignore\n",
    "\n",
    "            return [Send('task_node',\n",
    "                        {\n",
    "                        'template_inputs': state.template_inputs,\n",
    "                        'task': task,\n",
    "                        'simple_task_response': None\n",
    "                        }) for task in state.task_list.prompts]\n",
    "        \n",
    "        return tasks_router_func\n",
    "    \n",
    "    def _set_task_node_func(self):\n",
    "        \"\"\"\n",
    "        Set the function that solve the tasks.\n",
    "        \"\"\"\n",
    "        \n",
    "        def task_node_func(state: SimpleTaskModel) -> Dict:\n",
    "\n",
    "            system = self.internal_prompts['task']['prompt'].format(**state['template_inputs'], **self.global_inputs)\n",
    "            prompt = state['task'].format(**state['template_inputs'], **self.global_inputs)\n",
    "\n",
    "            messages = [SystemMessage(content=system), HumanMessage(content=prompt)]\n",
    "            task_response = self.llm.with_structured_output(self.internal_prompts['task']['answer_format']).invoke(messages)\n",
    "\n",
    "            return {'simple_task_response': [task_response]}\n",
    "        \n",
    "        return task_node_func\n",
    "    \n",
    "    def _set_output_node_func(self):\n",
    "\n",
    "        def output_node_func(state: self.state_class) -> Dict: # type: ignore\n",
    "\n",
    "            task_response = '\\n-----\\n'.join([f'Job {i+1}:\\n'+resp.recommendations for i, resp in enumerate(state.simple_task_response)])\n",
    "\n",
    "            output = self._invoke_internal_msg(name='answer', template_inputs=state.template_inputs | {'task_response': task_response})\n",
    "\n",
    "            return {'verified_answer': output}\n",
    "        \n",
    "        return output_node_func\n",
    "    \n",
    "    def _compile_graph(self):\n",
    "\n",
    "        task_gen_func = self._set_tasks_gen_func()\n",
    "        tasks_router_func = self._set_tasks_router_func()\n",
    "        task_node_func = self._set_task_node_func()\n",
    "        output_node_func = self._set_output_node_func()\n",
    "\n",
    "        workflow = StateGraph(self.state_class)\n",
    "        workflow.add_node('task_gen', task_gen_func)\n",
    "        workflow.add_node('task_node', task_node_func)\n",
    "        workflow.add_node('output_node', output_node_func)\n",
    "\n",
    "        workflow.add_edge(START, 'task_gen')\n",
    "        workflow.add_conditional_edges('task_gen', tasks_router_func, ['task_node'])\n",
    "        workflow.add_edge('task_node', 'output_node')\n",
    "        workflow.add_edge('output_node', END)\n",
    "\n",
    "        self.graph = workflow.compile(\n",
    "            checkpointer=self.memory,\n",
    "        )\n",
    "\n",
    "    def run(self, template_inputs: Dict, thread_id: str, parent_thread_id: str):\n",
    "\n",
    "        self.init_thread(thread_id=thread_id, template_inputs=template_inputs)\n",
    "\n",
    "        config = self._get_config(thread_id)\n",
    "\n",
    "        return self.graph.invoke({'parent_thread_id': parent_thread_id, 'template_inputs': template_inputs}, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a3d84b",
   "metadata": {},
   "source": [
    "## fake llm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2c0a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_research_inputs = {\n",
    "    'template_inputs': {\n",
    "        'task': 'List all variants of Chain-of-Thought (CoT) prompting techniques.',\n",
    "        'context': 'CoT prompting techniques list is necessary to plan a chapter about CoT prompting. It is dedicated to potential users of LLMs who want to learn how to efficiently use LLMs.',\n",
    "    },\n",
    "    'ssc_thread_id': 'test_2/ssc1',\n",
    "    'parent_thread_id': 'test_2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72021fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.chatbots.specbots import SelfConvForStrategySpecBot, StrategizedSelfResearchSpecBot\n",
    "from fcgb.fake_models import FakeLLM\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "fake_llm = FakeLLM()\n",
    "\n",
    "memory = MemorySaver()\n",
    "convbot = SelfConvForStrategySpecBot(llm=fake_llm, memory=memory)\n",
    "strategybot = StrategizedSelfResearchSpecBot(llm=fake_llm, self_conv_bot=convbot, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d48e9dea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'template_inputs': {'task': 'List all variants of Chain-of-Thought (CoT) prompting techniques.',\n",
       "  'context': 'CoT prompting techniques list is necessary to plan a chapter about CoT prompting. It is dedicated to potential users of LLMs who want to learn how to efficiently use LLMs.'},\n",
       " 'ssc_thread_id': 'test_2/ssc1',\n",
       " 'parent_thread_id': 'test_2',\n",
       " 'ssc_summary': SimpleAnswerModel(answer='Fake string srxrs'),\n",
       " 'strategies': StrategyTaskModel(strategies=[{'strategy_description': 'Fake string vywvv', 'paraphrased_task': 'Fake string drije', 'paraphrased_context': 'Fake string pnuhd'}, {'strategy_description': 'Fake string bdwql', 'paraphrased_task': 'Fake string aaouo', 'paraphrased_context': 'Fake string fijkg'}, {'strategy_description': 'Fake string upjna', 'paraphrased_task': 'Fake string ibxnn', 'paraphrased_context': 'Fake string jwxsu'}, {'strategy_description': 'Fake string belfk', 'paraphrased_task': 'Fake string faehz', 'paraphrased_context': 'Fake string dqrea'}]),\n",
       " 'sc_thread_id': ['test_2/ssc1/self_conv0',\n",
       "  'test_2/ssc1/self_conv1',\n",
       "  'test_2/ssc1/self_conv2',\n",
       "  'test_2/ssc1/self_conv3'],\n",
       " 'sc_summary': ['Fake string komfq',\n",
       "  'Fake string wfynb',\n",
       "  'Fake string rtiza',\n",
       "  'Fake string omqhb']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_output = strategybot.run(**self_research_inputs)\n",
    "research_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07af7f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_inputs ={\n",
    "    'template_inputs': self_research_inputs['template_inputs'] | {'answer': research_output['ssc_summary'].answer},\n",
    "    'thread_id': self_research_inputs['ssc_thread_id'] + '/ver',\n",
    "    'parent_thread_id': self_research_inputs['ssc_thread_id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c62b6e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.cfg.chat_inputs_spec import ResearchVerificationConfig\n",
    "\n",
    "verificationbot = SimpleTaskDistributionChatBot(\n",
    "    llm=fake_llm,\n",
    "    initial_messages_spec=ResearchVerificationConfig.initial_messages_spec,\n",
    "    internal_messages_spec=ResearchVerificationConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    global_inputs=ResearchVerificationConfig.global_inputs,\n",
    "    init_values=ResearchVerificationConfig.init_values,\n",
    "    prompt_manager_spec=ResearchVerificationConfig.prompt_manager_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7377ce1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parent_thread_id': 'test_2/ssc1',\n",
       " 'template_inputs': {'task': 'List all variants of Chain-of-Thought (CoT) prompting techniques.',\n",
       "  'context': 'CoT prompting techniques list is necessary to plan a chapter about CoT prompting. It is dedicated to potential users of LLMs who want to learn how to efficiently use LLMs.',\n",
       "  'answer': 'Fake string srxrs'},\n",
       " 'task_list': PromptTemplatesListModel(analysis='Fake string ukgjw', prompts=['Fake string klyze', 'Fake string jlaxq', 'Fake string janjk']),\n",
       " 'simple_task_response': [SingleVerificationModel(analysis='Fake string dvqxz', recommendations='Fake string cvqeq'),\n",
       "  SingleVerificationModel(analysis='Fake string apynn', recommendations='Fake string nuqma'),\n",
       "  SingleVerificationModel(analysis='Fake string xeudp', recommendations='Fake string suvmg')],\n",
       " 'verified_answer': SimpleAnswerModel(answer='Fake string vzojy')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification_output = verificationbot.run(**verification_inputs)\n",
    "verification_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bee1c5",
   "metadata": {},
   "source": [
    "## real llm test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04b6c082",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.cfg.precompiled import get_checkpointer, get_llm\n",
    "\n",
    "memory = get_checkpointer(checkpointer_mode='mongodb', mode='test')\n",
    "llm = get_llm(llm_model='google')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ade27e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.chatbots.specbots import SelfConvForStrategySpecBot, StrategizedSelfResearchSpecBot\n",
    "from fcgb.cfg.chat_inputs_spec import ResearchVerificationConfig\n",
    "\n",
    "convbot = SelfConvForStrategySpecBot(llm=llm, memory=memory)\n",
    "strategybot = StrategizedSelfResearchSpecBot(llm=llm, self_conv_bot=convbot, memory=memory)\n",
    "verificationbot = SimpleTaskDistributionChatBot(\n",
    "    llm=llm,\n",
    "    initial_messages_spec=ResearchVerificationConfig.initial_messages_spec,\n",
    "    internal_messages_spec=ResearchVerificationConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    global_inputs=ResearchVerificationConfig.global_inputs,\n",
    "    init_values=ResearchVerificationConfig.init_values,\n",
    "    prompt_manager_spec=ResearchVerificationConfig.prompt_manager_spec\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b72db1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"from fcgb.cfg.precompiled import get_db_client\n",
    "\n",
    "db = get_db_client(db_engine='mongodb', mode='test')\n",
    "\n",
    "db['checkpoints_writes'].delete_many({'thread_id': 'partial/research/cot/ssc1'})\n",
    "db['checkpoints'].delete_many({'thread_id': 'partial/research/cot/ssc1'})\n",
    "\n",
    "strategybot.get_state('partial/research/cot/ssc1')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9fac4356",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_research_inputs = {\n",
    "    'template_inputs': {\n",
    "        'task': 'List all variants of Chain-of-Thought (CoT) prompting techniques.',\n",
    "        'context': 'CoT prompting techniques list is necessary to plan a chapter about CoT prompting. List should be very comprehensive, be sure to include all known variants of CoT prompting techniques. Be aware to not include fine-tuning methods, as they are not related to prompting.',\n",
    "    },\n",
    "    'ssc_thread_id': 'partial/research/cot/ssc7',\n",
    "    'parent_thread_id': 'partial/research/cot'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19bac65a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'template_inputs': {'task': 'List all variants of Chain-of-Thought (CoT) prompting techniques.',\n",
       "  'context': 'CoT prompting techniques list is necessary to plan a chapter about CoT prompting. List should be very comprehensive, be sure to include all known variants of CoT prompting techniques.'},\n",
       " 'ssc_thread_id': 'partial/research/cot/ssc7',\n",
       " 'parent_thread_id': 'partial/research/cot',\n",
       " 'ssc_summary': SimpleAnswerModel(answer='The variants of Chain-of-Thought (CoT) prompting techniques are:\\n\\n*   Standard CoT\\n*   Zero-shot CoT\\n*   Self-Consistency\\n*   Finetuned CoT\\n*   Least-to-Most prompting\\n*   Automatic Prompt Optimization (APO)\\n*   CoT with Verification\\n*   Graph CoT\\n*   Tree-of-Thoughts (ToT)\\n*   CoT combined with Knowledge Retrieval\\n*   Distillation for CoT\\n*   Complexity-Based Prompting\\n*   Task-Specific CoT\\n*   Self-Refinement\\n*   CoT with External Verification\\n*   Constraint-Based CoT\\n*   Graph-of-Thoughts (GoT)\\n*   Program-of-Thoughts (PoT)\\n*   Chain-of-Hindsight (CoH)\\n*   CoT-Guided ToT/GoT\\n*   CoT for Branch Selection in ToT\\n*   CoT for Node Generation in GoT'),\n",
       " 'strategies': StrategyTaskModel(strategies=[{'strategy_description': 'Comprehensive Recall: Focus on recalling and listing all known CoT variants. Prioritize breadth of coverage and aim for an exhaustive list.', 'paraphrased_task': 'Could you provide a detailed list of all Chain-of-Thought (CoT) prompting techniques?', 'paraphrased_context': \"I'm writing a chapter about Chain-of-Thought (CoT) prompting and need a complete list of all its variations.\"}, {'strategy_description': 'Taxonomy and Classification: Focus on classifying CoT techniques into different categories or types. Aim to provide a structured overview.', 'paraphrased_task': 'What are the different methods and approaches within Chain-of-Thought (CoT) prompting?', 'paraphrased_context': 'I am trying to understand the different ways Chain-of-Thought prompting can be applied.'}, {'strategy_description': 'Exploration of Novel Techniques: Focus on uncovering less common or experimental CoT variants. Prioritize depth of exploration and aim to identify cutting-edge techniques.', 'paraphrased_task': 'Can you list all Chain-of-Thought (CoT) prompting methods, including less common or experimental ones?', 'paraphrased_context': \"I'm researching Chain-of-Thought prompting for a specific application and need to know all the available options.\"}]),\n",
       " 'sc_thread_id': ['partial/research/cot/ssc7/self_conv0',\n",
       "  'partial/research/cot/ssc7/self_conv1',\n",
       "  'partial/research/cot/ssc7/self_conv2'],\n",
       " 'sc_summary': ['*   Standard CoT\\n*   Zero-shot CoT\\n*   Self-Consistency\\n*   Finetuned CoT\\n*   Least-to-Most prompting\\n*   Automatic Prompt Optimization (APO)\\n*   CoT with Verification\\n*   Graph CoT\\n*   Tree-of-Thoughts (ToT)\\n*   CoT combined with Knowledge Retrieval\\n*   Distillation for CoT\\n*   Complexity-Based Prompting\\n*   Task-Specific CoT\\n*   Self-Refinement\\n*   CoT with External Verification\\n*   Constraint-Based CoT',\n",
       "  'The variants of Chain-of-Thought (CoT) prompting techniques are:\\n\\n- Standard CoT\\n- Self-Consistency\\n- Zero-shot CoT\\n- Least-to-Most prompting\\n- Tree-of-Thoughts (ToT) ',\n",
       "  \"Here's a comprehensive list of Chain-of-Thought (CoT) prompting techniques:\\n\\n*   Standard Chain-of-Thought (CoT)\\n*   Self-Consistency Decoding\\n*   Graph-of-Thoughts (GoT)\\n*   Tree-of-Thoughts (ToT)\\n*   Program-of-Thoughts (PoT)\\n*   Chain-of-Hindsight (CoH)\\n*   CoT-Guided ToT/GoT\\n*   CoT for Branch Selection in ToT\\n*   CoT for Node Generation in GoT\"]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_output = strategybot.run(**self_research_inputs)\n",
    "research_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835c799b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'template_inputs': {'task': 'List all variants of Chain-of-Thought (CoT) prompting techniques.',\n",
       "  'context': 'CoT prompting techniques list is necessary to plan a chapter about CoT prompting. List should be very comprehensive, be sure to include all known variants of CoT prompting techniques.'},\n",
       " 'ssc_thread_id': 'partial/research/cot/ssc7',\n",
       " 'parent_thread_id': 'partial/research/cot',\n",
       " 'ssc_summary': SimpleAnswerModel(answer='The variants of Chain-of-Thought (CoT) prompting techniques are:\\n\\n*   Standard CoT\\n*   Zero-shot CoT\\n*   Self-Consistency\\n*   Finetuned CoT\\n*   Least-to-Most prompting\\n*   Automatic Prompt Optimization (APO)\\n*   CoT with Verification\\n*   Graph CoT\\n*   Tree-of-Thoughts (ToT)\\n*   CoT combined with Knowledge Retrieval\\n*   Distillation for CoT\\n*   Complexity-Based Prompting\\n*   Task-Specific CoT\\n*   Self-Refinement\\n*   CoT with External Verification\\n*   Constraint-Based CoT\\n*   Graph-of-Thoughts (GoT)\\n*   Program-of-Thoughts (PoT)\\n*   Chain-of-Hindsight (CoH)\\n*   CoT-Guided ToT/GoT\\n*   CoT for Branch Selection in ToT\\n*   CoT for Node Generation in GoT'),\n",
       " 'strategies': StrategyTaskModel(strategies=[{'strategy_description': 'Comprehensive Recall: Focus on recalling and listing all known CoT variants. Prioritize breadth of coverage and aim for an exhaustive list.', 'paraphrased_task': 'Could you provide a detailed list of all Chain-of-Thought (CoT) prompting techniques?', 'paraphrased_context': \"I'm writing a chapter about Chain-of-Thought (CoT) prompting and need a complete list of all its variations.\"}, {'strategy_description': 'Taxonomy and Classification: Focus on classifying CoT techniques into different categories or types. Aim to provide a structured overview.', 'paraphrased_task': 'What are the different methods and approaches within Chain-of-Thought (CoT) prompting?', 'paraphrased_context': 'I am trying to understand the different ways Chain-of-Thought prompting can be applied.'}, {'strategy_description': 'Exploration of Novel Techniques: Focus on uncovering less common or experimental CoT variants. Prioritize depth of exploration and aim to identify cutting-edge techniques.', 'paraphrased_task': 'Can you list all Chain-of-Thought (CoT) prompting methods, including less common or experimental ones?', 'paraphrased_context': \"I'm researching Chain-of-Thought prompting for a specific application and need to know all the available options.\"}]),\n",
       " 'sc_thread_id': ['partial/research/cot/ssc7/self_conv0',\n",
       "  'partial/research/cot/ssc7/self_conv1',\n",
       "  'partial/research/cot/ssc7/self_conv2'],\n",
       " 'sc_summary': ['*   Standard CoT\\n*   Zero-shot CoT\\n*   Self-Consistency\\n*   Finetuned CoT\\n*   Least-to-Most prompting\\n*   Automatic Prompt Optimization (APO)\\n*   CoT with Verification\\n*   Graph CoT\\n*   Tree-of-Thoughts (ToT)\\n*   CoT combined with Knowledge Retrieval\\n*   Distillation for CoT\\n*   Complexity-Based Prompting\\n*   Task-Specific CoT\\n*   Self-Refinement\\n*   CoT with External Verification\\n*   Constraint-Based CoT',\n",
       "  'The variants of Chain-of-Thought (CoT) prompting techniques are:\\n\\n- Standard CoT\\n- Self-Consistency\\n- Zero-shot CoT\\n- Least-to-Most prompting\\n- Tree-of-Thoughts (ToT) ',\n",
       "  \"Here's a comprehensive list of Chain-of-Thought (CoT) prompting techniques:\\n\\n*   Standard Chain-of-Thought (CoT)\\n*   Self-Consistency Decoding\\n*   Graph-of-Thoughts (GoT)\\n*   Tree-of-Thoughts (ToT)\\n*   Program-of-Thoughts (PoT)\\n*   Chain-of-Hindsight (CoH)\\n*   CoT-Guided ToT/GoT\\n*   CoT for Branch Selection in ToT\\n*   CoT for Node Generation in GoT\"]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "research_output = strategybot.get_state(self_research_inputs['ssc_thread_id'])\n",
    "research_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a420c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variants of Chain-of-Thought (CoT) prompting techniques are:\n",
      "\n",
      "*   Standard CoT\n",
      "*   Zero-shot CoT\n",
      "*   Self-Consistency\n",
      "*   Finetuned CoT\n",
      "*   Least-to-Most prompting\n",
      "*   Automatic Prompt Optimization (APO)\n",
      "*   CoT with Verification\n",
      "*   Graph CoT\n",
      "*   Tree-of-Thoughts (ToT)\n",
      "*   CoT combined with Knowledge Retrieval\n",
      "*   Distillation for CoT\n",
      "*   Complexity-Based Prompting\n",
      "*   Task-Specific CoT\n",
      "*   Self-Refinement\n",
      "*   CoT with External Verification\n",
      "*   Constraint-Based CoT\n",
      "*   Graph-of-Thoughts (GoT)\n",
      "*   Program-of-Thoughts (PoT)\n",
      "*   Chain-of-Hindsight (CoH)\n",
      "*   CoT-Guided ToT/GoT\n",
      "*   CoT for Branch Selection in ToT\n",
      "*   CoT for Node Generation in GoT\n"
     ]
    }
   ],
   "source": [
    "for line in research_output['ssc_summary'].answer.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea647bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_inputs ={\n",
    "    'template_inputs': self_research_inputs['template_inputs'] | {'answer': research_output['ssc_summary'].answer},\n",
    "    'thread_id': self_research_inputs['ssc_thread_id'] + '/ver12',\n",
    "    'parent_thread_id': self_research_inputs['ssc_thread_id']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca85b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_output = verificationbot.run(**verification_inputs)\n",
    "verification_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cbfa71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. **Task Decomposition:** The task is to list all variants of Chain-of-Thought (CoT) prompting techniques. The answer format is a list.\n",
      "\n",
      "2. **Contextual Restrictions and Information:**\n",
      "    - The list should be comprehensive.\n",
      "    - The list should not include fine-tuning methods.\n",
      "    - The list should only include prompting techniques.\n",
      "\n",
      "3. **Answer Analysis and Doubts:**\n",
      "    - The answer provides a list of CoT prompting techniques. However, some entries might be fine-tuning methods (which should be excluded based on the context). Also, the comprehensiveness of the list is questionable and needs verification. There might be missing CoT variants. Some listed items may be duplicates or very similar techniques described with different names. The correctness of each listed item needs to be verified to ensure it's a valid CoT prompting technique and not a misclassified or non-existent method.\n",
      "    - Some of the items might be too general, e.g. 'CoT combined with Knowledge Retrieval' is a very broad category, and it would be better to list concrete techniques. Also, some items seem to be follow-up research directions instead of established CoT variants.\n"
     ]
    }
   ],
   "source": [
    "# task delegation analysis\n",
    "for line in verification_output['task_list'].analysis.split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868972f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job: Verify that each item in the list is a valid Chain-of-Thought (CoT) *prompting* technique and not a fine-tuning method or something else.\n",
      "Doubts: Some items might be misclassified or not directly related to CoT prompting as defined in the context.\n",
      "Additional Info: The context specifies that fine-tuning methods should be excluded. Focus on techniques that guide the LLM during inference, not during training.\n",
      "Analysis methodology: 1. For each item in the list, research its definition and usage.\n",
      "2. Determine if the item is a prompting technique or a fine-tuning method.\n",
      "3. If it's a prompting technique, verify that it aligns with the Chain-of-Thought approach (i.e., involves generating intermediate reasoning steps).\n",
      "4. If it's not a valid CoT prompting technique, flag it for removal or modification.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Job: Check the comprehensiveness of the list. Are there any significant and well-known CoT prompting techniques missing?\n",
      "Doubts: The list might not be exhaustive, and some important variants could be absent.\n",
      "Additional Info: Consider recent research papers and surveys on CoT prompting to identify potential omissions.\n",
      "Analysis methodology: 1. Search for recent surveys and research papers on Chain-of-Thought prompting.\n",
      "2. Identify CoT variants mentioned in these sources that are not present in the provided list.\n",
      "3. Add any missing variants to the list.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Job: Identify and remove any duplicate or very similar CoT prompting techniques that are listed under different names.\n",
      "Doubts: The list might contain redundant entries that describe essentially the same technique.\n",
      "Additional Info: Pay close attention to the descriptions and underlying mechanisms of each listed item.\n",
      "Analysis methodology: 1. Compare the descriptions of each pair of items in the list.\n",
      "2. If two items describe the same technique with different names, choose the most common or descriptive name and remove the other item.\n",
      "3. Consider merging similar items into a single entry if appropriate.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Job: Verify the accuracy of the names of the techniques. Some of them seems to be not correct, e.g. 'Finetuned CoT'.\n",
      "Doubts: Some of the names are not standard and can be misleading.\n",
      "Additional Info: Check original papers for the correct names.\n",
      "Analysis methodology: 1. Search for original papers describing the mentioned techniques.\n",
      "2. Compare names from the list with names used in the original papers.\n",
      "3. Correct names if needed.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Job: Some of the items might be too general, e.g. 'CoT combined with Knowledge Retrieval'. Try to be more specific.\n",
      "Doubts: General items should be replaced with specific techniques.\n",
      "Additional Info: Focus on concrete techniques instead of general categories.\n",
      "Analysis methodology: 1. Identify general items.\n",
      "2. Find specific techniques that fall under these general categories.\n",
      "3. Replace general items with specific techniques.\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# prompts list\n",
    "sep = f'\\n{'-' * 40}\\n'\n",
    "for sc_summ in verification_output['task_list'].prompts:\n",
    "    for line in sc_summ.split('\\n'):\n",
    "        print(line)\n",
    "    print(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09213f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will analyze each item in the provided list to determine if it is a valid Chain-of-Thought (CoT) prompting technique, ensuring it is not a fine-tuning method or an unrelated technique. I will consult external resources to confirm the definition and usage of each item. If an item is misclassified or not directly related to CoT prompting, I will flag it for removal or modification.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "I will conduct a search for recent surveys and research papers on Chain-of-Thought prompting to identify CoT variants mentioned in these sources that are not present in the provided list and add any missing variants to the list.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "I have compared all pairs of items in the list and identified potential duplicates or very similar techniques. For example, 'Graph CoT' and 'Graph-of-Thoughts (GoT)' seem very similar, and 'CoT-Guided ToT/GoT', 'CoT for Branch Selection in ToT', and 'CoT for Node Generation in GoT' also appear closely related.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "I will search for original papers describing the mentioned techniques and compare names from the list with names used in the original papers. Then I will correct names if needed.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Identified general items: 'CoT combined with Knowledge Retrieval', 'Task-Specific CoT'.\n",
      "Researched specific techniques that fall under these categories.\n",
      "\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# analysis from all tasks\n",
    "sep = f'\\n{'-' * 40}\\n'\n",
    "for sc_summ in verification_output['simple_task_response']:\n",
    "    for line in sc_summ.analysis.split('\\n'):\n",
    "        print(line)\n",
    "    print(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e4f9958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No changes are needed. The list appears to be comprehensive and accurate. All listed items are valid variants or applications of Chain-of-Thought (CoT) prompting techniques. Therefore, no modifications are required at this time. The answer is correct and comprehensive\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "The list seems relatively comprehensive, but it could benefit from the inclusion of the following CoT variants: - Multimodal CoT: This variant incorporates multiple modalities, such as text and images, into the CoT process. - Step-Back Prompting: This involves prompting the model to take a step back and consider the bigger picture before answering a question. - Generated Knowledge Prompting: This technique encourages the model to generate relevant knowledge before answering a question. Adding these techniques would make the list more complete and up-to-date. Also consider merging similar techniques, such as Graph CoT and Graph-of-Thoughts (GoT), and explicitly mentioning their relationship or differences to avoid redundancy and improve clarity. Also Program-of-Thoughts (PoT) can be considered a sub-variant of ToT, GoT, where the 'thoughts' are programs. Consider adding a small description to each item to clarify the differences between them\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Based on the analysis, I will provide specific recommendations for correcting any inaccurate names or terminology used in the list, citing the appropriate sources for verification. The recommendations will include the exact text to add, remove, or modify to align with the standard terminology used in research papers and surveys.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "Consider removing 'CoT combined with Knowledge Retrieval' from the list as it represents a combination of CoT with another method, rather than a distinct CoT variant itself. It might be better placed in a section discussing CoT's integration with other techniques, if such a section exists or is planned. Alternatively, rename it to Knowledge Retrieval Augmented CoT or similar to clarify its nature as a combined approach if kept in the list.\n",
      "\n",
      "----------------------------------------\n",
      "\n",
      "The list should be reorganized into the following categories:\n",
      "\n",
      "**1. Foundational CoT:**\n",
      "*   Standard CoT\n",
      "*   Zero-shot CoT\n",
      "\n",
      "**2. Reasoning Refinement Techniques:**\n",
      "*   Self-Consistency\n",
      "*   Finetuned CoT\n",
      "*   Least-to-Most prompting\n",
      "*   Automatic Prompt Optimization (APO)\n",
      "*   CoT with Verification\n",
      "*   Self-Refinement\n",
      "*   CoT with External Verification\n",
      "*   Constraint-Based CoT\n",
      "*   Complexity-Based Prompting\n",
      "*   Task-Specific CoT\n",
      "\n",
      "**3. Multi-Path Exploration Techniques:**\n",
      "*   Graph CoT\n",
      "*   Tree-of-Thoughts (ToT)\n",
      "*   Graph-of-Thoughts (GoT)\n",
      "*   Program-of-Thoughts (PoT)\n",
      "*   CoT-Guided ToT/GoT\n",
      "*   CoT for Branch Selection in ToT\n",
      "*   CoT for Node Generation in GoT\n",
      "\n",
      "**4. Knowledge Integration Techniques:**\n",
      "*   CoT combined with Knowledge Retrieval\n",
      "\n",
      "**5. Retrospective Refinement Techniques:**\n",
      "*   Chain-of-Hindsight (CoH)\n",
      "\n",
      "**6. Model Compression Techniques:**\n",
      "*   Distillation for CoT\n",
      "\n",
      "----------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# separate recommendations from all tasks\n",
    "sep = f'\\n{'-' * 40}\\n'\n",
    "for sc_summ in verification_output['simple_task_response']:\n",
    "    for line in sc_summ.recommendations.split('\\n'):\n",
    "        print(line)\n",
    "    print(sep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3791473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variants of Chain-of-Thought (CoT) prompting techniques are:\n",
      "\n",
      "*   Standard CoT\n",
      "*   Zero-shot CoT\n",
      "*   Self-Consistency\n",
      "*   Finetuned CoT\n",
      "*   Least-to-Most prompting\n",
      "*   Automatic Prompt Optimization (APO)\n",
      "*   CoT with Verification\n",
      "*   Graph CoT\n",
      "*   Tree-of-Thoughts (ToT)\n",
      "*   Distillation for CoT\n",
      "*   Complexity-Based Prompting\n",
      "*   Task-Specific CoT\n",
      "*   Self-Refinement\n",
      "*   CoT with External Verification\n",
      "*   Constraint-Based CoT\n",
      "*   Graph-of-Thoughts (GoT)\n",
      "*   Program-of-Thoughts (PoT)\n",
      "*   Chain-of-Hindsight (CoH)\n",
      "*   CoT-Guided ToT/GoT\n",
      "*   CoT for Branch Selection in ToT\n",
      "*   CoT for Node Generation in GoT\n",
      "*   Multimodal CoT\n",
      "*   Step-Back Prompting\n",
      "*   Generated Knowledge Prompting\n",
      "*   Knowledge Retrieval Augmented CoT\n"
     ]
    }
   ],
   "source": [
    "for line in verification_output['verified_answer'].answer.split('\\n'):\n",
    "    print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
