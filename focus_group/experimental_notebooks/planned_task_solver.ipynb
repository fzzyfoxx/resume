{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50e4d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.chatbots.chatbot import BaseChatBot\n",
    "from fcgb.types.tools import ToolOutput\n",
    "from langgraph.graph import MessagesState\n",
    "from langchain_core.runnables.config import RunnableConfig\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from typing import List, Dict, Annotated\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from operator import add\n",
    "import uuid\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langgraph.constants import Send\n",
    "from fcgb.types.utils import append_or_clear, MessagesType\n",
    "from fcgb.cfg.utils import model2string, dict2string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "60e7027f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(JobModel(job='Fake string ebxdn', restrictions='Fake string lndml', output_format='Fake string vxpwe', variables=['restrictions', 'restrictions', 'knowledge_base']),\n",
       " fcgb.types.tools.JobModel)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fcgb.fake_models import FakeStructuredOutput\n",
    "from fcgb.types.tools import JobModel\n",
    "\n",
    "job_model = FakeStructuredOutput(JobModel)()\n",
    "job_model, type(job_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304c48b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PlannedIterativeTaskSolver(BaseChatBot):\n",
    "    def __init__(self,\n",
    "                 llm,\n",
    "                 job_handler,\n",
    "                 initial_messages_spec,\n",
    "                 internal_messages_spec,\n",
    "                 memory=None,\n",
    "                 init_values={},\n",
    "                 prompt_manager_spec={},\n",
    "                 global_inputs={}):\n",
    "        super().__init__(\n",
    "            llm=llm,\n",
    "            initial_messages_spec=initial_messages_spec,\n",
    "            internal_messages_spec=internal_messages_spec,\n",
    "            memory=memory,\n",
    "            init_values=init_values,\n",
    "            prompt_manager_spec=prompt_manager_spec,\n",
    "            global_inputs=global_inputs,\n",
    "            compile=False\n",
    "        )\n",
    "\n",
    "        self.job_handler = job_handler\n",
    "        self.compile_graph()\n",
    "\n",
    "    def _set_state_class(self):\n",
    "        \n",
    "        class State(BaseModel):\n",
    "            template_inputs: Dict[str, str]\n",
    "            all_messages: MessagesType\n",
    "            current_messages: MessagesType\n",
    "            all_jobs: Annotated[List, append_or_clear]\n",
    "            current_jobs: List = []\n",
    "            current_jobs_outputs: Annotated[List[str], append_or_clear]\n",
    "            knowledge_base: str\n",
    "            turns: int\n",
    "            thread_id: str = None\n",
    "            output: str = None # type: ignore\n",
    "\n",
    "        self.state_class = State\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_jobs_list(jobs_descriptions: List) -> str:\n",
    "        return '\\n'.join(f'Job {i+1}: {job.job}' for i, job in enumerate(jobs_descriptions))\n",
    "\n",
    "    def _set_planning_func(self):\n",
    "\n",
    "        def planning(state: self.state_class): # type: ignore\n",
    "            turns = state.turns + 1\n",
    "            print(f'Planning turn {turns}...')\n",
    "            all_jobs = self._get_jobs_list(state.all_jobs)\n",
    "            template_inputs = state.template_inputs | {'turns': turns, 'knowledge_base': state.knowledge_base, 'all_jobs': all_jobs}\n",
    "\n",
    "            system_msg, _ = self._get_internal_message('system', template_inputs)\n",
    "            query_msg, _ = self._get_internal_message('query', template_inputs)\n",
    "            planning_msg, _ = self._get_internal_message('planning', template_inputs)\n",
    "\n",
    "            plan_msg = self.llm.invoke([system_msg, query_msg, planning_msg])\n",
    "\n",
    "            return {\n",
    "                'current_messages': [system_msg, query_msg, planning_msg, plan_msg], \n",
    "                'turns': turns\n",
    "                }\n",
    "        \n",
    "        return planning\n",
    "    \n",
    "    def _set_process_end_routing_func(self):\n",
    "\n",
    "        def process_end_routing(state: self.state_class): # type: ignore\n",
    "\n",
    "            if state.turns == 1:\n",
    "                return 'distribution'\n",
    "            elif state.turns >  self.global_inputs['max_turns']:\n",
    "                return 'report'\n",
    "            else:\n",
    "                print(f'Process End Routing turn {state.turns}...')\n",
    "                routing_msg, answer_model = self._get_internal_message('process_end_routing', state.template_inputs)\n",
    "\n",
    "                decision = self.llm.with_structured_output(answer_model).invoke(state.current_messages + [routing_msg]).decision\n",
    "\n",
    "                if decision == 'report':\n",
    "                    return 'report'\n",
    "                else:\n",
    "                    return 'distribution'\n",
    "                \n",
    "        def max_turns_routing(state: self.state_class): # type: ignore\n",
    "            return 'report' if state.turns >= self.global_inputs['max_turns'] else 'planning'\n",
    "                \n",
    "            \n",
    "        return process_end_routing, max_turns_routing\n",
    "    \n",
    "    def _set_distribution_func(self):\n",
    "\n",
    "        def distribution(state: self.state_class): # type: ignore\n",
    "            print(f'Jobs Distribution turn {state.turns}...')\n",
    "\n",
    "            template_inputs = state.template_inputs | {'turns': state.turns, 'knowledge_base': state.knowledge_base}\n",
    "\n",
    "            distribution_msg, answer_model = self._get_internal_message('distribution', template_inputs)\n",
    "\n",
    "            jobs = self.llm.with_structured_output(answer_model).invoke(state.current_messages + [distribution_msg])\n",
    "\n",
    "            return {\n",
    "                'current_jobs': jobs.jobs\n",
    "            }\n",
    "        \n",
    "        return distribution\n",
    "    \n",
    "    def _set_job_routing_func(self):\n",
    "\n",
    "        def job_routing(state: self.state_class): # type: ignore\n",
    "\n",
    "            return [Send('executor',  {'state': state, 'job': job}) for job in state.current_jobs]\n",
    "        \n",
    "        return job_routing\n",
    "    \n",
    "    def _set_executor_func(self):\n",
    "\n",
    "        def executor(input: Dict): # type: ignore\n",
    "            job = input['job']\n",
    "            state = input['state']\n",
    "\n",
    "            print(f'Job Execution turn {state.turns}: {job.job}...')\n",
    "\n",
    "            job_dict = job.model_dump()\n",
    "            variables = job_dict['variables']\n",
    "            job_dict.pop('variables', None)  # Remove 'variables' key if it exists\n",
    "            job_description = dict2string(job_dict)\n",
    "\n",
    "            if len(variables) > 0:\n",
    "                data_content = '\\n\\n# **additional data**:\\n'\n",
    "                variable_base = state.template_inputs | {'knowledge_base': state.knowledge_base}\n",
    "                available_variables = variable_base.keys()\n",
    "                for variable in variables:\n",
    "                    if variable in available_variables:\n",
    "                        data_content += f'## {variable}:\\n{variable_base[variable]}\\n\\n'\n",
    "\n",
    "                job_description += data_content\n",
    "            \n",
    "            job_output = self.job_handler.run(job_description=job_description)\n",
    "            print(f'Job execution end')\n",
    "            return {'current_jobs_outputs': job_output}\n",
    "        \n",
    "        return executor\n",
    "    \n",
    "    @staticmethod\n",
    "    def concatenate_outputs(outputs: List[Dict]) -> str:\n",
    "        return '\\n-----\\n'.join(output['output'] for output in outputs if 'output' in output)\n",
    "    \n",
    "    def _set_base_extension_func(self):\n",
    "\n",
    "        def base_extension(state: self.state_class): # type: ignore\n",
    "            print(f'Base Extension turn {state.turns}...')\n",
    "            retrieved_data = self.concatenate_outputs(state.current_jobs_outputs)\n",
    "            current_jobs = self._get_jobs_list(state.current_jobs)\n",
    "            template_inputs = state.template_inputs | {'turns': state.turns, 'knowledge_base': state.knowledge_base, 'retrieved_data': retrieved_data, 'current_jobs': current_jobs}\n",
    "            extension_msg, _ = self._get_internal_message('base_extension', template_inputs)\n",
    "\n",
    "            extended_base = self.llm.invoke(state.current_messages + [extension_msg])\n",
    "            return {\n",
    "                'knowledge_base': extended_base.content,\n",
    "                'current_messages': [extension_msg, extended_base],\n",
    "            }\n",
    "        \n",
    "        return base_extension\n",
    "    \n",
    "    def _set_iteration_end_func(self):\n",
    "\n",
    "        def iteration_end(state: self.state_class): # type: ignore\n",
    "            messages_to_pass = state.current_messages[2:] if state.turns>1 else state.current_messages\n",
    "            return {\n",
    "                'all_messages': messages_to_pass,\n",
    "                'current_messages': '__clear__',\n",
    "                'all_jobs': state.current_jobs,\n",
    "                'current_jobs': [],\n",
    "                'current_jobs_outputs': '__clear__'\n",
    "            }\n",
    "\n",
    "        return iteration_end\n",
    "    \n",
    "    def _set_report_func(self):\n",
    "\n",
    "        def report(state: self.state_class, config: RunnableConfig): # type: ignore\n",
    "            print(f'Reporting turn {state.turns}...')\n",
    "            template_inputs = state.template_inputs | {'turns': state.turns, 'knowledge_base': state.knowledge_base}\n",
    "\n",
    "            report_msg, _ = self._get_internal_message('report', template_inputs)\n",
    "\n",
    "            output = self.llm.invoke([report_msg])\n",
    "            thread_id = config['configurable']['thread_id']\n",
    "\n",
    "            return {\n",
    "                'output': output.content,\n",
    "                'thread_id': thread_id,\n",
    "                'all_messages': state.current_messages[2:],\n",
    "                'current_messages': '__clear__',\n",
    "            }\n",
    "        \n",
    "        return report\n",
    "    \n",
    "    def _compile_graph(self):\n",
    "        \n",
    "        planning_func = self._set_planning_func()\n",
    "        process_end_routing_func, max_turns_routing_func = self._set_process_end_routing_func()\n",
    "        distribution_func = self._set_distribution_func()\n",
    "        job_routing_func = self._set_job_routing_func()\n",
    "        executor_func = self._set_executor_func()\n",
    "        base_extension_func = self._set_base_extension_func()\n",
    "        iteration_end_func = self._set_iteration_end_func()\n",
    "        report_func = self._set_report_func()\n",
    "\n",
    "        workflow = StateGraph(self.state_class)\n",
    "        workflow.add_node('planning', planning_func)\n",
    "        workflow.add_node('distribution', distribution_func)\n",
    "        workflow.add_node('executor', executor_func)\n",
    "        workflow.add_node('base_extension', base_extension_func)\n",
    "        workflow.add_node('iteration_end', iteration_end_func)\n",
    "        workflow.add_node('report', report_func)\n",
    "\n",
    "        workflow.add_edge(START, 'planning')\n",
    "        workflow.add_conditional_edges('planning', process_end_routing_func, ['distribution', 'report'])\n",
    "        workflow.add_conditional_edges('distribution', job_routing_func, ['executor'])\n",
    "        workflow.add_edge('executor', 'base_extension')\n",
    "        workflow.add_edge('base_extension', 'iteration_end')\n",
    "        workflow.add_conditional_edges('iteration_end', max_turns_routing_func, ['planning', 'report'])\n",
    "        workflow.add_edge('report', END)\n",
    "\n",
    "        self.graph = workflow.compile(\n",
    "            checkpointer=self.memory\n",
    "        )\n",
    "\n",
    "    def run(self, job: str, restrictions: str, output_format: str, data: str) -> ToolOutput:\n",
    "        \n",
    "        thread_id = uuid.uuid4().hex\n",
    "        return self.graph.invoke(\n",
    "            input={\n",
    "                'template_inputs': {\n",
    "                    'job': job,\n",
    "                    'restrictions': restrictions,\n",
    "                    'output_format': output_format,\n",
    "                    'data': data\n",
    "                    },\n",
    "                'turns': 0,\n",
    "                'knowledge_base': 'Empty'\n",
    "                },\n",
    "            config = {'configurable': {'thread_id': thread_id}},\n",
    "            output_keys=['thread_id', 'output']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d812bea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'job': 'List all Chain-of-Thought prompting variants',\n",
    "    'restrictions': \"\"\"\n",
    "    1. List only real prompting techniques\n",
    "    2. Do not include techniques that are just applications of other techniques\n",
    "    3. Do not include techniques that are not related to CoT prompting\"\"\",\n",
    "    'output_format': 'List of techniques with very short description of each technique',\n",
    "    'data': 'None'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14f9bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_data = \"\"\"\n",
    "**BOOK SPECIFICATION:**\n",
    "{'main_title': 'About Prompt Engineering',\n",
    " 'initial_description': 'Guide should cover widely concepts of prompt engineering, with focus on specific prompt engineering techniques and their variations, \\ntry to cover as many of them as you can. Target audience is not defined, so potential readers would be as well non-technical as technical.\\nEnrich every technique with examples. Write also something about how LLMs work, and how prompt engineering can help to improve their performance.',\n",
    " 'main_subject': 'Mastering prompt engineering techniques: a comprehensive guide for all skill levels',\n",
    " 'content_description': '*   Broad overview of prompt engineering techniques [essential]\\n*   Comprehensive guide from beginner to expert [essential]\\n*   Everything relevant to writing great and accurate prompts [essential]\\n*   Detailed breakdown of techniques with multiple variations and real-world examples [essential]\\n*   Information about how prompting may influence technical aspects of LLMs, covered within the introduction [moderate]\\n*   Techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats [high]\\n*   Detailed view of techniques like zero-shot prompting and chain-of-thought prompting [essential]\\n*   Visual aids to augment every technique [essential]',\n",
    " 'style': \"*   Avoid industry-focused content [essential]\\n*   Avoid overly formal language [essential]\\n*   Humorous language is acceptable if it doesn't detract from credibility [moderate]\",\n",
    " 'target_audience': '*   Both non-technical and technical readers',\n",
    " 'layout': '*   Full-length book (200+ pages) [essential]\\n*   Detailed view includes: formal definition, explanation of why it works, multiple examples, limitations/drawbacks, and variations [essential]',\n",
    " 'restrictions': ['*   No deep-dive into LLM architecture beyond the introduction [essential]']}\n",
    "\"\"\"\n",
    "\n",
    "inputs = {\n",
    "    'job': 'You are constructing an initial level of a subjects tree-graph for a guide book defined in the additional_data section. Divide the main subject into up to 20 distinct subjects that will decompose the core ideas of the book.',\n",
    "    'restrictions': \"\"\"\n",
    "    1. Use all information provided in the additional_data section\n",
    "    \"\"\",\n",
    "    'output_format': \"\"\"\n",
    "    List of sections with titles, descriptions and relevance (how it refers to the book specification) in format:\n",
    "    Title: <title 1>\n",
    "    - Description: <description 1>\n",
    "    - Relevance: <relevance 1>\n",
    "    Title: <title 2>\n",
    "    - Description: <description 2>\n",
    "    - Relevance: <relevance 2>\n",
    "    ...\n",
    "    \"\"\",\n",
    "    'data': additional_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61980e09",
   "metadata": {},
   "source": [
    "# **TASK**\n",
    "You are constructing a knowledge graph for a book: \"About Prompt Engineering: Mastering prompt engineering techniques: a comprehensive guide for all skill levels\".\n",
    "Analyze current graph state and according to the provided book specification, knowledge graph rules and node types specification propose a list of up to 10 new knowledge graph nodes. \n",
    "Do not treat nodes from your answer as already existing nodes but rather as proposals. You can't refer to them as parent nodes in other nodes included in your answer.\n",
    "Propose only nodes that fit to already existing graph state.\n",
    "\n",
    "## **KNOWLEDGE GRAPH RULES**\n",
    "- Knowledge graph is a collection of nodes connected with edges in a directed acyclic graph (DAG) structure where except the core node, each node can have multiple children nodes and only one parent node. \n",
    "- Each node should represent a single knowledge entity useful for the book structure planning. The are not suposed to be sections of the book.\n",
    "- Build it from the core node which is the book title starting with the most general subjects and then gradually narrow down to more specific topics.\n",
    "- Use container nodes to collect entities that represents the same category of knowledge.\n",
    "- Concept nodes are usefull to gather knowledge about specific entities to plan further exploration, build analysis nodes or just explain unit topics.\n",
    "- Analysis nodes should be used mainly to produce some inights of elements of some container node, collection of concept nodes or add some specific additional information to a single concept node.\n",
    "- Avoid duplicating nodes, be sure you are not proposing nodes that already exist or explore the same areas at the same time.\n",
    "\n",
    "## **NODE TYPES SPECIFICATION**\n",
    "1. **container** \n",
    "- purpose: Node will be used just as a parent node to its list of outputs. It won't have its own content.\n",
    "- research objective: Specify directly what kind of items are expected to be placed under this node. Do not specify what future child nodes should contain, just what they should be.\n",
    "- examples: \"ML classification techniques\", \"Flower species\", \"Programming languages\"\n",
    "2. **concept**\n",
    "- purpose: Node will contain a concept, definition, or explanation of a specific term or idea. It can be still connected with some child nodes later.\n",
    "- research objective: Specify what should be included in its content, such as definitions, explanations, and examples.\n",
    "- examples: \"Neural networks\", \"Photosynthesis\", \"Object-oriented programming\"\n",
    "3. **analysis**\n",
    "- purpose: Node will contain an analysis of a specific topic, including comparisons, evaluations, or assessments. The role of this node is to provide extended insights into container or concept nodes.\n",
    "- research objective: Specify the purpose of the analysis, such as comparing different approaches, evaluating effectiveness, assessing implications etc.. If your are able to at this point also write steps of reasoning.\n",
    "- examples: \"Comparison of ML algorithms\", \"Evaluation of renewable energy sources\", \"Limitations of JavaScript\"\n",
    "- **Constraint**: Analysis nodes should be based on existing concept nodes. Before using them make sure that concept nodes they are based on exist in the graph. For exaple, if you want to create an analysis node \"Comparison of ML algorithms\", make sure that there is some container with different nodes representing specific ML algorithms.\n",
    "\n",
    "## **GRAPH STATE**\n",
    "### **Nodes**\n",
    "('id'=1, 'title'='About Prompt Engineering', 'type'='container', 'description'='Core node of a knowledge graph')\n",
    "\n",
    "## **ANSWER FORMAT**\n",
    "```\n",
    "1. [Node Title 1]\n",
    "    - Node type: [container/concept/analysis]\n",
    "    - Research objective: [brief description of what should be included in the node according to the node type specification]\n",
    "    - Purpose: [why it is relevant to the book specification]\n",
    "    - Parent node id: [id of an existing node from the graph state]\n",
    "2. [None Title 2]\n",
    "...\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **BOOK SPECIFICATION**\n",
    "\n",
    "## **Main title**\n",
    "About Prompt Engineering\n",
    "\n",
    "## **Subtitle**\n",
    "Mastering prompt engineering techniques: a comprehensive guide for all skill levels\n",
    "\n",
    "## **Book object description**\n",
    "Guide should cover widely concepts of prompt engineering, with focus on specific prompt engineering techniques and their variations, try to cover as many of them as you can. Target audience is not defined, so potential readers would be as well non-technical as technical.\\nEnrich every technique with examples. Write also something about how LLMs work, and how prompt engineering can help to improve their performance.\n",
    "\n",
    "## **Content description**\n",
    "* Broad overview of prompt engineering techniques [essential] \n",
    "* Comprehensive guide from beginner to expert [essential]\n",
    "* Everything relevant to writing great and accurate prompts [essential]  \n",
    "* Detailed breakdown of techniques with multiple variations and real-world examples [essential]\n",
    "* Information about how prompting may influence technical aspects of LLMs, covered within the introduction [moderate]  \n",
    "* Techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats [high]\n",
    "* Detailed view of techniques like zero-shot prompting and chain-of-thought prompting [essential]\n",
    "* Visual aids to augment every technique [essential]\n",
    "\n",
    "## **Style**\n",
    "* Avoid industry-focused content [essential] \n",
    "* Avoid overly formal language [essential]\n",
    "* Humorous language is acceptable if it doesn't detract from credibility [moderate]\n",
    "\n",
    "## **Layout**\n",
    "* Full-length book (200+ pages) [essential]\n",
    "* Detailed view includes: formal definition, explanation of why it works, multiple examples, limitations/drawbacks, and variations [essential]\n",
    "\n",
    "## **Restrictions**\n",
    "* No deep-dive into LLM architecture beyond the introduction.,\n",
    "* Avoid sections focused on LLM usage for specific industries or professional fields (e.g., law, medicine, finance). Examples of techniques are allowed, but they should not be the primary focus.,\n",
    "* Avoid including techniques that are actually LLM weights fine-tuning methods (as opposed to prompt engineering techniques).,\n",
    "* Avoid sections heavily reliant on bullet points, code snippets, or examples. Aim for a balance that prioritizes descriptive explanations.,\n",
    "* Prioritize practical, real-world examples from professional environments. Avoid simplistic or \"toy\" examples.,\n",
    "* Explain advanced technical concepts in a simplified manner, focusing on how to use the prompting techniques rather than the underlying technical details of how they affect the model\n",
    "\n",
    "## **Target audience**\n",
    "Both non-technical and technical readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e640111",
   "metadata": {},
   "source": [
    "# **TASK**\n",
    "Your mission is to find Chain-of-Thought variants which will be added to the knowledge graph for a book described in the book specification.\n",
    "Analyze the research assignment and if you are able to do it by yourself propose an answer in format:\n",
    "```\n",
    "* **item 1**: \n",
    " - description: [brief description of the item]\n",
    " - relevance: [why it is relevant to the book specification and research assignment]\n",
    "* **item 2**:\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "## **RESEARCH ASSIGNMENT**\n",
    "Research objective: Collect comprehensive list of Chain-of-Thought prompting variations (like \"Zero-shot CoT\", \"Few-shot CoT\", \"Self-consistency CoT\") \n",
    "Purpose: As specified in the content description the book should include detailed breakdown of techniques with multiple variations. CoT seems to be one of the most important techniques, so it should be covered in detail.\n",
    "\n",
    "# **BOOK SPECIFICATION**\n",
    "\n",
    "## **Main title**\n",
    "About Prompt Engineering\n",
    "\n",
    "## **Subtitle**\n",
    "Mastering prompt engineering techniques: a comprehensive guide for all skill levels\n",
    "\n",
    "## **Book object description**\n",
    "Guide should cover widely concepts of prompt engineering, with focus on specific prompt engineering techniques and their variations, try to cover as many of them as you can. Target audience is not defined, so potential readers would be as well non-technical as technical.\\nEnrich every technique with examples. Write also something about how LLMs work, and how prompt engineering can help to improve their performance.\n",
    "\n",
    "## **Content description**\n",
    "* Broad overview of prompt engineering techniques [essential] \n",
    "* Comprehensive guide from beginner to expert [essential]\n",
    "* Everything relevant to writing great and accurate prompts [essential]  \n",
    "* Detailed breakdown of techniques with multiple variations and real-world examples [essential]\n",
    "* Information about how prompting may influence technical aspects of LLMs, covered within the introduction [moderate]  \n",
    "* Techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats [high]\n",
    "* Detailed view of techniques like zero-shot prompting and chain-of-thought prompting [essential]\n",
    "* Visual aids to augment every technique [essential]\n",
    "\n",
    "## **Style**\n",
    "* Avoid industry-focused content [essential] \n",
    "* Avoid overly formal language [essential]\n",
    "* Humorous language is acceptable if it doesn't detract from credibility [moderate]\n",
    "\n",
    "## **Layout**\n",
    "* Full-length book (200+ pages) [essential]\n",
    "* Detailed view includes: formal definition, explanation of why it works, multiple examples, limitations/drawbacks, and variations [essential]\n",
    "\n",
    "## **Restrictions**\n",
    "* No deep-dive into LLM architecture beyond the introduction.,\n",
    "* Avoid sections focused on LLM usage for specific industries or professional fields (e.g., law, medicine, finance). Examples of techniques are allowed, but they should not be the primary focus.,\n",
    "* Avoid including techniques that are actually LLM weights fine-tuning methods (as opposed to prompt engineering techniques).,\n",
    "* Avoid sections heavily reliant on bullet points, code snippets, or examples. Aim for a balance that prioritizes descriptive explanations.,\n",
    "* Prioritize practical, real-world examples from professional environments. Avoid simplistic or \"toy\" examples.,\n",
    "* Explain advanced technical concepts in a simplified manner, focusing on how to use the prompting techniques rather than the underlying technical details of how they affect the model\n",
    "\n",
    "## **Target audience**\n",
    "Both non-technical and technical readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "914a7a1a",
   "metadata": {},
   "source": [
    "Keeping in mind all provided specifications and current answer state propose a step-by-step strategy to expand the answer with more items.\n",
    "\n",
    "Strategy example 1:\n",
    "```\n",
    "Research objective: Find all main ML algorithms.\n",
    "Strategy:\n",
    "1. Identify the main categories of ML algorithms (e.g., supervised learning, unsupervised learning, reinforcement learning).\n",
    "2. For each category, list the most common algorithms (e.g., linear regression, decision trees, k-means clustering).\n",
    "3. Collect items from each category.\n",
    "```\n",
    "\n",
    "Strategy example 2:\n",
    "```\n",
    "Research objective: How to stay calm in stressful situations.\n",
    "Strategy:\n",
    "1. Describe some stressful situation and how it affects people.\n",
    "2. Identify how one can mitigate stress in such situation.\n",
    "3. Find techniques that fits to the methods described in point 2.\n",
    "```\n",
    "\n",
    "Strategy example 3:\n",
    "```\n",
    "Research objective: Fundamentals of healthy diet. Speficy main concepts of healthy eating.\n",
    "Strategy:\n",
    "1. List few purposes of why people should eat healthy.\n",
    "2. Specify how to address each purpose.\n",
    "3. Aggregate purposes into distinct subjects.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b948e14d",
   "metadata": {},
   "source": [
    "Evaluate provided list in terms of how general or specific every subject is using the provided scale.\n",
    "Return a list in following format:\n",
    "([subject_title], [level_of_generality])\n",
    "\n",
    "For example:\n",
    "(Machine Learning, 2)\n",
    "(Support Vector Machines, 4)\n",
    "\n",
    "## **Level of Generality Scale**\n",
    "### Level 1: Very Broad / Foundational\n",
    "\n",
    "    Name: Macro-Topic\n",
    "    Instruction: Assign this level if the subject represents a very high-level, overarching domain or discipline. It's likely to encompass numerous major sub-fields and could easily be the title of an entire textbook or university department. Further decomposition is absolutely necessary to make it actionable within a knowledge base.\n",
    "    Example: \"Artificial Intelligence,\" \"Human Anatomy,\" \"World History\"\n",
    "\n",
    "### Level 2: Broad / Major Area\n",
    "\n",
    "    Name: Major Domain\n",
    "    Instruction: Assign this level if the subject is a significant, well-defined area within a broader macro-topic. While more focused than Level 1, it still contains a considerable amount of information and would likely be broken down into several distinct sub-topics. Requires substantial further decomposition.\n",
    "    Example: \"Machine Learning\" (within Artificial Intelligence), \"Skeletal System\" (within Human Anatomy), \"World War II\" (within World History)\n",
    "\n",
    "### Level 3: Moderate / Specific Topic\n",
    "\n",
    "    Name: Specific Topic\n",
    "    Instruction: Assign this level if the subject is a distinct topic that can be reasonably covered in a dedicated chapter or significant section. It's specific enough that its boundaries are clear, but still likely to have a few key sub-areas or concepts that would be beneficial to explore individually. Further decomposition is often beneficial, but not always strictly necessary depending on the overall depth desired for the knowledge base.\n",
    "    Example: \"Supervised Learning Algorithms\" (within Machine Learning), \"Bone Fractures\" (within Skeletal System), \"The Battle of Stalingrad\" (within World War II)\n",
    "\n",
    "### Level 4: Detailed / Sub-Topic\n",
    "\n",
    "    Name: Sub-Topic / Concept\n",
    "    Instruction: Assign this level if the subject represents a clearly defined concept, method, or component within a more specific topic. It's getting close to a \"leaf node\" for many knowledge bases, though very granular details might still exist. Further decomposition might involve breaking down a process into steps, a concept into its defining attributes, or a component into its sub-components.\n",
    "    Example: \"Support Vector Machines\" (within Supervised Learning Algorithms), \"Types of Fractures\" (within Bone Fractures), \"German Strategy at Stalingrad\" (within The Battle of Stalingrad)\n",
    "\n",
    "### Level 5: Very Detailed / Atomic Unit\n",
    "\n",
    "    Name: Atomic Detail / Granular Fact\n",
    "    Instruction: Assign this level if the subject represents a highly specific piece of information, a single concept, a particular definition, or a very specific technique. It's unlikely to be further decomposed in a meaningful way for most knowledge bases, serving as a \"leaf node\" or a specific data point. It represents the smallest practical unit of information for the current scope.\n",
    "    Example: \"Kernel Trick in SVMs\" (within Support Vector Machines), \"Greenstick Fracture Definition\" (within Types of Fractures), \"Operation Uranus\" (within German Strategy at Stalingrad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d697c",
   "metadata": {},
   "source": [
    "Think of every research path as a node of knowledge graph for specified book. Add to every point of listed directions node classification using categories:\n",
    "\n",
    "1. **container** \n",
    "- purpose: Node will be used just as a parent node to its list of outputs. It won't have its own content.\n",
    "- research objective: Specify directly what kind of items are expected to be placed under this node. Do not specify what future child nodes should contain, just what they should be.\n",
    "- examples: \"ML classification techniques\", \"Flower species\", \"Programming languages\"\n",
    "2. **concept**\n",
    "- purpose: Node will contain a concept, definition, or explanation of a specific term or idea. It can be still connected with some child nodes later.\n",
    "- research objective: Specify what should be included in its content, such as definitions, explanations, and examples.\n",
    "- examples: \"Neural networks\", \"Photosynthesis\", \"Object-oriented programming\"\n",
    "3. **analysis**\n",
    "- purpose: Node will contain an analysis of a specific topic, including comparisons, evaluations, or assessments. The role of this node is to provide extended insights into container or concept nodes.\n",
    "- research objective: Specify the purpose of the analysis, such as comparing different approaches, evaluating effectiveness, assessing implications etc.. If your are able to at this point also write steps of reasoning.\n",
    "- examples: \"Comparison of ML algorithms\", \"Evaluation of renewable energy sources\", \"Limitations of JavaScript\"\n",
    "\n",
    "---\n",
    "\n",
    "Rewrite your adding category to every research task and refine research objectives to fit description of assigned category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42a91551",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'job': 'Prepare a list of 6 to 8 potential chapters for a guide book on Prompt Engineering Techniques: from beginner to advanced',\n",
    "    'restrictions': \"\"\"\n",
    "    1. The chapters should be suitable for a beginner to advanced audience\n",
    "    2. Focus primarily on actual prompting techniques, not just general concepts\n",
    "    3. Ignore any chapters that are just applications of those techniques\n",
    "    \"\"\",\n",
    "    'output_format': 'List of chapters with very short description of each chapter',\n",
    "    'data': 'None'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b883079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.cfg.precompiled import get_llm, get_checkpointer\n",
    "from fcgb.tools.spectools import PhantomResearcherSpecTool, JobHandlerSpecTool, JobHandler\n",
    "from fcgb.cfg.chat_inputs_spec import PlannedIterativeTaskSolverConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc2911f",
   "metadata": {},
   "source": [
    "## Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b172b9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_llm = get_llm(llm_model='fake')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')\n",
    "\n",
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=fake_llm, memory=memory)\n",
    "]\n",
    "\n",
    "job_handler = JobHandlerSpecTool(\n",
    "    llm=fake_llm,\n",
    "    tool_containers=tool_containers,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf4888aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_solver = PlannedIterativeTaskSolver(\n",
    "    llm=fake_llm,\n",
    "    job_handler=job_handler,\n",
    "    initial_messages_spec=PlannedIterativeTaskSolverConfig.initial_messages_spec,\n",
    "    internal_messages_spec=PlannedIterativeTaskSolverConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    init_values=PlannedIterativeTaskSolverConfig.init_values,\n",
    "    prompt_manager_spec=PlannedIterativeTaskSolverConfig.prompt_manager_spec,\n",
    "    global_inputs=PlannedIterativeTaskSolverConfig.global_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65310a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning turn 1...\n",
      "Jobs Distribution turn 1...\n",
      "Job Execution turn 1: Fake string zoopt...\n",
      "Job Execution turn 1: Fake string jcbhf...\n",
      "Job Execution turn 1: Fake string bxnxx...\n",
      "Job Execution turn 1: Fake string xxuzp...\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Base Extension turn 1...\n",
      "Planning turn 2...\n",
      "Process End Routing turn 2...\n",
      "Reporting turn 2...\n",
      "Fake LLM response 51\n"
     ]
    }
   ],
   "source": [
    "output = task_solver.run(**inputs)\n",
    "\n",
    "# Final Report\n",
    "for line in output['output'].split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271d5cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'template_inputs': {'job': 'List all Chain-of-Thought prompting variants',\n",
       "  'restrictions': '\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting',\n",
       "  'output_format': 'List of techniques with very short description of each technique',\n",
       "  'data': 'None'},\n",
       " 'turns': 4,\n",
       " 'knowledge_base': 'Fake LLM response 138',\n",
       " 'current_messages': [],\n",
       " 'current_jobs': [],\n",
       " 'current_jobs_outputs': [],\n",
       " 'all_messages': [SystemMessage(content=\"# **CONVERSATION PURPOSE**\\n\\nThis conversation aims to:\\n\\n1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\\n2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\\n3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\\n\\n---\\n\\n# **WORKFLOW OVERVIEW**\\n\\n## **Workflow nodes**\\nEach node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\\n- Task Specification: The user provides the main task description and all necessary details.\\n- Analysis: Assess the current report state and formulate further research directions.\\n- Jobs Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\\n- Jobs Execution: Agents execute the assigned jobs, gathering data and insights.\\n- Report Extension: Integrate collected results from agents to enrich report.\\n- Final Check: Final answer formulation including verification in relation to given restrictions.\\n\\n## **Workflow Schema**\\nThe workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\\n\\n**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Check**\\n\\n---\\n\\n# **AVAILABLE AGENTS**\\n- **external_research**: Conducts web searches including academic papers, news, and other online resources.\", additional_kwargs={}, response_metadata={}, name='system'),\n",
       "  HumanMessage(content='# **TASK DESCRIPTION**\\n\\n## **MAIN TASK** \\n*Here is the main goal of the task:*\\nList all Chain-of-Thought prompting variants\\n\\n## **RESTRICTIONS** \\n*At every stage of the process bear in mind the following restrictions:*\\n\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting\\n\\n## **OUTPUT FORMAT** \\n*The final report should be written in the following format:*\\nList of techniques with very short description of each technique\\n\\n## **CONTEXTUAL DATA** \\n*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\\n```\\nNone\\n```', additional_kwargs={}, response_metadata={}, name='query'),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Analysis** phase of research process.\\n    * Task Specification\\n    -> Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    * Report Extension\\n    * Final Check\\n\\n## **ANALYSIS STEPS**\\n\\n1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\\n    - *evaluate current completion level of the report*\\n    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\\n    - *point missing information*\\n    - *point irrelevant or doubtful information*\\n\\n2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\\n    - *Strategy description: Provide an overview of the overall research approach.*\\n    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\\n    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\\n    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\\n    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\\n    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\\n    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\\n    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\\n\\n3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\\n    - *collect research objectives as simple list based on prior analysis steps*\\n\\n---\\n\\n## **ANALYSIS INSTRUCTIONS**\\n- use descriptive style\\n- follow directly provided analysis steps and output format\\n- perform every action in terms of realization of the main task\\n- focus explicitly on paths that will enrich the report\\n\\n---\\n\\n## **ANALYSIS OUTPUT FORMAT**\\n```\\n### **STATE SUMMARY**\\n[current report state evaluation]\\n\\n### **STRATEGICAL REASONING**\\n\\n#### Strategy description\\n[strategical reasoning description]\\n\\n#### Validation\\n[explanation of how the current report state may not be compatible with the restrictions or main task goal]\\n\\n#### Existing areas expansion\\n[explanation of how existing areas should be expanded or clarified]\\n\\n#### New areas exploration\\n[explanation of possible new areas to explore]\\n\\n### **THESES FORMULATION**\\n- [thesis 1]\\n- [thesis 2]\\n...\\n- [thesis N]\\n```\\n\\n---\\n\\n## **REPORT STATE**\\nEmpty', additional_kwargs={}, response_metadata={}, name='planning'),\n",
       "  AIMessage(content='Fake LLM response 91', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Report Extension** phase of research process.\\n    * Task Specification\\n    * Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    -> Report Extension\\n    * Final Check\\n\\n## **REPORT EXTENSION PHASE DESCRIPTION**\\nThis phase is responsible for integrating the results from the Jobs Execution phase into the report content.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION INSTRUCTIONS**\\n- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\\n- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\\n- **Follow output format**: Use the provided output format to structure the report and action logs.\\n- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\\n\\nKnowledge base consist of 2 main parts:\\n- **report**: Current output report proposition which addresses MAIN TASK.\\n- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\\n\\n**Output format:**\\n```\\n<report>\\n[enriched report content]\\n</report>\\n<actions>\\n### **ACTION LOGS**\\n| Job Title | Action Type | Description |\\n| --- | --- | --- |\\n| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\\n| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\\n| ... | ... | ... |\\n</actions>\\n```\\n---\\n\\n## **REPORT STATE**\\nEmpty\\n\\n---\\n\\n## **COLLECTED NEW DATA**\\nFake LLM response 97\\n-----\\nFake LLM response 46\\n-----\\nFake LLM response 47\\n\\n---\\n\\n## **JOBS**\\nThese are the jobs from the current iteration:\\nJob 1: Fake string vlroo\\nJob 2: Fake string wmdar\\nJob 3: Fake string wlkez\\n\\n---\\n\\n## **RESTRICTIONS**\\n\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting\\n\\n', additional_kwargs={}, response_metadata={}, name='base_extension'),\n",
       "  AIMessage(content='Fake LLM response 98', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Analysis** phase of research process.\\n    * Task Specification\\n    -> Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    * Report Extension\\n    * Final Check\\n\\n## **ANALYSIS STEPS**\\n\\n1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\\n    - *evaluate current completion level of the report*\\n    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\\n    - *point missing information*\\n    - *point irrelevant or doubtful information*\\n\\n2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\\n    - *Strategy description: Provide an overview of the overall research approach.*\\n    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\\n    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\\n    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\\n    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\\n    - *take into account that this is an iterative research process and you are currently at 2 turn of maximum 4 iterations*\\n    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\\n    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\\n\\n3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\\n    - *collect research objectives as simple list based on prior analysis steps*\\n\\n---\\n\\n## **ANALYSIS INSTRUCTIONS**\\n- use descriptive style\\n- follow directly provided analysis steps and output format\\n- perform every action in terms of realization of the main task\\n- focus explicitly on paths that will enrich the report\\n\\n---\\n\\n## **ANALYSIS OUTPUT FORMAT**\\n```\\n### **STATE SUMMARY**\\n[current report state evaluation]\\n\\n### **STRATEGICAL REASONING**\\n\\n#### Strategy description\\n[strategical reasoning description]\\n\\n#### Validation\\n[explanation of how the current report state may not be compatible with the restrictions or main task goal]\\n\\n#### Existing areas expansion\\n[explanation of how existing areas should be expanded or clarified]\\n\\n#### New areas exploration\\n[explanation of possible new areas to explore]\\n\\n### **THESES FORMULATION**\\n- [thesis 1]\\n- [thesis 2]\\n...\\n- [thesis N]\\n```\\n\\n---\\n\\n## **REPORT STATE**\\nFake LLM response 98', additional_kwargs={}, response_metadata={}, name='planning'),\n",
       "  AIMessage(content='Fake LLM response 99', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Report Extension** phase of research process.\\n    * Task Specification\\n    * Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    -> Report Extension\\n    * Final Check\\n\\n## **REPORT EXTENSION PHASE DESCRIPTION**\\nThis phase is responsible for integrating the results from the Jobs Execution phase into the report content.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION INSTRUCTIONS**\\n- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\\n- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\\n- **Follow output format**: Use the provided output format to structure the report and action logs.\\n- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\\n\\nKnowledge base consist of 2 main parts:\\n- **report**: Current output report proposition which addresses MAIN TASK.\\n- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\\n\\n**Output format:**\\n```\\n<report>\\n[enriched report content]\\n</report>\\n<actions>\\n### **ACTION LOGS**\\n| Job Title | Action Type | Description |\\n| --- | --- | --- |\\n| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\\n| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\\n| ... | ... | ... |\\n</actions>\\n```\\n---\\n\\n## **REPORT STATE**\\nFake LLM response 98\\n\\n---\\n\\n## **COLLECTED NEW DATA**\\nFake LLM response 53\\n-----\\nFake LLM response 114\\n-----\\nFake LLM response 113\\n\\n---\\n\\n## **JOBS**\\nThese are the jobs from the current iteration:\\nJob 1: Fake string sfxjf\\nJob 2: Fake string hfvrl\\nJob 3: Fake string sggsv\\n\\n---\\n\\n## **RESTRICTIONS**\\n\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting\\n\\n', additional_kwargs={}, response_metadata={}, name='base_extension'),\n",
       "  AIMessage(content='Fake LLM response 115', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Analysis** phase of research process.\\n    * Task Specification\\n    -> Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    * Report Extension\\n    * Final Check\\n\\n## **ANALYSIS STEPS**\\n\\n1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\\n    - *evaluate current completion level of the report*\\n    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\\n    - *point missing information*\\n    - *point irrelevant or doubtful information*\\n\\n2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\\n    - *Strategy description: Provide an overview of the overall research approach.*\\n    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\\n    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\\n    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\\n    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\\n    - *take into account that this is an iterative research process and you are currently at 3 turn of maximum 4 iterations*\\n    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\\n    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\\n\\n3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\\n    - *collect research objectives as simple list based on prior analysis steps*\\n\\n---\\n\\n## **ANALYSIS INSTRUCTIONS**\\n- use descriptive style\\n- follow directly provided analysis steps and output format\\n- perform every action in terms of realization of the main task\\n- focus explicitly on paths that will enrich the report\\n\\n---\\n\\n## **ANALYSIS OUTPUT FORMAT**\\n```\\n### **STATE SUMMARY**\\n[current report state evaluation]\\n\\n### **STRATEGICAL REASONING**\\n\\n#### Strategy description\\n[strategical reasoning description]\\n\\n#### Validation\\n[explanation of how the current report state may not be compatible with the restrictions or main task goal]\\n\\n#### Existing areas expansion\\n[explanation of how existing areas should be expanded or clarified]\\n\\n#### New areas exploration\\n[explanation of possible new areas to explore]\\n\\n### **THESES FORMULATION**\\n- [thesis 1]\\n- [thesis 2]\\n...\\n- [thesis N]\\n```\\n\\n---\\n\\n## **REPORT STATE**\\nFake LLM response 115', additional_kwargs={}, response_metadata={}, name='planning'),\n",
       "  AIMessage(content='Fake LLM response 116', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Report Extension** phase of research process.\\n    * Task Specification\\n    * Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    -> Report Extension\\n    * Final Check\\n\\n## **REPORT EXTENSION PHASE DESCRIPTION**\\nThis phase is responsible for integrating the results from the Jobs Execution phase into the report content.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION INSTRUCTIONS**\\n- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\\n- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\\n- **Follow output format**: Use the provided output format to structure the report and action logs.\\n- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\\n\\nKnowledge base consist of 2 main parts:\\n- **report**: Current output report proposition which addresses MAIN TASK.\\n- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\\n\\n**Output format:**\\n```\\n<report>\\n[enriched report content]\\n</report>\\n<actions>\\n### **ACTION LOGS**\\n| Job Title | Action Type | Description |\\n| --- | --- | --- |\\n| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\\n| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\\n| ... | ... | ... |\\n</actions>\\n```\\n---\\n\\n## **REPORT STATE**\\nFake LLM response 115\\n\\n---\\n\\n## **COLLECTED NEW DATA**\\nFake LLM response 125\\n\\n---\\n\\n## **JOBS**\\nThese are the jobs from the current iteration:\\nJob 1: Fake string agtmb\\n\\n---\\n\\n## **RESTRICTIONS**\\n\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting\\n\\n', additional_kwargs={}, response_metadata={}, name='base_extension'),\n",
       "  AIMessage(content='Fake LLM response 126', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Analysis** phase of research process.\\n    * Task Specification\\n    -> Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    * Report Extension\\n    * Final Check\\n\\n## **ANALYSIS STEPS**\\n\\n1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\\n    - *evaluate current completion level of the report*\\n    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\\n    - *point missing information*\\n    - *point irrelevant or doubtful information*\\n\\n2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\\n    - *Strategy description: Provide an overview of the overall research approach.*\\n    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\\n    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\\n    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\\n    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\\n    - *take into account that this is an iterative research process and you are currently at 4 turn of maximum 4 iterations*\\n    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\\n    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\\n\\n3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\\n    - *collect research objectives as simple list based on prior analysis steps*\\n\\n---\\n\\n## **ANALYSIS INSTRUCTIONS**\\n- use descriptive style\\n- follow directly provided analysis steps and output format\\n- perform every action in terms of realization of the main task\\n- focus explicitly on paths that will enrich the report\\n\\n---\\n\\n## **ANALYSIS OUTPUT FORMAT**\\n```\\n### **STATE SUMMARY**\\n[current report state evaluation]\\n\\n### **STRATEGICAL REASONING**\\n\\n#### Strategy description\\n[strategical reasoning description]\\n\\n#### Validation\\n[explanation of how the current report state may not be compatible with the restrictions or main task goal]\\n\\n#### Existing areas expansion\\n[explanation of how existing areas should be expanded or clarified]\\n\\n#### New areas exploration\\n[explanation of possible new areas to explore]\\n\\n### **THESES FORMULATION**\\n- [thesis 1]\\n- [thesis 2]\\n...\\n- [thesis N]\\n```\\n\\n---\\n\\n## **REPORT STATE**\\nFake LLM response 126', additional_kwargs={}, response_metadata={}, name='planning'),\n",
       "  AIMessage(content='Fake LLM response 127', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Report Extension** phase of research process.\\n    * Task Specification\\n    * Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    -> Report Extension\\n    * Final Check\\n\\n## **REPORT EXTENSION PHASE DESCRIPTION**\\nThis phase is responsible for integrating the results from the Jobs Execution phase into the report content.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION INSTRUCTIONS**\\n- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\\n- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\\n- **Follow output format**: Use the provided output format to structure the report and action logs.\\n- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\\n\\n---\\n\\n## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\\n\\nKnowledge base consist of 2 main parts:\\n- **report**: Current output report proposition which addresses MAIN TASK.\\n- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\\n\\n**Output format:**\\n```\\n<report>\\n[enriched report content]\\n</report>\\n<actions>\\n### **ACTION LOGS**\\n| Job Title | Action Type | Description |\\n| --- | --- | --- |\\n| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\\n| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\\n| ... | ... | ... |\\n</actions>\\n```\\n---\\n\\n## **REPORT STATE**\\nFake LLM response 126\\n\\n---\\n\\n## **COLLECTED NEW DATA**\\nFake LLM response 64\\n-----\\nFake LLM response 68\\n-----\\nFake LLM response 66\\n-----\\nFake LLM response 137\\n\\n---\\n\\n## **JOBS**\\nThese are the jobs from the current iteration:\\nJob 1: Fake string ajlaw\\nJob 2: Fake string frzvt\\nJob 3: Fake string klgba\\nJob 4: Fake string rgyxx\\n\\n---\\n\\n## **RESTRICTIONS**\\n\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting\\n\\n', additional_kwargs={}, response_metadata={}, name='base_extension'),\n",
       "  AIMessage(content='Fake LLM response 138', additional_kwargs={}, response_metadata={})],\n",
       " 'all_jobs': [JobModel(job='Fake string vlroo', restrictions='Fake string ipeqb', output_format='Fake string yzscb', variables=['restrictions', 'knowledge_base', 'knowledge_base']),\n",
       "  JobModel(job='Fake string wmdar', restrictions='Fake string ugyqe', output_format='Fake string ehzoc', variables=['knowledge_base', 'restrictions', 'restrictions']),\n",
       "  JobModel(job='Fake string wlkez', restrictions='Fake string sacco', output_format='Fake string rggps', variables=['knowledge_base', 'knowledge_base', 'knowledge_base', 'restrictions']),\n",
       "  JobModel(job='Fake string sfxjf', restrictions='Fake string fymwn', output_format='Fake string uaddt', variables=['knowledge_base', 'restrictions', 'restrictions']),\n",
       "  JobModel(job='Fake string hfvrl', restrictions='Fake string zyhku', output_format='Fake string epoks', variables=['knowledge_base', 'restrictions', 'knowledge_base']),\n",
       "  JobModel(job='Fake string sggsv', restrictions='Fake string lolye', output_format='Fake string rzxbj', variables=['restrictions']),\n",
       "  JobModel(job='Fake string agtmb', restrictions='Fake string lrgvv', output_format='Fake string dffpb', variables=['restrictions', 'restrictions']),\n",
       "  JobModel(job='Fake string ajlaw', restrictions='Fake string rotmy', output_format='Fake string kfvkg', variables=['knowledge_base', 'knowledge_base', 'restrictions', 'knowledge_base']),\n",
       "  JobModel(job='Fake string frzvt', restrictions='Fake string dfddg', output_format='Fake string kugoj', variables=['restrictions', 'knowledge_base']),\n",
       "  JobModel(job='Fake string klgba', restrictions='Fake string njjgp', output_format='Fake string iflqx', variables=['knowledge_base', 'restrictions']),\n",
       "  JobModel(job='Fake string rgyxx', restrictions='Fake string gzggw', output_format='Fake string xctjs', variables=['knowledge_base', 'restrictions'])],\n",
       " 'output': 'Fake LLM response 139',\n",
       " 'thread_id': '532f06fb9e3e45f797d5800c2b58a404'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load whole task solver state\n",
    "research_state = task_solver.get_state(output['thread_id'])\n",
    "research_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "50c60155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: system\n",
      "\n",
      "# **CONVERSATION PURPOSE**\n",
      "\n",
      "This conversation aims to:\n",
      "\n",
      "1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\n",
      "2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\n",
      "3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\n",
      "\n",
      "---\n",
      "\n",
      "# **WORKFLOW OVERVIEW**\n",
      "\n",
      "## **Workflow nodes**\n",
      "Each node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\n",
      "- Task Specification: The user provides the main task description and all necessary details.\n",
      "- Analysis: Assess the current knowledge base and formulate further research directions.\n",
      "- Job Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\n",
      "- Report Extension: Integrate collected results from agents to expand the knowledge base.\n",
      "- Final Report: Compile the comprehensive knowledge base into a final report addressing the main task.\n",
      "\n",
      "## **Workflow Schema**\n",
      "The workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\n",
      "\n",
      "**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "# **AVAILABLE AGENTS**\n",
      "- **external_research**: Conducts web searches including academic papers, news, and other online resources.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **MAIN TASK** \n",
      "*Here is the main goal of the task:*\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "## **RESTRICTIONS** \n",
      "*At every stage of the process bear in mind the following restrictions:*\n",
      "\n",
      "    1. List only real prompting techniques\n",
      "    2. Do not include techniques that are just applications of other techniques\n",
      "    3. Do not include techniques that are not related to CoT prompting\n",
      "\n",
      "## **OUTPUT FORMAT** \n",
      "*The final report should be written in the following format:*\n",
      "List of techniques with very short description of each technique\n",
      "\n",
      "## **CONTEXTUAL DATA** \n",
      "*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\n",
      "```\n",
      "None\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Job Distribution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Empty\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 1\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **job**\n",
      "Here is the main goal of the task:\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "------------------\n",
      "\n",
      "# **KNOWLEDGE BASE**\n",
      "Empty\n",
      "\n",
      "------------------\n",
      "\n",
      "# **RETREIVED DATA**\n",
      "Fake LLM response 15\n",
      "-----\n",
      "Fake LLM response 14\n",
      "\n",
      "------------------\n",
      "\n",
      "# **JOBS**\n",
      "Job 1: Fake string vzyha\n",
      "Job 2: Fake string tjjnp\n",
      "\n",
      "------------------\n",
      "\n",
      "I'm collecting data to be able to prepare a raport for the described task.\n",
      "You have access to my current knowledge base and data I recently retreived.\n",
      "\n",
      "Your task is to extend my knowledge base with new information that will help me to prepare a final report.\n",
      "In your answer provide existing knowledge base with added relevant new information.\n",
      "Assure that you relate to the job's goals that were performed to gather retreived data.\n",
      "If any descriptions are unnecessary long or not relevant, please shorten them or remove them.\n",
      "Also try to keep it as concise as possible and avoid redundant data.\n",
      "\n",
      "Knowledge base should be divided into sections with titles. For section title use '##' markdown syntax.\n",
      "Your answer should contain only extended and properly formatted knowledge base without any additional comments or explanations.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 16\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Job Distribution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 2 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Fake LLM response 16\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 17\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **job**\n",
      "Here is the main goal of the task:\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "------------------\n",
      "\n",
      "# **KNOWLEDGE BASE**\n",
      "Fake LLM response 16\n",
      "\n",
      "------------------\n",
      "\n",
      "# **RETREIVED DATA**\n",
      "Fake LLM response 25\n",
      "-----\n",
      "Fake LLM response 9\n",
      "\n",
      "------------------\n",
      "\n",
      "# **JOBS**\n",
      "Job 1: Fake string pewvz\n",
      "Job 2: Fake string kvtqx\n",
      "\n",
      "------------------\n",
      "\n",
      "I'm collecting data to be able to prepare a raport for the described task.\n",
      "You have access to my current knowledge base and data I recently retreived.\n",
      "\n",
      "Your task is to extend my knowledge base with new information that will help me to prepare a final report.\n",
      "In your answer provide existing knowledge base with added relevant new information.\n",
      "Assure that you relate to the job's goals that were performed to gather retreived data.\n",
      "If any descriptions are unnecessary long or not relevant, please shorten them or remove them.\n",
      "Also try to keep it as concise as possible and avoid redundant data.\n",
      "\n",
      "Knowledge base should be divided into sections with titles. For section title use '##' markdown syntax.\n",
      "Your answer should contain only extended and properly formatted knowledge base without any additional comments or explanations.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 26\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Job Distribution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 3 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Fake LLM response 26\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 27\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **job**\n",
      "Here is the main goal of the task:\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "------------------\n",
      "\n",
      "# **KNOWLEDGE BASE**\n",
      "Fake LLM response 26\n",
      "\n",
      "------------------\n",
      "\n",
      "# **RETREIVED DATA**\n",
      "Fake LLM response 14\n",
      "-----\n",
      "Fake LLM response 35\n",
      "\n",
      "------------------\n",
      "\n",
      "# **JOBS**\n",
      "Job 1: Fake string dfvgs\n",
      "Job 2: Fake string aywvu\n",
      "\n",
      "------------------\n",
      "\n",
      "I'm collecting data to be able to prepare a raport for the described task.\n",
      "You have access to my current knowledge base and data I recently retreived.\n",
      "\n",
      "Your task is to extend my knowledge base with new information that will help me to prepare a final report.\n",
      "In your answer provide existing knowledge base with added relevant new information.\n",
      "Assure that you relate to the job's goals that were performed to gather retreived data.\n",
      "If any descriptions are unnecessary long or not relevant, please shorten them or remove them.\n",
      "Also try to keep it as concise as possible and avoid redundant data.\n",
      "\n",
      "Knowledge base should be divided into sections with titles. For section title use '##' markdown syntax.\n",
      "Your answer should contain only extended and properly formatted knowledge base without any additional comments or explanations.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 36\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Job Distribution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 4 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Fake LLM response 36\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 37\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **job**\n",
      "Here is the main goal of the task:\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "------------------\n",
      "\n",
      "# **KNOWLEDGE BASE**\n",
      "Fake LLM response 36\n",
      "\n",
      "------------------\n",
      "\n",
      "# **RETREIVED DATA**\n",
      "Fake LLM response 50\n",
      "-----\n",
      "Fake LLM response 19\n",
      "-----\n",
      "Fake LLM response 51\n",
      "\n",
      "------------------\n",
      "\n",
      "# **JOBS**\n",
      "Job 1: Fake string yeshs\n",
      "Job 2: Fake string xglbd\n",
      "Job 3: Fake string fgebu\n",
      "\n",
      "------------------\n",
      "\n",
      "I'm collecting data to be able to prepare a raport for the described task.\n",
      "You have access to my current knowledge base and data I recently retreived.\n",
      "\n",
      "Your task is to extend my knowledge base with new information that will help me to prepare a final report.\n",
      "In your answer provide existing knowledge base with added relevant new information.\n",
      "Assure that you relate to the job's goals that were performed to gather retreived data.\n",
      "If any descriptions are unnecessary long or not relevant, please shorten them or remove them.\n",
      "Also try to keep it as concise as possible and avoid redundant data.\n",
      "\n",
      "Knowledge base should be divided into sections with titles. For section title use '##' markdown syntax.\n",
      "Your answer should contain only extended and properly formatted knowledge base without any additional comments or explanations.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 52\n",
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: system\n",
      "\n",
      "# **CONVERSATION PURPOSE**\n",
      "\n",
      "This conversation aims to:\n",
      "\n",
      "1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\n",
      "2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\n",
      "3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\n",
      "\n",
      "---\n",
      "\n",
      "# **WORKFLOW OVERVIEW**\n",
      "\n",
      "## **Workflow nodes**\n",
      "Each node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\n",
      "- Task Specification: The user provides the main task description and all necessary details.\n",
      "- Analysis: Assess the current knowledge base and formulate further research directions.\n",
      "- Job Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\n",
      "- Report Extension: Integrate collected results from agents to expand the knowledge base.\n",
      "- Final Report: Compile the comprehensive knowledge base into a final report addressing the main task.\n",
      "\n",
      "## **Workflow Schema**\n",
      "The workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\n",
      "\n",
      "**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "# **AVAILABLE AGENTS**\n",
      "- **external_research**: Conducts web searches including academic papers, news, and other online resources.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **MAIN TASK** \n",
      "*Here is the main goal of the task:*\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "## **RESTRICTIONS** \n",
      "*At every stage of the process bear in mind the following restrictions:*\n",
      "\n",
      "    1. List only real prompting techniques\n",
      "    2. Do not include techniques that are just applications of other techniques\n",
      "    3. Do not include techniques that are not related to CoT prompting\n",
      "\n",
      "## **OUTPUT FORMAT** \n",
      "*The final report should be written in the following format:*\n",
      "List of techniques with very short description of each technique\n",
      "\n",
      "## **CONTEXTUAL DATA** \n",
      "*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\n",
      "```\n",
      "None\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Job Distribution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 5 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Fake LLM response 52\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 53\n"
     ]
    }
   ],
   "source": [
    "# All messages from the process\n",
    "for msg in research_state['all_messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0653a663",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1:\n",
      "Fake string pzixp\n",
      "Fake string xudic\n",
      "Fake string vvegy\n",
      "['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 2:\n",
      "Fake string rxiod\n",
      "Fake string reelv\n",
      "Fake string stjdj\n",
      "['knowledge_base']\n",
      "--------------------------------------------------\n",
      "Job 3:\n",
      "Fake string omsdr\n",
      "Fake string klkst\n",
      "Fake string lletu\n",
      "['knowledge_base']\n",
      "--------------------------------------------------\n",
      "Job 4:\n",
      "Fake string kvtoh\n",
      "Fake string ahehe\n",
      "Fake string nkznr\n",
      "['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 5:\n",
      "Fake string abixy\n",
      "Fake string obprb\n",
      "Fake string bjhty\n",
      "['knowledge_base', 'restrictions', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 6:\n",
      "Fake string ltbon\n",
      "Fake string vobqr\n",
      "Fake string qbhay\n",
      "['restrictions', 'knowledge_base', 'knowledge_base', 'knowledge_base']\n",
      "--------------------------------------------------\n",
      "Job 7:\n",
      "Fake string tukhl\n",
      "Fake string xpsty\n",
      "Fake string szfit\n",
      "['restrictions', 'knowledge_base', 'knowledge_base', 'knowledge_base']\n",
      "--------------------------------------------------\n",
      "Job 8:\n",
      "Fake string kyubv\n",
      "Fake string mxelj\n",
      "Fake string lxluj\n",
      "['knowledge_base']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# All delegated jobs\n",
    "for i,job in enumerate(research_state['all_jobs']):\n",
    "    print(f'Job {i+1}:')\n",
    "    print(job.job)\n",
    "    print(job.restrictions)\n",
    "    print(job.output_format)\n",
    "    print(job.variables)\n",
    "    print('-'*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "975f0c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 200,
       "width": 200
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "task_solver.display_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d592f2e3",
   "metadata": {},
   "source": [
    "## Real LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae332f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm(llm_model='google')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')\n",
    "\n",
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=llm, memory=memory)\n",
    "]\n",
    "\n",
    "job_handler = JobHandlerSpecTool(\n",
    "    llm=llm,\n",
    "    tool_containers=tool_containers,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b23fa0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_solver = PlannedIterativeTaskSolver(\n",
    "    llm=llm,\n",
    "    job_handler=job_handler,\n",
    "    initial_messages_spec=PlannedIterativeTaskSolverConfig.initial_messages_spec,\n",
    "    internal_messages_spec=PlannedIterativeTaskSolverConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    init_values=PlannedIterativeTaskSolverConfig.init_values,\n",
    "    prompt_manager_spec=PlannedIterativeTaskSolverConfig.prompt_manager_spec,\n",
    "    global_inputs=PlannedIterativeTaskSolverConfig.global_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf169a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning turn 1...\n",
      "Jobs Distribution turn 1...\n",
      "Job Execution turn 1: Research and describe core Chain-of-Thought prompting techniques, focusing on the original CoT paper and any widely recognized variations....\n",
      "Job Execution turn 1: Investigate Self-Consistency Decoding in the context of Chain-of-Thought prompting. Determine if it is considered a CoT variant or an independent decoding strategy....\n",
      "Job Execution turn 1: Explore Graph-based Chain-of-Thought prompting. Identify its key characteristics and how it extends the standard CoT approach....\n",
      "Job Execution turn 1: Research Program-aided Chain-of-Thought prompting. Describe how programs are used to aid the reasoning process in CoT....\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Base Extension turn 1...\n",
      "Planning turn 2...\n",
      "Process End Routing turn 2...\n",
      "Jobs Distribution turn 2...\n",
      "Job Execution turn 2: Determine if Self-Consistency is considered a prompting technique or primarily a decoding strategy in the context of Chain-of-Thought prompting....\n",
      "Job Execution turn 2: Research and provide detailed descriptions and examples for Standard CoT, Zero-Shot CoT, Least-to-Most Prompting, Graph-of-Thoughts, and Program-Aided Chain-of-Thought....\n",
      "Job Execution turn 2: Investigate Reflexion as a potential Chain-of-Thought variant. Determine if it qualifies as a distinct prompting technique....\n",
      "Job Execution turn 2: Research Chain of Hindsight and Plan-and-Solve Prompting as potential Chain-of-Thought variants. Determine if they qualify as distinct prompting techniques....\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Base Extension turn 2...\n",
      "Planning turn 3...\n",
      "Process End Routing turn 3...\n",
      "Jobs Distribution turn 3...\n",
      "Job Execution turn 3: Verify if Self-Consistency is a distinct prompting technique or primarily a decoding strategy. Focus on its relationship to Chain-of-Thought prompting....\n",
      "Job Execution turn 3: Investigate Plan-and-Solve prompting to determine if it is a distinct technique or an application of Least-to-Most prompting. Provide evidence and reasoning for your conclusion....\n",
      "Job Execution turn 3: Search for novel or recently developed Chain-of-Thought prompting variants in research papers and surveys published in the last 2 years. Focus on techniques not already listed in the knowledge base....\n",
      "Job Execution turn 3: For each technique currently in the knowledge base, explicitly state whether it is a distinct prompting technique or an application/modification of another technique. Provide a brief justification for each....\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Base Extension turn 3...\n",
      "Planning turn 4...\n",
      "Process End Routing turn 4...\n",
      "Jobs Distribution turn 4...\n",
      "Job Execution turn 4: Validate whether Self-Consistency with Chain-of-Thought is a distinct prompting technique or primarily a decoding strategy. If it is primarily a decoding strategy, explain why it was included and whether it should be removed based on the restrictions....\n",
      "Job Execution turn 4: For each technique in the knowledge base, verify the accuracy of the 'distinct or modification' notes against reliable sources (research papers, blog posts, etc.)....\n",
      "Job Execution turn 4: Expand the descriptions of Least-to-Most Prompting, Graph-of-Thoughts, and Program-Aided Chain-of-Thought with more specific implementation details and examples....\n",
      "Job Execution turn 4: Search for novel or advanced CoT prompting techniques not currently listed in the knowledge base. Prioritize techniques published or discussed in the last 1-2 years....\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Job execution end\n",
      "Base Extension turn 4...\n",
      "Reporting turn 4...\n",
      "\n",
      "---\n",
      "Final Report:\n",
      "\n",
      "\n",
      "List of Chain-of-Thought prompting variants:\n",
      "\n",
      "*   **Standard Chain-of-Thought (CoT) Prompting:** Providing a few examples demonstrating the reasoning process to arrive at the answer. This is the foundational technique upon which others are built.\n",
      "*   **Zero-Shot Chain-of-Thought Prompting:** Appending \"Let's think step by step\" to the prompt to encourage reasoning without explicit examples.\n",
      "*   **Least-to-Most Prompting:**\n",
      "    *   **Description:** Least-to-Most Prompting is a Chain-of-Thought variant designed to tackle complex problems by decomposing them into simpler, more manageable subproblems. The core idea is to first prompt the model to identify the necessary subproblems. Then, the model solves these subproblems sequentially, using the solutions to earlier subproblems as context for later ones. This method mirrors a human problem-solving approach, where complex tasks are broken down into smaller steps.\n",
      "    *   **Implementation Details:**\n",
      "        *   **Subproblem Identification Phase:** The initial prompt asks the LLM to list the subproblems required to solve the main problem. For example, \"To solve [complex problem], what are the necessary subproblems?\"\n",
      "        *   **Sequential Solving Phase:** Each subproblem is then presented to the LLM with the solutions to the previous subproblems included in the prompt. The prompt might look like this: \"You have solved [subproblem 1] with the answer [answer 1], and [subproblem 2] with the answer [answer 2]. Now solve [subproblem 3].\"\n",
      "        *   **Concatenation:** The solutions to all subproblems are then combined to form the final answer to the original complex problem.\n",
      "    *   **Example:**\n",
      "        *   **Complex Problem:** Solve the equation (a+b)^2 where a = (c+d)^2 and b = (e+f)^2, given c=1, d=2, e=3, and f=4.\n",
      "        *   **Subproblems Identified:**\n",
      "            1.  Calculate (c+d)^2.\n",
      "            2.  Calculate (e+f)^2.\n",
      "            3.  Calculate a+b.\n",
      "            4.  Calculate (a+b)^2.\n",
      "        *   **Sequential Solving:**\n",
      "            1.  Prompt: \"Calculate (c+d)^2 given c=1 and d=2.\" Model responds: \"9\".\n",
      "            2.  Prompt: \"Calculate (e+f)^2 given e=3 and f=4.\" Model responds: \"49\".\n",
      "            3.  Prompt: \"You know (c+d)^2 = 9 and (e+f)^2 = 49. Calculate a+b.\" Model responds: \"58\".\n",
      "            4.  Prompt: \"You know a+b = 58. Calculate (a+b)^2.\" Model responds: \"3364\".\n",
      "        *   **Final Answer:** 3364\n",
      "*   **Graph-of-Thoughts (GoT):**\n",
      "    *   **Description:** Graph-of-Thoughts extends the Chain-of-Thought approach by structuring the reasoning process as a graph, rather than a linear chain. Each node in the graph represents a \"thought,\" which can be an intermediate conclusion, a hypothesis, or a piece of evidence. Edges between nodes represent relationships between these thoughts, such as support, contradiction, or refinement. This structure allows the model to explore multiple reasoning paths concurrently and to revisit previous thoughts in light of new information.\n",
      "    *   **Implementation Details:**\n",
      "        *   **Thought Generation:** The initial prompt encourages the model to generate multiple initial thoughts related to the problem.\n",
      "        *   **Graph Construction:** Subsequent prompts guide the model to connect these thoughts, creating a graph structure. This involves identifying relationships between thoughts and creating edges accordingly.\n",
      "        *   **Evaluation and Selection:** The model evaluates the different reasoning paths within the graph and selects the most promising ones. This can involve assigning scores to nodes and edges based on their relevance and coherence.\n",
      "        *   **Iteration:** The model can iteratively refine the graph by adding new thoughts, modifying existing connections, or re-evaluating the reasoning paths.\n",
      "    *   **Example:**\n",
      "        *   **Problem:** Determine the main theme of a complex novel.\n",
      "        *   **Thought Generation:** The model generates initial thoughts such as: \"The novel explores themes of isolation,\" \"The protagonist struggles with identity,\" and \"The story critiques societal norms.\"\n",
      "        *   **Graph Construction:** The model connects these thoughts: \"Isolation is a consequence of the protagonist's struggle with identity,\" and \"The critique of societal norms contributes to the protagonist's isolation.\"\n",
      "        *   **Evaluation and Selection:** The model evaluates the paths and determines that the path connecting \"struggle with identity\" -> \"isolation\" -> \"critique of societal norms\" is the most coherent and relevant.\n",
      "        *   **Final Answer:** The main theme of the novel is the protagonist's struggle with identity, leading to isolation and a critique of societal norms.\n",
      "*   **Program-Aided Chain-of-Thought:**\n",
      "    *   **Description:** Program-Aided Chain-of-Thought integrates external programs or tools into the reasoning process of a large language model. Instead of relying solely on the LLM's internal knowledge and reasoning abilities, this approach allows the model to call upon external programs to perform specific tasks, such as calculations, data retrieval, or simulations. This can significantly enhance the accuracy and reliability of the reasoning process, especially for tasks that require specialized knowledge or skills.\n",
      "    *   **Implementation Details:**\n",
      "        *   **Tool Selection:** The prompt must instruct the LLM on which tools are available and when to use them. This requires a clear description of each tool's functionality and input/output format.\n",
      "        *   **Tool Invocation:** When the LLM encounters a step in the reasoning process that requires external computation or data retrieval, it generates a specific instruction to invoke the appropriate tool. This instruction includes the necessary input parameters.\n",
      "        *   **Result Integration:** The output from the external tool is then fed back into the LLM, which uses it to continue the reasoning process.\n",
      "        *   **Iterative Process:** The LLM can invoke multiple tools in sequence, using the results from one tool as input for another.\n",
      "    *   **Example:**\n",
      "        *   **Problem:** Calculate the area of a complex shape described in natural language.\n",
      "        *   **Tool Selection:** The LLM has access to a \"Shape Calculator\" tool that can calculate the area of various shapes given their dimensions.\n",
      "        *   **Tool Invocation:** The prompt describes a shape as \"a rectangle with a length of 10 meters and a width of 5 meters, with a semi-circle on top of the rectangle's width\". The LLM first uses its reasoning to decompose the shape into a rectangle and a semi-circle. Then, it invokes the \"Shape Calculator\" tool twice: once to calculate the area of the rectangle with length=10 and width=5, and once to calculate the area of the semi-circle with radius=2.5.\n",
      "        *   **Result Integration:** The \"Shape Calculator\" returns the area of the rectangle as 50 square meters and the area of the semi-circle as approximately 9.82 square meters. The LLM then adds these two areas together.\n",
      "        *   **Final Answer:** The area of the shape is approximately 59.82 square meters.\n",
      "*   **Reflexion:** Enhances language model reasoning through iterative self-reflection and refinement. The model evaluates its performance, identifies errors, and adjusts its reasoning in subsequent attempts. This introduces a feedback loop where the model reflects on its previous reasoning steps to improve future performance.\n",
      "*   **Chain-of-Hindsight (CoH):** Enhances LLM reasoning by incorporating a reflective step. It prompts the model to critique and refine its reasoning after generating an initial chain of thought.\n",
      "*   **Plan-and-Solve Prompting:** Improves LLM performance on complex tasks through a two-stage process: planning and solving. The LLM first creates a detailed plan and then executes it. This uses a two-stage process, planning and solving, for complex tasks.\n",
      "*   **Chain-of-Verification (CoVer):** Generates multiple reasoning chains and employs a verification mechanism to identify and correct factual errors or inconsistencies.\n",
      "*   **Tree-of-Thoughts (ToT):** Explores multiple reasoning paths in a tree structure, evaluating different thoughts at each step and branching out based on their potential.\n",
      "*   **Step-Back Prompting:** Encourages the language model to abstract away from the specifics of a given problem and consider a broader context before attempting to solve it.\n",
      "*   **Chain-of-Abstraction:** Encourages the model to create a series of increasingly abstract representations of the problem before attempting to solve it.\n",
      "*   **Automatic Prompt Engineer (APE)**: Automates the generation and selection of effective CoT prompts using a large language model and an evaluation strategy. This removes the need for manual prompt engineering.\n"
     ]
    }
   ],
   "source": [
    "output = task_solver.run(**inputs)\n",
    "\n",
    "# Final Report\n",
    "print(\"\\n---\\nFinal Report:\\n\\n\")\n",
    "for line in output['output'].split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "53870b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load whole task solver state\n",
    "research_state = task_solver.get_state(output['thread_id'])\n",
    "#research_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92eb7a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: system\n",
      "\n",
      "# **CONVERSATION PURPOSE**\n",
      "\n",
      "This conversation aims to:\n",
      "\n",
      "1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\n",
      "2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\n",
      "3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\n",
      "\n",
      "---\n",
      "\n",
      "# **WORKFLOW OVERVIEW**\n",
      "\n",
      "## **Workflow nodes**\n",
      "Each node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\n",
      "- Task Specification: The user provides the main task description and all necessary details.\n",
      "- Analysis: Assess the current report state and formulate further research directions.\n",
      "- Jobs Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\n",
      "- Jobs Execution: Agents execute the assigned jobs, gathering data and insights.\n",
      "- Report Extension: Integrate collected results from agents to enrich report.\n",
      "- Final Check: Final answer formulation including verification in relation to given restrictions.\n",
      "\n",
      "## **Workflow Schema**\n",
      "The workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\n",
      "\n",
      "**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Check**\n",
      "\n",
      "---\n",
      "\n",
      "# **AVAILABLE AGENTS**\n",
      "- **external_research**: Conducts web searches including academic papers, news, and other online resources.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **MAIN TASK** \n",
      "*Here is the main goal of the task:*\n",
      "You are constructing an initial level of a subjects tree-graph for a guide book defined in the additional_data section. Divide the main subject into up to 20 distinct subjects that will decompose the core ideas of the book.\n",
      "\n",
      "## **RESTRICTIONS** \n",
      "*At every stage of the process bear in mind the following restrictions:*\n",
      "\n",
      "    1. Use all information provided in the additional_data section\n",
      "    \n",
      "\n",
      "## **OUTPUT FORMAT** \n",
      "*The final report should be written in the following format:*\n",
      "\n",
      "    List of sections with titles, descriptions and relevance (how it refers to the book specification) in format:\n",
      "    Title: <title 1>\n",
      "    - Description: <description 1>\n",
      "    - Relevance: <relevance 1>\n",
      "    Title: <title 2>\n",
      "    - Description: <description 2>\n",
      "    - Relevance: <relevance 2>\n",
      "    ...\n",
      "    \n",
      "\n",
      "## **CONTEXTUAL DATA** \n",
      "*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\n",
      "```\n",
      "\n",
      "**BOOK SPECIFICATION:**\n",
      "{'main_title': 'About Prompt Engineering',\n",
      " 'initial_description': 'Guide should cover widely concepts of prompt engineering, with focus on specific prompt engineering techniques and their variations, \n",
      "try to cover as many of them as you can. Target audience is not defined, so potential readers would be as well non-technical as technical.\n",
      "Enrich every technique with examples. Write also something about how LLMs work, and how prompt engineering can help to improve their performance.',\n",
      " 'main_subject': 'Mastering prompt engineering techniques: a comprehensive guide for all skill levels',\n",
      " 'content_description': '*   Broad overview of prompt engineering techniques [essential]\n",
      "*   Comprehensive guide from beginner to expert [essential]\n",
      "*   Everything relevant to writing great and accurate prompts [essential]\n",
      "*   Detailed breakdown of techniques with multiple variations and real-world examples [essential]\n",
      "*   Information about how prompting may influence technical aspects of LLMs, covered within the introduction [moderate]\n",
      "*   Techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats [high]\n",
      "*   Detailed view of techniques like zero-shot prompting and chain-of-thought prompting [essential]\n",
      "*   Visual aids to augment every technique [essential]',\n",
      " 'style': \"*   Avoid industry-focused content [essential]\n",
      "*   Avoid overly formal language [essential]\n",
      "*   Humorous language is acceptable if it doesn't detract from credibility [moderate]\",\n",
      " 'target_audience': '*   Both non-technical and technical readers',\n",
      " 'layout': '*   Full-length book (200+ pages) [essential]\n",
      "*   Detailed view includes: formal definition, explanation of why it works, multiple examples, limitations/drawbacks, and variations [essential]',\n",
      " 'restrictions': ['*   No deep-dive into LLM architecture beyond the introduction [essential]']}\n",
      "\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\n",
      "    - *evaluate current completion level of the report*\n",
      "    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\n",
      "    - *point missing information*\n",
      "    - *point irrelevant or doubtful information*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\n",
      "    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\n",
      "    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\n",
      "    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths that will enrich the report\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "[current report state evaluation]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Validation\n",
      "[explanation of how the current report state may not be compatible with the restrictions or main task goal]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded or clarified]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "Empty\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "The report state is currently empty, indicating that no sections or topics have been defined yet for the subject tree-graph of the prompt engineering guidebook. Therefore, there are no gaps or irrelevant information to point out at this stage. We need to start from scratch, keeping the main task and restrictions in mind.\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "The initial strategy will focus on breaking down the broad subject of \"Mastering prompt engineering techniques\" into its fundamental components. This involves identifying key areas within prompt engineering, such as the basics of how LLMs work (introduction), core prompting techniques, advanced prompting strategies, and practical applications. The approach will prioritize the \"essential\" elements outlined in the content description and adhere to the style guidelines. We will start with a high-level overview and then delve into specific techniques and their variations in subsequent iterations.\n",
      "\n",
      "#### Validation\n",
      "Since the report is currently empty, there's nothing to validate against the restrictions. However, as we progress, we need to ensure that we avoid deep dives into LLM architecture beyond the introduction, industry-focused content, and overly formal language. We will also need to ensure that any humorous language doesn't detract from credibility.\n",
      "\n",
      "#### Existing areas expansion\n",
      "Since no areas exist, there's nothing to expand. However, the initial sections will be designed to allow for future expansion with detailed examples, limitations, and variations of each technique, as specified in the book layout.\n",
      "\n",
      "#### New areas exploration\n",
      "The initial exploration will cover the following areas:\n",
      "\n",
      "1.  **Introduction to Prompt Engineering**: Defining prompt engineering, its importance, and its role in improving LLM performance. Briefly touch upon how LLMs work to provide context.\n",
      "2.  **Basic Prompting Techniques**: Covering fundamental techniques like zero-shot prompting, few-shot prompting, and providing clear instructions.\n",
      "3.  **Advanced Prompting Techniques**: Exploring more complex techniques like chain-of-thought prompting, tree-of-thought prompting, and self-consistency.\n",
      "4.  **Prompt Engineering for Specific Tasks**: Focusing on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats.\n",
      "5.  **Prompt Optimization and Evaluation**: Discussing methods for optimizing prompts and evaluating their performance.\n",
      "6.  **Limitations and Challenges of Prompt Engineering**: Addressing the drawbacks and potential issues with prompt engineering.\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- Research and define the core concepts of prompt engineering and its significance in the context of large language models.\n",
      "- Investigate and describe basic prompting techniques such as zero-shot, one-shot, and few-shot prompting, including examples.\n",
      "- Explore and explain advanced prompting techniques like chain-of-thought, tree-of-thought, and self-consistency prompting, providing examples.\n",
      "- Research and describe how prompt engineering can be used to improve factual accuracy in LLM outputs.\n",
      "- Investigate and explain how prompt engineering can be used to control the style and tone of LLM-generated text.\n",
      "- Research and describe how prompt engineering can be used to elicit creative content from LLMs.\n",
      "- Explore and explain how prompt engineering can be used to enhance reasoning and problem-solving abilities in LLMs.\n",
      "- Research and describe how prompt engineering can be used to generate different content formats (e.g., code, poems, scripts).\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Report Extension** phase of research process.\n",
      "    * Task Specification\n",
      "    * Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    -> Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **REPORT EXTENSION PHASE DESCRIPTION**\n",
      "This phase is responsible for integrating the results from the Jobs Execution phase into the report content.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION INSTRUCTIONS**\n",
      "- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\n",
      "- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\n",
      "- **Follow output format**: Use the provided output format to structure the report and action logs.\n",
      "- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\n",
      "\n",
      "Knowledge base consist of 2 main parts:\n",
      "- **report**: Current output report proposition which addresses MAIN TASK.\n",
      "- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\n",
      "\n",
      "**Output format:**\n",
      "```\n",
      "<report>\n",
      "[enriched report content]\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\n",
      "| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\n",
      "| ... | ... | ... |\n",
      "</actions>\n",
      "```\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "Empty\n",
      "\n",
      "---\n",
      "\n",
      "## **COLLECTED NEW DATA**\n",
      "**Prompt Engineering: Definition, Significance, and LLM Overview**\n",
      "\n",
      "Prompt engineering is the art and science of crafting effective prompts (or instructions) that guide large language models (LLMs) to generate desired outputs. Think of it as carefully formulating your questions or requests to get the most relevant and accurate answers from an AI. Key aspects include clarity, context, instruction format, and iterative refinement.\n",
      "\n",
      "Prompt engineering is crucial because the quality of the prompt directly determines the quality of the LLM's output. It allows us to control output, improve accuracy, unlock the potential of LLMs, and improve cost efficiency.\n",
      "\n",
      "LLMs are complex neural networks trained on massive text datasets. They learn to predict the probability of the next word in a sequence. When you provide a prompt, the LLM converts it into a numerical representation and uses its learned knowledge to predict the most likely sequence of words that should follow, generating a coherent response.\n",
      "-----\n",
      "# Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "\n",
      "### Zero-Shot Prompting\n",
      "\n",
      "**Definition:** Zero-shot prompting involves instructing a language model to perform a task without providing any specific examples of how to complete that task. The model relies solely on its pre-existing knowledge and understanding of language to generate an appropriate response.\n",
      "\n",
      "**Explanation:** This technique works because large language models are trained on vast amounts of text data, enabling them to develop a broad understanding of various concepts, relationships, and patterns. When given a prompt, the model leverages this pre-existing knowledge to infer the desired output, even without explicit examples. The model essentially applies its general knowledge to a new, unseen task.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "*   **Prompt:** Translate \"hello\" to French.\n",
      "*   **Expected Output:** Bonjour.\n",
      "\n",
      "### One-Shot Prompting\n",
      "\n",
      "**Definition:** One-shot prompting involves providing a single example of the desired input-output relationship to guide the language model. This single example demonstrates the task and format expected in the response.\n",
      "\n",
      "**Explanation:** By providing one example, the model can better understand the task's requirements and the desired style or format of the output. This technique helps to reduce ambiguity and ground the model's response in a specific context. The model learns from the single instance and applies that learning to generate similar outputs for new inputs.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "*   **Prompt:** English: happy, French: content. English: sad, French:\n",
      "*   **Expected Output:** triste.\n",
      "\n",
      "### Few-Shot Prompting\n",
      "\n",
      "**Definition:** Few-shot prompting involves providing a language model with a small number of examples (typically between 2 and 10) that demonstrate the desired task and output format. These examples serve as a learning set for the model.\n",
      "\n",
      "**Explanation:** Few-shot prompting enhances the model's ability to generalize and perform the task accurately compared to zero-shot or one-shot prompting. By seeing multiple examples, the model can better discern the underlying patterns, rules, or relationships relevant to the task. This reduces the risk of the model latching onto irrelevant details from a single example and improves the consistency and quality of the generated outputs.\n",
      "\n",
      "**Example:**\n",
      "\n",
      "*   **Prompt:**\n",
      "\n",
      "    English: cat, Spanish: gato\n",
      "\n",
      "    English: dog, Spanish: perro\n",
      "\n",
      "    English: bird, Spanish: pjaro\n",
      "\n",
      "    English: house, Spanish:\n",
      "*   **Expected Output:** casa\n",
      "-----\n",
      "Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "\n",
      "**1. Chain-of-Thought (CoT) Prompting**\n",
      "\n",
      "*   **Definition:** Guiding a language model to think step-by-step through a problem before giving the final answer.\n",
      "*   **Explanation:** Unlocks memorized knowledge by providing a structured way to access it. Breaks down complex problems into smaller steps, improving accuracy.\n",
      "*   **Example:**\n",
      "    *   **Problem:** \"The cafeteria had 23 apples. If they used 20 for lunch and bought 6 more, how many apples do they have?\"\n",
      "    *   **With CoT:** \"The cafeteria started with 23 apples. They used 20, so 23 - 20 = 3 apples left. Then they bought 6 more, so 3 + 6 = 9. Answer: 9\"\n",
      "\n",
      "**2. Tree-of-Thought (ToT) Prompting**\n",
      "\n",
      "*   **Definition:** Allows the model to explore multiple reasoning paths at each step.\n",
      "*   **Explanation:** Useful for complex tasks requiring exploration and strategic decision-making. Enables backtracking and exploring alternative paths.\n",
      "*   **Example:** (Simplified)\n",
      "    *   **Problem:** \"Write a creative story opening about a mysterious door.\"\n",
      "    *   **ToT Approach:**\n",
      "        *   **Thought 1:** \"The door was old and wooden...\" (Evaluate: Generic)\n",
      "        *   **Thought 2:** \"A shimmering portal hung in the air, door-shaped...\" (Evaluate: Interesting, but needs more context)\n",
      "        *   **Thought 3:** \"The doorknob was made of bone...\" (Evaluate: Intriguing, unsettling)\n",
      "        *   **Selection:** Choose \"The doorknob was made of bone...\" and continue the story from there.\n",
      "\n",
      "**3. Self-Consistency Prompting**\n",
      "\n",
      "*   **Definition:** Generating multiple independent reasoning paths and selecting the most consistent answer.\n",
      "*   **Explanation:** Reduces the impact of random errors and improves robustness by leveraging the consistency across multiple reasoning attempts.\n",
      "*   **Example:**\n",
      "    *   **Problem:** \"What is the capital of Australia?\"\n",
      "    *   **CoT 1:** \"Australia is a country in Oceania. Its largest city is Sydney, but the capital is Canberra. Answer: Canberra.\"\n",
      "    *   **CoT 2:** \"Australia has many big cities. The capital is not Melbourne or Sydney. It is Canberra. Answer: Canberra.\"\n",
      "    *   **CoT 3:** \"The capital of Australia was moved from Melbourne to Canberra. Answer: Canberra.\"\n",
      "    *   **Self-Consistency:** Since \"Canberra\" appears consistently across all reasoning paths, it is selected as the final answer.\n",
      "-----\n",
      "**Prompt Engineering Applications in LLMs**\n",
      "\n",
      "**Factual Accuracy:** Prompt engineering improves factual accuracy through techniques like Chain-of-Thought prompting, Knowledge Integration via Retrieval-Augmented Generation (RAG), prompting with constraints, few-shot learning with verified examples, self-consistency checks, prompting for source attribution, and adversarial prompting. For example, using a CoT prompt such as \"To determine the capital of Australia, let's first consider the major cities in Australia. Sydney and Melbourne are large cities, but they are not the capital. Canberra is another city in Australia. Therefore, the capital of Australia is Canberra,\" guides the LLM to a more accurate answer.\n",
      "\n",
      "**Style/Tone:** Prompt engineering controls style and tone by incorporating specific instructions, keywords, or examples within the prompt. For example, a prompt like \"Compose a business letter addressing a client regarding overdue payments. Maintain a professional and courteous tone\" directs the LLM to adopt a formal tone, while \"Write a friendly email to a friend reminding them about the money they owe you. Keep it light and casual\" encourages an informal style.\n",
      "\n",
      "**Creative Content:** Prompt engineering elicits creative content by specifying the creative task, injecting a persona, providing constraints, using seed words, and iterative refinement. For example, \"You are a renowned science fiction author. Write the opening paragraph of a novel set on a distant planet, describing the protagonist's first encounter with an alien artifact\" encourages the LLM to generate creative content aligned with a specific persona and genre.\n",
      "\n",
      "**Reasoning/Problem-Solving:** Prompt engineering enhances reasoning and problem-solving through techniques like Chain-of-Thought prompting, zero-shot prompting, few-shot prompting, prompt chaining, self-consistency, and adding constraints. For example, a Chain-of-Thought prompt such as \"Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now? Let's think step by step. First, Roger starts with 5 balls. Second, he buys 2 cans * 3 balls/can = 6 balls. Third, he adds the new balls to his original balls: 5 balls + 6 balls = 11 balls. Answer: Roger has 11 tennis balls\" guides the LLM to solve the problem step-by-step.\n",
      "\n",
      "---\n",
      "\n",
      "## **JOBS**\n",
      "These are the jobs from the current iteration:\n",
      "Job 1: Research and define the core concepts of prompt engineering, its significance in the context of large language models, and briefly touch upon how LLMs work to provide context. Focus on providing a clear and concise definition suitable for both non-technical and technical readers.\n",
      "Job 2: Investigate and describe basic prompting techniques such as zero-shot, one-shot, and few-shot prompting. Provide formal definitions, explanations of why they work, and simple examples for each technique.\n",
      "Job 3: Explore and explain advanced prompting techniques like chain-of-thought, tree-of-thought, and self-consistency prompting. Provide formal definitions, explanations of why they work, and simple examples for each technique.\n",
      "Job 4: Research how prompt engineering can be applied to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving abilities in LLMs. Provide examples for each application.\n",
      "\n",
      "---\n",
      "\n",
      "## **RESTRICTIONS**\n",
      "\n",
      "    1. Use all information provided in the additional_data section\n",
      "    \n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "</actions>\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\n",
      "    - *evaluate current completion level of the report*\n",
      "    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\n",
      "    - *point missing information*\n",
      "    - *point irrelevant or doubtful information*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\n",
      "    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 2 turn of maximum 4 iterations*\n",
      "    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\n",
      "    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths that will enrich the report\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "[current report state evaluation]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Validation\n",
      "[explanation of how the current report state may not be compatible with the restrictions or main task goal]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded or clarified]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "</actions>\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "The current report state provides a foundational structure for the guidebook, covering introductory concepts, basic and advanced prompting techniques, and applications of prompt engineering in LLMs. It aligns well with the book specification's requirements for a broad overview, comprehensive guide, and detailed breakdown of techniques. However, there are gaps in terms of visual aids, limitations/drawbacks of techniques, variations of techniques, and specific guidance for different skill levels. The report also lacks a dedicated section on prompt variations and their impact.\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "The strategy is to expand upon the existing sections by adding more depth and breadth to the techniques discussed. This includes incorporating visual aids, discussing limitations and drawbacks, and exploring variations of each technique. Additionally, new sections will be introduced to address specific areas like prompt optimization, safety considerations, and the impact of different LLM architectures on prompt engineering. The approach will maintain a balance between technical and non-technical language, ensuring accessibility for all skill levels.\n",
      "\n",
      "#### Validation\n",
      "The current report state adheres to the restrictions by avoiding deep dives into LLM architecture beyond the introduction and refraining from overly formal or industry-focused content. However, the absence of visual aids needs to be addressed to fully comply with the book specification.\n",
      "\n",
      "#### Existing areas expansion\n",
      "The existing sections on basic and advanced prompting techniques can be expanded by:\n",
      "\n",
      "*   Adding visual aids (e.g., diagrams, flowcharts) to illustrate the techniques.\n",
      "*   Discussing the limitations and drawbacks of each technique.\n",
      "*   Providing more real-world examples and variations of each technique.\n",
      "*   Including a \"troubleshooting\" or \"best practices\" subsection for each technique.\n",
      "\n",
      "#### New areas exploration\n",
      "New areas to explore include:\n",
      "\n",
      "*   **Prompt Optimization Techniques:** Methods for refining prompts to improve performance (e.g., token length optimization, prompt compression).\n",
      "*   **Prompt Ensembling:** Combining multiple prompts to achieve better results.\n",
      "*   **Prompt Safety and Security:** Addressing potential risks associated with prompts, such as prompt injection and adversarial attacks.\n",
      "*   **Conditional Prompting:** Techniques for creating prompts that adapt to different contexts or user inputs.\n",
      "*   **The impact of LLM architecture on Prompt Engineering:** Briefly discuss how different LLM architectures (e.g., Transformers, RNNs) may influence the effectiveness of certain prompt engineering techniques.\n",
      "*   **Multi-modal Prompting**: How to use prompts with images, audio, and video.\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- Research prompt optimization techniques and their impact on LLM performance.\n",
      "- Investigate prompt ensembling methods and their benefits.\n",
      "- Explore prompt safety and security considerations, including prompt injection and adversarial attacks.\n",
      "- Examine conditional prompting techniques and their applications.\n",
      "- Research the impact of different LLM architectures on prompt engineering effectiveness.\n",
      "- Research multi-modal prompting and its applications.\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Report Extension** phase of research process.\n",
      "    * Task Specification\n",
      "    * Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    -> Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **REPORT EXTENSION PHASE DESCRIPTION**\n",
      "This phase is responsible for integrating the results from the Jobs Execution phase into the report content.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION INSTRUCTIONS**\n",
      "- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\n",
      "- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\n",
      "- **Follow output format**: Use the provided output format to structure the report and action logs.\n",
      "- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\n",
      "\n",
      "Knowledge base consist of 2 main parts:\n",
      "- **report**: Current output report proposition which addresses MAIN TASK.\n",
      "- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\n",
      "\n",
      "**Output format:**\n",
      "```\n",
      "<report>\n",
      "[enriched report content]\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\n",
      "| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\n",
      "| ... | ... | ... |\n",
      "</actions>\n",
      "```\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "</actions>\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **COLLECTED NEW DATA**\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "\n",
      "Prompt optimization techniques, including token length optimization and prompt compression, enhance LLM performance by reducing costs, improving response times, and increasing efficiency. Token length optimization focuses on using concise language and keyword extraction to shorten prompts, while prompt compression employs summarization and data encoding. Practical examples show measurable improvements, such as a 40% reduction in token usage for summarization tasks and a 50% reduction using summarization or embedding techniques. These optimizations lead to more scalable and cost-effective LLM applications, balancing brevity with informativeness and requiring experimentation to suit specific LLMs. The provided knowledge base details prompt engineering techniques like zero-shot, one-shot, few-shot, chain-of-thought, and tree-of-thought prompting, which can be integrated into optimization strategies for improved factual accuracy, style control, and reasoning abilities.\n",
      "-----\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "\n",
      "Prompt ensembling combines multiple prompts to get more reliable responses from language models. Strategies include simple averaging/voting, weighted averaging, prompt chaining, model selection, and self-consistency decoding.\n",
      "\n",
      "Advantages are improved accuracy, robustness, and creativity, and reduced sensitivity to prompt wording. Disadvantages include increased cost and complexity, potential for conflicting outputs, and difficulty in interpretation.\n",
      "\n",
      "Examples include content generation, question answering, code generation, and summarization. It's a powerful technique if prompts are designed carefully and the ensembling strategy fits the task.\n",
      "-----\n",
      "Title: Prompt Safety and Security Report\n",
      "\n",
      "### Prompt Safety and Security Risks\n",
      "\n",
      "*   **Input Validation and Sanitization:** Failure to properly validate and sanitize user inputs can lead to malicious commands or code being injected into the prompt.\n",
      "*   **Output Monitoring and Filtering:** Lack of monitoring and filtering of the language model's outputs can allow prompt injection attempts to go undetected.\n",
      "*   **Principle of Least Privilege:** Overly permissive access to sensitive data and functionalities can be exploited through prompt injection.\n",
      "*   **Sandboxing or Containerization:** Absence of sandboxing or containerization can allow prompt injection attacks to compromise other system components.\n",
      "\n",
      "### Mitigation Techniques\n",
      "\n",
      "*   **Input Sanitization and Validation:** Implement rigorous input sanitization to neutralize potentially harmful characters or commands. Employ whitelisting techniques, allowing only expected and safe inputs. Validate input length, format, and content against predefined rules to prevent malicious code injection.\n",
      "*   **Prompt Hardening:** Design prompts that are less susceptible to manipulation. Use clear, unambiguous instructions and avoid open-ended prompts that invite exploitation. Structure prompts to explicitly define the expected input format and output behavior.\n",
      "*   **Output Monitoring and Filtering:** Monitor the AI model's output for suspicious patterns or deviations from expected responses. Implement filters to block or modify outputs that contain sensitive information, malicious code, or harmful content.\n",
      "*   **Sandboxing and Isolation:** Run the AI model in a sandboxed environment to limit its access to sensitive resources and prevent it from executing arbitrary code. Isolate the model from critical systems and data to minimize the impact of successful prompt injection attacks.\n",
      "\n",
      "### Best Practices for Developing Secure Prompts\n",
      "\n",
      "*   **Input Sanitization:** Treat all user inputs as potentially malicious. Implement strict input validation and sanitization techniques to prevent prompt injection attacks.\n",
      "*   **Principle of Least Privilege:** Grant the LLM only the necessary permissions and access to data. Avoid giving it broad or unrestricted access.\n",
      "*   **Sandboxing/Isolation:** Run the LLM in a sandboxed environment to limit the potential damage if it is compromised.\n",
      "*   **Output Validation:** Validate the LLM's output to ensure it conforms to expected formats and doesn't contain sensitive information or malicious code.\n",
      "*   **Prompt Hardening:** Design prompts that are resistant to manipulation and injection attacks by providing clear instructions, setting context, assigning roles, and using delimiters.\n",
      "-----\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "\n",
      "Multi-modal prompting involves using various data modalities like text, images, audio, and video to get specific responses from LLMs. Techniques include concatenation, co-attention mechanisms, cross-modal embeddings, modality-specific tokens, and instruction tuning. Applications span image captioning, visual question answering, audio-visual scene understanding, video summarization, and cross-modal retrieval.\n",
      "\n",
      "---\n",
      "\n",
      "## **JOBS**\n",
      "These are the jobs from the current iteration:\n",
      "Job 1: Research prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. Focus on practical examples and measurable improvements.\n",
      "Job 2: Investigate prompt ensembling methods, including different ensembling strategies and their benefits in terms of accuracy, robustness, and creativity. Provide examples and potential drawbacks.\n",
      "Job 3: Explore prompt safety and security considerations, including prompt injection and adversarial attacks. Identify mitigation strategies and best practices for developing secure prompts.\n",
      "Job 4: Research multi-modal prompting techniques and their applications, focusing on how prompts can be used with images, audio, and video to elicit specific responses from LLMs. Provide examples and potential use cases.\n",
      "\n",
      "---\n",
      "\n",
      "## **RESTRICTIONS**\n",
      "\n",
      "    1. Use all information provided in the additional_data section\n",
      "    \n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "</actions>\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\n",
      "    - *evaluate current completion level of the report*\n",
      "    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\n",
      "    - *point missing information*\n",
      "    - *point irrelevant or doubtful information*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\n",
      "    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 3 turn of maximum 4 iterations*\n",
      "    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\n",
      "    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths that will enrich the report\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "[current report state evaluation]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Validation\n",
      "[explanation of how the current report state may not be compatible with the restrictions or main task goal]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded or clarified]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "</actions>\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "The current report provides a good initial structure for a guidebook on prompt engineering. It covers introductory concepts, basic and advanced prompting techniques, applications, optimization, ensembling, safety, and multi-modal prompting. The report aligns well with the book specification, covering essential techniques and providing explanations and examples. However, there's room for expansion, particularly in providing more variations and real-world examples for each technique, and in exploring the limitations and drawbacks of each method. The report also lacks a dedicated section on prompt variations for specific tasks or industries, and a conclusion summarizing key takeaways and future trends.\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "The strategy is to refine the existing structure by adding depth and breadth to the covered topics. This involves expanding on existing sections with more detailed explanations, examples, and variations, as well as exploring new, related areas that haven't been covered yet. The focus will be on ensuring that each section provides practical guidance and actionable insights for readers of all skill levels.\n",
      "\n",
      "#### Validation\n",
      "The current report state aligns well with the restrictions, avoiding industry-focused content and overly formal language. The additions should continue to adhere to these restrictions, maintaining a balance between technical accuracy and accessibility. The restriction of \"no deep-dive into LLM architecture beyond the introduction\" should be kept in mind when expanding on the \"Introduction to Prompt Engineering\" section.\n",
      "\n",
      "#### Existing areas expansion\n",
      "Existing sections can be expanded by:\n",
      "\n",
      "*   Adding more variations and real-world examples for each prompting technique.\n",
      "*   Discussing the limitations and drawbacks of each technique.\n",
      "*   Providing guidance on how to choose the right technique for a specific task.\n",
      "*   Including case studies or success stories that demonstrate the effectiveness of prompt engineering.\n",
      "*   Adding visual aids to augment every technique.\n",
      "\n",
      "#### New areas exploration\n",
      "Potential new areas to explore include:\n",
      "\n",
      "*   **Prompt variations for specific tasks or industries:** This section could explore how prompt engineering techniques can be adapted for different applications, such as content creation, customer service, or data analysis.\n",
      "*   **Tools and platforms for prompt engineering:** This section could review various tools and platforms that can help users create, test, and optimize prompts.\n",
      "*   **The future of prompt engineering:** This section could discuss emerging trends and potential future directions in the field of prompt engineering.\n",
      "*   **Combining prompting techniques**: Explore how to combine different techniques to achieve better results. For example, combining chain-of-thought with few-shot learning.\n",
      "*   **Bias and fairness in prompts**: Discuss how prompts can inadvertently introduce bias and how to mitigate this.\n",
      "*   **Prompt debugging**: Provide strategies for identifying and fixing issues with prompts.\n",
      "*   **Cost optimization strategies**: Explore techniques for reducing the cost of using LLMs through prompt engineering.\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- Research prompt variations for specific tasks or industries (e.g., marketing, education, healthcare).\n",
      "- Investigate and describe available tools and platforms for prompt engineering.\n",
      "- Explore the future trends and potential directions in prompt engineering.\n",
      "- Research and describe how to combine different prompting techniques to achieve better results.\n",
      "- Investigate bias and fairness issues in prompts and mitigation strategies.\n",
      "- Research prompt debugging strategies for identifying and fixing issues.\n",
      "- Explore cost optimization strategies in prompt engineering.\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Report Extension** phase of research process.\n",
      "    * Task Specification\n",
      "    * Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    -> Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **REPORT EXTENSION PHASE DESCRIPTION**\n",
      "This phase is responsible for integrating the results from the Jobs Execution phase into the report content.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION INSTRUCTIONS**\n",
      "- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\n",
      "- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\n",
      "- **Follow output format**: Use the provided output format to structure the report and action logs.\n",
      "- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\n",
      "\n",
      "Knowledge base consist of 2 main parts:\n",
      "- **report**: Current output report proposition which addresses MAIN TASK.\n",
      "- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\n",
      "\n",
      "**Output format:**\n",
      "```\n",
      "<report>\n",
      "[enriched report content]\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\n",
      "| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\n",
      "| ... | ... | ... |\n",
      "</actions>\n",
      "```\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "</actions>\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **COLLECTED NEW DATA**\n",
      "```json\n",
      "{\n",
      "  \"title\": \"Prompt Variations by Task/Industry\",\n",
      "  \"variations\": [\n",
      "    {\n",
      "      \"task/industry\": \"Marketing\",\n",
      "      \"prompt_variation\": \"Zero-shot Prompting: 'Write a compelling marketing email for [product/service] targeting [target audience].'\",\n",
      "      \"example\": \"Write a compelling marketing email for a new brand of organic coffee targeting young professionals.\",\n",
      "      \"use_case\": \"Quickly generate marketing copy for various products or services without providing specific examples.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Marketing\",\n",
      "      \"prompt_variation\": \"One-shot Prompting: 'Here's an example of a successful marketing campaign: [example]. Now, write a similar campaign for [product/service].'\",\n",
      "      \"example\": \"Here's an example of a successful marketing campaign: 'Buy one get one free on all summer dresses'. Now, write a similar campaign for winter coats.\",\n",
      "      \"use_case\": \"Create marketing campaigns by adapting successful strategies from provided examples.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Marketing\",\n",
      "      \"prompt_variation\": \"Few-shot Prompting: 'Here are a few examples of effective social media posts: [examples]. Now, create a new post promoting [event/product].'\",\n",
      "      \"example\": \"Here are a few examples of effective social media posts: ['Image of a person enjoying coffee with the caption 'Morning bliss!', 'Video of coffee beans being roasted with the caption 'Freshly roasted for you!'']. Now, create a new post promoting a new flavor of coffee.\",\n",
      "      \"use_case\": \"Generate social media content based on a set of successful examples.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Education\",\n",
      "      \"prompt_variation\": \"Chain-of-Thought Prompting: 'Explain the process of photosynthesis step-by-step, showing your reasoning at each stage.'\",\n",
      "      \"example\": \"Explain the process of photosynthesis step-by-step, showing your reasoning at each stage.\",\n",
      "      \"use_case\": \"Encourage students to demonstrate their understanding of complex processes by explaining their reasoning.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Education\",\n",
      "      \"prompt_variation\": \"Tree-of-Thought Prompting: 'Brainstorm different approaches to solving this math problem, then evaluate each approach and select the best one.'\",\n",
      "      \"example\": \"Brainstorm different approaches to solving this algebra problem, then evaluate each approach and select the best one.\",\n",
      "      \"use_case\": \"Help students develop problem-solving skills by exploring multiple solutions and evaluating their effectiveness.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Education\",\n",
      "      \"prompt_variation\": \"Self-Consistency Prompting: 'Answer this question multiple times using slightly different phrasing, then identify the most consistent and accurate answer: [question].'\",\n",
      "      \"example\": \"Answer this question multiple times using slightly different phrasing, then identify the most consistent and accurate answer: 'What are the main causes of the French Revolution?'\",\n",
      "      \"use_case\": \"Improve the accuracy of answers by identifying and reinforcing consistent information across multiple responses.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Healthcare\",\n",
      "      \"prompt_variation\": \"Prompt for Improving Factual Accuracy: 'Summarize the key findings of this medical research paper, ensuring all information is factually correct and supported by evidence.'\",\n",
      "      \"example\": \"Summarize the key findings of this medical research paper on the effects of exercise on heart health, ensuring all information is factually correct and supported by evidence.\",\n",
      "      \"use_case\": \"Ensure accurate and reliable summaries of medical research for healthcare professionals.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Healthcare\",\n",
      "      \"prompt_variation\": \"Prompt for Controlling Style/Tone: 'Write a patient-friendly explanation of [medical condition] in a compassionate and reassuring tone.'\",\n",
      "      \"example\": \"Write a patient-friendly explanation of diabetes in a compassionate and reassuring tone.\",\n",
      "      \"use_case\": \"Create patient education materials that are easy to understand and emotionally supportive.\"\n",
      "    },\n",
      "    {\n",
      "      \"task/industry\": \"Healthcare\",\n",
      "      \"prompt_variation\": \"Prompt for Reasoning/Problem-Solving: 'Given these symptoms and medical history, what are the most likely diagnoses and what further tests should be ordered?'\",\n",
      "      \"example\": \"Given these symptoms of chest pain, shortness of breath, and a history of smoking, what are the most likely diagnoses and what further tests should be ordered?\",\n",
      "      \"use_case\": \"Assist healthcare professionals in diagnosis and treatment planning.\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "```\n",
      "-----\n",
      "Title: Tools and Platforms for Prompt Engineering\n",
      "\n",
      "Here's a list of tools and platforms for prompt engineering, focusing on functionality, pricing, and user reviews:\n",
      "\n",
      "**1. OpenAI Playground**\n",
      "\n",
      "*   **Description:** A web-based interface for experimenting with OpenAI models, allowing users to test prompts, adjust parameters, and see the model's output in real-time.\n",
      "*   **Functionality:** Prompt testing, parameter adjustment, model selection, real-time output, code generation.\n",
      "*   **Pricing:** Token-based; cost varies by model and tokens processed. New users often receive free credits.\n",
      "*   **User Reviews:** Praised for ease of use and flexibility; excellent for beginners and experienced users. Pricing can be complex.\n",
      "\n",
      "**2. PromptLayer**\n",
      "\n",
      "*   **Description:** A platform for prompt management, version control, and collaboration. It integrates with LLMs and provides tools for A/B testing and performance monitoring.\n",
      "*   **Functionality:** Prompt versioning, collaboration, A/B testing, performance monitoring, LLM integration.\n",
      "*   **Pricing:** Free tier with limitations; paid tiers with advanced features. Pricing is based on prompts, team members, or usage volume.\n",
      "*   **User Reviews:** Appreciated for organization and collaboration features, especially for teams. Version control and A/B testing are highly valued. Some learning curve with advanced features.\n",
      "\n",
      "**3. ChainForge**\n",
      "\n",
      "*   **Description:** A visual programming environment for prompt engineering, allowing users to create complex prompt chains using a node-based interface.\n",
      "*   **Functionality:** Visual prompt chaining, node-based interface, support for variables and conditional logic, LLM integration, experimentation tools.\n",
      "*   **Pricing:** Open-source and free.\n",
      "*   **User Reviews:** Praised for its visual approach, making complex prompts easier to manage. The node-based interface is intuitive.\n",
      "\n",
      "**4. Microsoft Semantic Kernel**\n",
      "\n",
      "*   **Description:** An open-source SDK that augments apps with LLMs, supporting prompt templating, chaining, and planning.\n",
      "*   **Functionality:** Prompt templating, prompt chaining, planning and goal setting, integration with LLMs and services, extensible architecture.\n",
      "*   **Pricing:** Open-source and free. LLM usage incurs costs based on the provider's pricing (e.g., OpenAI, Azure OpenAI).\n",
      "*   **User Reviews:** Appreciated for flexibility and extensibility, allowing structured integration of LLMs into applications. Prompt templating and chaining are useful.\n",
      "\n",
      "**5. LangChain**\n",
      "\n",
      "*   **Description:** A framework for developing applications powered by language models, enabling chaining different components for advanced use-cases.\n",
      "*   **Functionality:** Prompt management, chains, data augmentation, agents, integration with LLMs and tools.\n",
      "*   **Pricing:** Open-source and free. LLM and service usage incur costs based on the respective providers.\n",
      "*   **User Reviews:** Highly regarded for versatility and extensive tools and integrations. Well-documented with a vibrant community.\n",
      "-----\n",
      "```json\n",
      "{\n",
      "  \"report\": {\n",
      "    \"title\": \"Bias and Fairness in Prompts: Identification and Mitigation\",\n",
      "    \"sections\": [\n",
      "      {\n",
      "        \"title\": \"Introduction\",\n",
      "        \"content\": \"Prompts can inadvertently introduce biases, leading to unfair or discriminatory outputs from Large Language Models (LLMs). Understanding and mitigating these biases is crucial for responsible AI development and deployment.\"\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"Common Biases in Prompts\",\n",
      "        \"content\": \"Several types of biases can manifest in prompts:\\n\\n*   **Stereotypical Bias:** Prompts can reinforce societal stereotypes related to gender, race, religion, or other demographic factors.\\n*   **Confirmation Bias:** Prompts can be phrased in a way that elicits responses confirming pre-existing beliefs or assumptions.\\n*   **Framing Bias:** The way a prompt is framed can influence the LLM's response, even if the underlying information is the same.\\n*   **Association Bias:** Prompts can create unintended associations between concepts, leading to biased outputs.\"\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"Mitigation Strategies\",\n",
      "        \"content\": \"Several techniques can be employed to reduce bias in prompts:\\n\\n*   **Diverse Prompting:** Create a variety of prompts that represent different perspectives and avoid reinforcing stereotypes.\\n*   **Bias Auditing:** Evaluate LLM outputs for potential biases by using bias detection tools and human review.\\n*   **Counterfactual Prompting:** Generate prompts that challenge existing biases and stereotypes.\\n*   **Data Augmentation:** Supplement training data with examples that address underrepresented groups or perspectives.\\n*   **Prompt Rephrasing:** Carefully rephrase prompts to remove any potentially biased language or framing.\\n*   **Prompt Engineering Applications in LLMs:** Use prompt engineering to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving abilities in LLMs.\\n*   **Prompt Ensembling Methods:** Combine multiple prompts to get more reliable responses from language models. Strategies include simple averaging/voting, weighted averaging, and prompt chaining.\"\n",
      "      },\n",
      "      {\n",
      "        \"title\": \"Prompt Safety and Security\",\n",
      "        \"content\": \"Focus on prompt safety and security considerations, including prompt injection and adversarial attacks. Identify mitigation strategies and best practices for developing secure prompts.\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "```\n",
      "\n",
      "Title: Bias and Fairness in Prompts: Identification and Mitigation\n",
      "-----\n",
      "```json\n",
      "{\n",
      " \"title\": \"Prompt Debugging Strategies for LLMs\",\n",
      " \"strategies\": [\n",
      "  {\n",
      "   \"name\": \"Iterative Refinement\",\n",
      "   \"description\": \"Start with a basic prompt and iteratively refine it based on the LLM's responses. This involves analyzing the output, identifying issues, and adjusting the prompt accordingly.\",\n",
      "   \"techniques\": [\n",
      "    \"Start Simple: Begin with a clear and concise prompt.\",\n",
      "    \"Analyze Output: Carefully examine the LLM's response for errors, inconsistencies, or irrelevant information.\",\n",
      "    \"Adjust Prompt: Modify the prompt based on the analysis, adding constraints, clarifying instructions, or providing more context.\",\n",
      "    \"Repeat: Repeat the process until the desired output is achieved.\"\n",
      "   ],\n",
      "   \"example\": \"Initial Prompt: 'Write a short story.' -> Response: Generic and uninspired. Refined Prompt: 'Write a short story about a robot who learns to love.' -> Response: More focused and creative.\"\n",
      "  },\n",
      "  {\n",
      "   \"name\": \"Constraint Addition\",\n",
      "   \"description\": \"Adding constraints to the prompt to guide the LLM towards the desired output and avoid irrelevant or undesirable responses.\",\n",
      "   \"techniques\": [\n",
      "    \"Specify Format: Define the desired output format (e.g., 'in bullet points', 'as a poem').\",\n",
      "    \"Set Length Limits: Restrict the length of the response (e.g., 'in under 100 words').\",\n",
      "    \"Define Tone: Specify the desired tone (e.g., 'in a professional tone', 'in a humorous way').\",\n",
      "    \"Exclude Topics: Explicitly exclude certain topics or phrases (e.g., 'without mentioning politics').\"\n",
      "   ],\n",
      "   \"example\": \"Initial Prompt: 'Tell me about dogs.' -> Response: Broad and general information. Refined Prompt: 'Tell me about the health benefits of owning dogs, in under 150 words.' -> Response: Focused and concise.\"\n",
      "  },\n",
      "  {\n",
      "   \"name\": \"Contextual Priming\",\n",
      "   \"description\": \"Providing the LLM with relevant context or background information to improve the accuracy and relevance of the response.\",\n",
      "   \"techniques\": [\n",
      "    \"Provide Background: Include relevant background information or context in the prompt.\",\n",
      "    \"Set the Scene: Describe the scenario or situation for which the LLM should generate a response.\",\n",
      "    \"Define Roles: Specify the roles or perspectives that the LLM should adopt.\",\n",
      "    \"Use Examples: Provide examples of the desired output format or style.\"\n",
      "   ],\n",
      "   \"example\": \"Initial Prompt: 'What is the capital of Australia?' -> Response: Canberra. Refined Prompt: 'Given that Australia is a country in Oceania, what is its capital?' -> Response: Canberra (Contextual priming not really needed here, but illustrates the technique).\"\n",
      "  },\n",
      "  {\n",
      "   \"name\": \"Prompt Ensembling\",\n",
      "   \"description\": \"Combining multiple prompts to get more reliable and robust responses from language models. This can involve simple averaging/voting, weighted averaging, or prompt chaining.\",\n",
      "   \"techniques\": [\n",
      "    \"Simple Averaging/Voting: Generate responses from multiple prompts and select the most common or representative response.\",\n",
      "    \"Weighted Averaging: Assign weights to different prompts based on their expected accuracy or relevance.\",\n",
      "    \"Prompt Chaining: Use the output of one prompt as the input for another prompt.\"\n",
      "   ],\n",
      "   \"example\": \"Prompt 1: 'Summarize this article.' Prompt 2: 'Give a concise overview of this article.' Combine the responses to create a more comprehensive summary.\"\n",
      "  },\n",
      "  {\n",
      "   \"name\": \"Safety and Security Checks\",\n",
      "   \"description\": \"Implementing checks to mitigate prompt injection and adversarial attacks. This includes identifying potential vulnerabilities and developing secure prompts.\",\n",
      "   \"techniques\": [\n",
      "    \"Input Sanitization: Sanitize user inputs to remove potentially harmful characters or commands.\",\n",
      "    \"Output Filtering: Filter the LLM's output to remove sensitive information or offensive content.\",\n",
      "    \"Prompt Hardening: Design prompts that are resistant to manipulation or adversarial attacks.\"\n",
      "   ],\n",
      "   \"example\": \"Prompt: 'Translate the following text into French: [User Input]'. Sanitize the [User Input] to prevent prompt injection attacks.\"\n",
      "  }\n",
      " ]\n",
      "}\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **JOBS**\n",
      "These are the jobs from the current iteration:\n",
      "Job 1: Research prompt variations for specific tasks or industries (e.g., marketing, education, healthcare). Focus on providing examples and use cases for each variation.\n",
      "Job 2: Investigate and describe available tools and platforms for prompt engineering. Focus on functionality, pricing, and user reviews.\n",
      "Job 3: Explore bias and fairness issues in prompts and mitigation strategies. Focus on identifying common biases and techniques for reducing them.\n",
      "Job 4: Research prompt debugging strategies for identifying and fixing issues. Focus on practical techniques and examples.\n",
      "\n",
      "---\n",
      "\n",
      "## **RESTRICTIONS**\n",
      "\n",
      "    1. Use all information provided in the additional_data section\n",
      "    \n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Variations by Task/Industry\n",
      "- Description: This section explores how prompt engineering techniques can be adapted for different applications across various tasks and industries, such as marketing, education, and healthcare. It provides examples and use cases for each variation.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for specific tasks or industries, as outlined in the analysis.\n",
      "\n",
      "Title: Tools and Platforms for Prompt Engineering\n",
      "- Description: This section reviews various tools and platforms that can help users create, test, and optimize prompts. It focuses on functionality, pricing, and user reviews to provide a comprehensive overview.\n",
      "- Relevance: This section directly addresses the need to investigate and describe available tools and platforms for prompt engineering, as outlined in the analysis.\n",
      "\n",
      "Title: Bias and Fairness in Prompts: Identification and Mitigation\n",
      "- Description: This section discusses bias and fairness issues in prompts, focusing on identifying common biases and techniques for reducing them. It provides strategies for creating more equitable and unbiased prompts.\n",
      "- Relevance: This section directly addresses the need to explore bias and fairness issues in prompts and mitigation strategies, as outlined in the analysis.\n",
      "\n",
      "Title: Prompt Debugging Strategies for LLMs\n",
      "- Description: This section explores prompt debugging strategies for identifying and fixing issues with prompts. It focuses on practical techniques and examples to help users troubleshoot and improve their prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt debugging strategies for identifying and fixing issues, as outlined in the analysis.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "| Task/Industry Var | Addition | Added a section exploring prompt variations for specific tasks or industries, including examples and use cases. |\n",
      "| Tools & Platforms | Addition | Added a section reviewing tools and platforms for prompt engineering, focusing on functionality, pricing, and user reviews. |\n",
      "| Bias & Fairness | Addition | Added a section discussing bias and fairness issues in prompts and mitigation strategies. |\n",
      "| Prompt Debugging | Addition | Added a section exploring prompt debugging strategies for identifying and fixing issues with prompts. |\n",
      "</actions>\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **state summary**: Summarize the report part of the current **REPORT STATE** to identify gaps and areas needing further research.\n",
      "    - *evaluate current completion level of the report*\n",
      "    - *critically validate the report in terms of the **RESTRICTIONS** and **MAIN TASK** goal*\n",
      "    - *point missing information*\n",
      "    - *point irrelevant or doubtful information*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Validation: Describe what parts of the report state may not be compatible with **RESTRICTIONS**.*\n",
      "    - *Existing areas expansion: Explain how exploring or clarification of existing parts of the report may help producing better answer.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 4 turn of maximum 4 iterations*\n",
      "    - *consider prior jobs summarized from the actions sections of report state to avoid redundancy and ensure new research paths are distinct*\n",
      "    - *be aware of **RESTRICTIONS** and ensure all proposed paths comply with them*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths that will enrich the report\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "[current report state evaluation]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Validation\n",
      "[explanation of how the current report state may not be compatible with the restrictions or main task goal]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded or clarified]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Variations by Task/Industry\n",
      "- Description: This section explores how prompt engineering techniques can be adapted for different applications across various tasks and industries, such as marketing, education, and healthcare. It provides examples and use cases for each variation.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for specific tasks or industries, as outlined in the analysis.\n",
      "\n",
      "Title: Tools and Platforms for Prompt Engineering\n",
      "- Description: This section reviews various tools and platforms that can help users create, test, and optimize prompts. It focuses on functionality, pricing, and user reviews to provide a comprehensive overview.\n",
      "- Relevance: This section directly addresses the need to investigate and describe available tools and platforms for prompt engineering, as outlined in the analysis.\n",
      "\n",
      "Title: Bias and Fairness in Prompts: Identification and Mitigation\n",
      "- Description: This section discusses bias and fairness issues in prompts, focusing on identifying common biases and techniques for reducing them. It provides strategies for creating more equitable and unbiased prompts.\n",
      "- Relevance: This section directly addresses the need to explore bias and fairness issues in prompts and mitigation strategies, as outlined in the analysis.\n",
      "\n",
      "Title: Prompt Debugging Strategies for LLMs\n",
      "- Description: This section explores prompt debugging strategies for identifying and fixing issues with prompts. It focuses on practical techniques and examples to help users troubleshoot and improve their prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt debugging strategies for identifying and fixing issues, as outlined in the analysis.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "| Task/Industry Var | Addition | Added a section exploring prompt variations for specific tasks or industries, including examples and use cases. |\n",
      "| Tools & Platforms | Addition | Added a section reviewing tools and platforms for prompt engineering, focusing on functionality, pricing, and user reviews. |\n",
      "| Bias & Fairness | Addition | Added a section discussing bias and fairness issues in prompts and mitigation strategies. |\n",
      "| Prompt Debugging | Addition | Added a section exploring prompt debugging strategies for identifying and fixing issues with prompts. |\n",
      "</actions>\n",
      "```\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "### **STATE SUMMARY**\n",
      "The current report provides a good initial structure for a guidebook on prompt engineering. It covers introductory concepts, basic and advanced techniques, applications, optimization, ensembling, safety, multi-modal prompting, task-specific variations, tools, bias, and debugging. The report addresses many of the requirements outlined in the book specification, including a broad overview of techniques, detailed breakdowns, and real-world examples. However, the report lacks depth in certain areas and could benefit from more specific examples and variations within each technique. Also, while the structure is comprehensive, the individual sections might need further refinement to ensure a smooth flow and logical progression.\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "The strategy is to refine the existing structure by adding more depth and specific examples to each section. This involves expanding on the variations of each technique, providing more real-world examples, and addressing any limitations or drawbacks associated with each method. Additionally, the strategy aims to ensure a logical flow between the sections, creating a cohesive and comprehensive guide.\n",
      "\n",
      "#### Validation\n",
      "The current report state aligns well with the restrictions, as it avoids deep dives into LLM architecture beyond the introduction and refrains from using overly formal or industry-focused language. The humorous language is also used sparingly, maintaining credibility.\n",
      "\n",
      "#### Existing areas expansion\n",
      "Each section can be expanded by including more specific examples and variations of the techniques. For instance, the \"Basic Prompting Techniques\" section could include different types of zero-shot prompts or variations of few-shot examples. The \"Advanced Prompting Techniques\" section could benefit from more detailed explanations of the underlying mechanisms and more complex use cases. The \"Prompt Engineering Applications\" section can include more real-world examples and case studies.\n",
      "\n",
      "#### New areas exploration\n",
      "Given the iterative limit, it's not necessary to explore new areas.\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- Expand each section with more specific examples and variations of the techniques.\n",
      "- Provide more real-world examples and case studies for each technique.\n",
      "- Ensure a logical flow between the sections, creating a cohesive and comprehensive guide.\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Report Extension** phase of research process.\n",
      "    * Task Specification\n",
      "    * Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    -> Report Extension\n",
      "    * Final Check\n",
      "\n",
      "## **REPORT EXTENSION PHASE DESCRIPTION**\n",
      "This phase is responsible for integrating the results from the Jobs Execution phase into the report content.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION INSTRUCTIONS**\n",
      "- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you handle report modification properly.\n",
      "- **Prevent duplicates**: Before extending the report, check if newly collected data is not already present in the report. If it is, evaluate if it provides some new useful insights and extend existing content properly.\n",
      "- **Follow output format**: Use the provided output format to structure the report and action logs.\n",
      "- **Follow restrictions**: Ensure that all added data complies with the **RESTRICTIONS** from the MAIN TASK description.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\n",
      "\n",
      "Knowledge base consist of 2 main parts:\n",
      "- **report**: Current output report proposition which addresses MAIN TASK.\n",
      "- **actions**: List of shortened descriptions of modification or extension actions performed to the existing report. Every action should follow the tabular format: \"| [job title] | [Addition/Modification] | [short description of the action] |\". For job title use shortened version of the job description.\n",
      "\n",
      "**Output format:**\n",
      "```\n",
      "<report>\n",
      "[enriched report content]\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\n",
      "| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\n",
      "| ... | ... | ... |\n",
      "</actions>\n",
      "```\n",
      "---\n",
      "\n",
      "## **REPORT STATE**\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Variations by Task/Industry\n",
      "- Description: This section explores how prompt engineering techniques can be adapted for different applications across various tasks and industries, such as marketing, education, and healthcare. It provides examples and use cases for each variation.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for specific tasks or industries, as outlined in the analysis.\n",
      "\n",
      "Title: Tools and Platforms for Prompt Engineering\n",
      "- Description: This section reviews various tools and platforms that can help users create, test, and optimize prompts. It focuses on functionality, pricing, and user reviews to provide a comprehensive overview.\n",
      "- Relevance: This section directly addresses the need to investigate and describe available tools and platforms for prompt engineering, as outlined in the analysis.\n",
      "\n",
      "Title: Bias and Fairness in Prompts: Identification and Mitigation\n",
      "- Description: This section discusses bias and fairness issues in prompts, focusing on identifying common biases and techniques for reducing them. It provides strategies for creating more equitable and unbiased prompts.\n",
      "- Relevance: This section directly addresses the need to explore bias and fairness issues in prompts and mitigation strategies, as outlined in the analysis.\n",
      "\n",
      "Title: Prompt Debugging Strategies for LLMs\n",
      "- Description: This section explores prompt debugging strategies for identifying and fixing issues with prompts. It focuses on practical techniques and examples to help users troubleshoot and improve their prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt debugging strategies for identifying and fixing issues, as outlined in the analysis.\n",
      "\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "| Task/Industry Var | Addition | Added a section exploring prompt variations for specific tasks or industries, including examples and use cases. |\n",
      "| Tools & Platforms | Addition | Added a section reviewing tools and platforms for prompt engineering, focusing on functionality, pricing, and user reviews. |\n",
      "| Bias & Fairness | Addition | Added a section discussing bias and fairness issues in prompts and mitigation strategies. |\n",
      "| Prompt Debugging | Addition | Added a section exploring prompt debugging strategies for identifying and fixing issues with prompts. |\n",
      "</actions>\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **COLLECTED NEW DATA**\n",
      "## Examples and Variations of Basic Prompting Techniques\n",
      "\n",
      "Here's a summary of examples and variations for zero-shot, one-shot, and few-shot prompting techniques, focusing on diverse examples across different domains while avoiding complex technical details or industry-specific jargon:\n",
      "\n",
      "**Zero-Shot Prompting:** A list of examples and variations for each technique, including a brief explanation of each.\n",
      "\n",
      "**One-Shot Prompting:** A list of examples and variations for each technique, including a brief explanation of each.\n",
      "\n",
      "**Few-Shot Prompting:** A list of examples and variations for each technique, including a brief explanation of each.\n",
      "-----\n",
      "Title: Real-World Case Studies of Advanced Prompting Techniques\n",
      "\n",
      "**Case Study 1: Chain-of-Thought Prompting**\n",
      "\n",
      "*   **Problem:** AI models struggle with multi-step reasoning in math word problems, commonsense reasoning, and code generation.\n",
      "*   **Technique:** Prompting the model to explicitly explain its reasoning step-by-step before providing the final answer.\n",
      "*   **Results:** Improved accuracy in math problem-solving, enhanced commonsense reasoning, and more reliable code generation.\n",
      "\n",
      "**Case Study 2: Tree-of-Thought Prompting**\n",
      "\n",
      "*   **Problem:** AI models struggle with complex reasoning, creative content generation and code generation/debugging.\n",
      "*   **Technique:** Prompting the model to generate a \"tree\" of thoughts, exploring multiple reasoning paths and backtracking when necessary.\n",
      "*   **Results:** Improved performance in complex reasoning tasks, more creative and original content, and more accurate/reliable code.\n",
      "\n",
      "**Case Study 3: Self-Consistency Prompting**\n",
      "\n",
      "*   **Problem:** AI models often provide inconsistent answers in math problem solving, code generation and question answering.\n",
      "*   **Technique:** Generating multiple independent reasoning paths and selecting the most consistent answer.\n",
      "*   **Results:** Improved accuracy in math problem solving, more robust code generation, and more reliable question answering.\n",
      "-----\n",
      "Title: Zero-Shot Prompt Types and Examples\n",
      "\n",
      "Here are several types of zero-shot prompts, along with examples and explanations of when they're most effective:\n",
      "\n",
      "**1. Simple Question/Instruction Prompts:**\n",
      "\n",
      "*   **Description:** These are the most straightforward type of zero-shot prompts. They directly ask a question or give an instruction without providing any examples.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"Translate the following English text to French: 'Hello, how are you?'\"\n",
      "    *   Expected Output: \"Bonjour, comment allez-vous ?\"\n",
      "*   **Effectiveness:** Most effective when the task is well-defined and the language model has a good general understanding of the task. Works well for common tasks like translation, summarization, or simple question answering.\n",
      "\n",
      "**2. Imperative Prompts:**\n",
      "\n",
      "*   **Description:** These prompts use commands to guide the model's behavior.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"Summarize this article in one sentence.\" \\[Followed by the article text]\n",
      "    *   Expected Output: A concise summary of the article.\n",
      "*   **Effectiveness:** Useful when you need a specific type of output (e.g., a summary, a list, an explanation). The command clearly directs the model's action.\n",
      "\n",
      "**3. Declarative Prompts:**\n",
      "\n",
      "*   **Description:** These prompts describe the desired output or behavior without explicitly commanding it.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"A short description of the Eiffel Tower:\"\n",
      "    *   Expected Output: \"The Eiffel Tower is a wrought-iron lattice tower on the Champ de Mars in Paris, France.\"\n",
      "*   **Effectiveness:** Effective when you want the model to generate text that matches a certain style or format. The declarative nature can encourage more creative or descriptive outputs.\n",
      "\n",
      "**4. Prompts with Context:**\n",
      "\n",
      "*   **Description:** These prompts provide some context or background information to help the model understand the task better.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"Given the following sentence: 'The cat sat on the mat.' Identify the subject of the sentence.\"\n",
      "    *   Expected Output: \"The cat\"\n",
      "*   **Effectiveness:** Useful when the task requires understanding specific terminology or concepts. The context helps the model narrow down the possible answers.\n",
      "\n",
      "**5. Role-Playing Prompts:**\n",
      "\n",
      "*   **Description:** These prompts instruct the model to adopt a specific persona or role.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"You are a helpful chatbot. Answer the following question: What is the capital of Australia?\"\n",
      "    *   Expected Output: \"The capital of Australia is Canberra.\"\n",
      "*   **Effectiveness:** Can improve the quality and relevance of the output by guiding the model to respond from a particular perspective. Useful for tasks like customer service simulations or creative writing.\n",
      "\n",
      "**6. Chain-of-Thought Prompting (Zero-Shot CoT):**\n",
      "\n",
      "*   **Description:** This technique encourages the model to think step-by-step before answering, even without explicit examples of chain-of-thought reasoning. This is often achieved by adding \"Let's think step by step\" to a question.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"I have 3 apples. I eat 2. How many apples do I have left? Let's think step by step.\"\n",
      "    *   Expected Output: \"I started with 3 apples. I ate 2 apples. 3 - 2 = 1. I have 1 apple left.\"\n",
      "*   **Effectiveness:** Significantly improves performance on complex reasoning tasks, arithmetic problems, and logical deductions by forcing the model to articulate its thought process.\n",
      "\n",
      "**7. Constraint Prompts:**\n",
      "\n",
      "*   **Description:** These prompts include specific limitations or constraints on the desired output.\n",
      "*   **Example:**\n",
      "    *   Prompt: \"Write a haiku about autumn.\"\n",
      "    *   Expected Output: A haiku poem about autumn.\n",
      "*   **Effectiveness:** Guides the model to produce outputs that adhere to specific rules, formats, or lengths. Useful for tasks where adherence to constraints is crucial.\n",
      "-----\n",
      "**Title: Impact of Few-Shot Example Quality on LLM Performance**\n",
      "\n",
      "**Good Few-Shot Examples:**\n",
      "\n",
      "*   **Clarity and Relevance:** Good examples directly relate to the task and are easy to understand, demonstrating the expected input-output format clearly.\n",
      "    *   Input: \"This movie was fantastic!\"\n",
      "    *   Output: Positive\n",
      "*   **Consistency:** Maintaining a consistent style and format across all examples helps the LLM learn the pattern more effectively.\n",
      "*   **Diversity (to a point):** Including a few diverse examples can help the model generalize better.\n",
      "*   **Correctness:** All examples should be accurate.\n",
      "*   **Representative of the Data:** The examples should reflect the kind of data the LLM will encounter during actual use.\n",
      "\n",
      "**Impact of Good Few-Shot Examples:**\n",
      "\n",
      "*   **Improved Accuracy:** Clear, relevant, and correct examples guide the LLM to produce more accurate responses.\n",
      "*   **Faster Learning:** The LLM can quickly grasp the task and generalize to new inputs with fewer examples.\n",
      "*   **Reduced Hallucinations:** Well-crafted examples help ground the LLM.\n",
      "*   **Better Generalization:** A diverse set of good examples enables the LLM to perform well on a wider range of inputs.\n",
      "\n",
      "**Bad Few-Shot Examples:**\n",
      "\n",
      "*   **Ambiguity:** Examples that are unclear or open to multiple interpretations can confuse the LLM.\n",
      "    *   Input: \"It was okay.\"\n",
      "    *   Output: ?\n",
      "*   **Irrelevance:** Examples that are not directly related to the task at hand.\n",
      "*   **Inconsistency:** Varying the format or style of the examples without a clear reason can hinder the LLMs ability to learn the underlying pattern.\n",
      "*   **Incorrectness:** Incorrect examples can be detrimental to performance.\n",
      "*   **Too Complex:** Overly complex or nuanced examples can overwhelm the LLM.\n",
      "\n",
      "**Impact of Bad Few-Shot Examples:**\n",
      "\n",
      "*   **Reduced Accuracy:** Ambiguous or incorrect examples can lead to inaccurate responses.\n",
      "*   **Slower Learning:** The LLM struggles to learn the task effectively.\n",
      "*   **Increased Hallucinations:** Confused by the examples, the LLM may generate more nonsensical or irrelevant outputs.\n",
      "*   **Poor Generalization:** The LLM may overfit to the specific examples, performing poorly on new, unseen inputs.\n",
      "*   **Bias Amplification:** If the bad examples contain biases, the LLM may amplify those biases in its responses.\n",
      "\n",
      "In summary, the quality of few-shot examples significantly impacts the performance of LLMs. Good examples promote accuracy, faster learning, and better generalization, while bad examples can lead to reduced accuracy, increased hallucinations, and poor generalization.\n",
      "\n",
      "---\n",
      "\n",
      "## **JOBS**\n",
      "These are the jobs from the current iteration:\n",
      "Job 1: Research specific examples and variations for basic prompting techniques like zero-shot, one-shot, and few-shot prompting. Focus on diverse examples across different domains.\n",
      "Job 2: Find real-world case studies demonstrating the application of advanced prompting techniques such as chain-of-thought, tree-of-thought, and self-consistency. Detail the problem, the technique used, and the results achieved.\n",
      "Job 3: Identify and describe different types of zero-shot prompts, providing examples for each type. Focus on the nuances of each type and when they are most effective.\n",
      "Job 4: Research variations of few-shot examples, detailing how the choice of examples impacts the LLM's response. Provide examples of good and bad few-shot examples and explain why they differ.\n",
      "\n",
      "---\n",
      "\n",
      "## **RESTRICTIONS**\n",
      "\n",
      "    1. Use all information provided in the additional_data section\n",
      "    \n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Variations by Task/Industry\n",
      "- Description: This section explores how prompt engineering techniques can be adapted for different applications across various tasks and industries, such as marketing, education, and healthcare. It provides examples and use cases for each variation.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for specific tasks or industries, as outlined in the analysis.\n",
      "\n",
      "Title: Tools and Platforms for Prompt Engineering\n",
      "- Description: This section reviews various tools and platforms that can help users create, test, and optimize prompts. It focuses on functionality, pricing, and user reviews to provide a comprehensive overview.\n",
      "- Relevance: This section directly addresses the need to investigate and describe available tools and platforms for prompt engineering, as outlined in the analysis.\n",
      "\n",
      "Title: Bias and Fairness in Prompts: Identification and Mitigation\n",
      "- Description: This section discusses bias and fairness issues in prompts, focusing on identifying common biases and techniques for reducing them. It provides strategies for creating more equitable and unbiased prompts.\n",
      "- Relevance: This section directly addresses the need to explore bias and fairness issues in prompts and mitigation strategies, as outlined in the analysis.\n",
      "\n",
      "Title: Prompt Debugging Strategies for LLMs\n",
      "- Description: This section explores prompt debugging strategies for identifying and fixing issues with prompts. It focuses on practical techniques and examples to help users troubleshoot and improve their prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt debugging strategies for identifying and fixing issues, as outlined in the analysis.\n",
      "\n",
      "Title: Zero-Shot Prompt Types and Examples\n",
      "- Description: This section explores different types of zero-shot prompts, providing examples for each type and explaining when they're most effective, including simple question/instruction prompts, imperative prompts, declarative prompts, prompts with context, role-playing prompts, chain-of-thought prompting, and constraint prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for zero-shot prompting, as outlined in the analysis.\n",
      "\n",
      "Title: Real-World Case Studies of Advanced Prompting Techniques\n",
      "- Description: This section provides real-world case studies demonstrating the application of advanced prompting techniques such as chain-of-thought, tree-of-thought, and self-consistency. It details the problem, the technique used, and the results achieved.\n",
      "- Relevance: This section directly addresses the need to research real-world examples for advanced prompting techniques, as outlined in the analysis.\n",
      "\n",
      "Title: Impact of Few-Shot Example Quality on LLM Performance\n",
      "- Description: This section details how the choice of examples impacts the LLM's response in few-shot prompting. It provides examples of good and bad few-shot examples and explains why they differ, focusing on clarity, relevance, consistency, diversity, correctness, and representativeness.\n",
      "- Relevance: This section directly addresses the need to research variations of few-shot examples, as outlined in the analysis.\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "| Task/Industry Var | Addition | Added a section exploring prompt variations for specific tasks or industries, including examples and use cases. |\n",
      "| Tools & Platforms | Addition | Added a section reviewing tools and platforms for prompt engineering, focusing on functionality, pricing, and user reviews. |\n",
      "| Bias & Fairness | Addition | Added a section discussing bias and fairness issues in prompts and mitigation strategies. |\n",
      "| Prompt Debugging | Addition | Added a section exploring prompt debugging strategies for identifying and fixing issues with prompts. |\n",
      "| Zero-Shot Ex & Var | Addition | Added a section exploring different types of zero-shot prompts, providing examples for each type. |\n",
      "| Adv Prompt Case Stud | Addition | Added a section providing real-world case studies demonstrating the application of advanced prompting techniques. |\n",
      "| Few-Shot Ex Quality | Addition | Added a section detailing how the choice of examples impacts the LLM's response in few-shot prompting. |\n",
      "</actions>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# All messages from the process\n",
    "for msg in research_state['all_messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e94ae46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "<report>\n",
      "Title: Introduction to Prompt Engineering\n",
      "- Description: This section defines prompt engineering, explains its importance, and provides a brief overview of how Large Language Models (LLMs) work.\n",
      "- Relevance: This section directly addresses the need for an introduction to prompt engineering and provides context for the rest of the guidebook, as outlined in the book specification. It also touches on how LLMs work, as requested in the initial description.\n",
      "\n",
      "Title: Basic Prompting Techniques: Zero-Shot, One-Shot, and Few-Shot\n",
      "- Description: This section covers fundamental prompting techniques, including zero-shot, one-shot, and few-shot prompting. It provides definitions, explanations of why they work, and examples.\n",
      "- Relevance: This section directly addresses the requirement for a broad overview of prompt engineering techniques and a comprehensive guide from beginner to expert, as stated in the content description.\n",
      "\n",
      "Title: Advanced Prompting Techniques: Chain-of-Thought, Tree-of-Thought, and Self-Consistency\n",
      "- Description: This section explores more complex prompting techniques, including chain-of-thought, tree-of-thought, and self-consistency prompting. It provides definitions, explanations, and examples.\n",
      "- Relevance: This section aligns with the need for a detailed breakdown of techniques with multiple variations and real-world examples, as specified in the content description. It builds upon the basic techniques to provide a more comprehensive guide.\n",
      "\n",
      "Title: Prompt Engineering Applications in LLMs\n",
      "- Description: This section focuses on how prompt engineering can be applied to different tasks, such as improving factual accuracy, controlling style/tone, eliciting creative content, and enhancing reasoning/problem-solving abilities in LLMs.\n",
      "- Relevance: This section directly addresses the requirement for techniques for improving factual accuracy, controlling style/tone, eliciting creative content, reasoning/problem-solving, and generating different content formats, as outlined in the content description.\n",
      "\n",
      "Title: Prompt Optimization Techniques and Their Impact on LLM Performance\n",
      "- Description: This section explores prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. It explains how these techniques reduce costs, improve response times, and increase efficiency.\n",
      "- Relevance: This section aligns with the need for a comprehensive guide, detailing methods for refining prompts to improve performance, as suggested by the analysis.\n",
      "\n",
      "Title: Prompt Ensembling Methods: Enhancing LLM Performance\n",
      "- Description: This section discusses prompt ensembling, which combines multiple prompts to get more reliable responses from language models. It covers strategies like simple averaging/voting, weighted averaging, and prompt chaining, highlighting their advantages and disadvantages.\n",
      "- Relevance: This section addresses the need for new areas of exploration, specifically prompt ensembling methods and their benefits, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Safety and Security\n",
      "- Description: This section focuses on prompt safety and security considerations, including prompt injection and adversarial attacks. It identifies mitigation strategies and best practices for developing secure prompts.\n",
      "- Relevance: This section directly addresses the need to explore prompt safety and security considerations, including prompt injection and adversarial attacks, as outlined in the analysis.\n",
      "\n",
      "Title: Multi-Modal Prompting Techniques and Applications\n",
      "- Description: This section explores multi-modal prompting, which involves using various data modalities like text, images, audio, and video to get specific responses from LLMs.\n",
      "- Relevance: This section addresses the need to explore multi-modal prompting and its applications, focusing on how prompts can be used with different modalities to elicit specific responses from LLMs, as identified in the analysis.\n",
      "\n",
      "Title: Prompt Variations by Task/Industry\n",
      "- Description: This section explores how prompt engineering techniques can be adapted for different applications across various tasks and industries, such as marketing, education, and healthcare. It provides examples and use cases for each variation.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for specific tasks or industries, as outlined in the analysis.\n",
      "\n",
      "Title: Tools and Platforms for Prompt Engineering\n",
      "- Description: This section reviews various tools and platforms that can help users create, test, and optimize prompts. It focuses on functionality, pricing, and user reviews to provide a comprehensive overview.\n",
      "- Relevance: This section directly addresses the need to investigate and describe available tools and platforms for prompt engineering, as outlined in the analysis.\n",
      "\n",
      "Title: Bias and Fairness in Prompts: Identification and Mitigation\n",
      "- Description: This section discusses bias and fairness issues in prompts, focusing on identifying common biases and techniques for reducing them. It provides strategies for creating more equitable and unbiased prompts.\n",
      "- Relevance: This section directly addresses the need to explore bias and fairness issues in prompts and mitigation strategies, as outlined in the analysis.\n",
      "\n",
      "Title: Prompt Debugging Strategies for LLMs\n",
      "- Description: This section explores prompt debugging strategies for identifying and fixing issues with prompts. It focuses on practical techniques and examples to help users troubleshoot and improve their prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt debugging strategies for identifying and fixing issues, as outlined in the analysis.\n",
      "\n",
      "Title: Zero-Shot Prompt Types and Examples\n",
      "- Description: This section explores different types of zero-shot prompts, providing examples for each type and explaining when they're most effective, including simple question/instruction prompts, imperative prompts, declarative prompts, prompts with context, role-playing prompts, chain-of-thought prompting, and constraint prompts.\n",
      "- Relevance: This section directly addresses the need to research prompt variations for zero-shot prompting, as outlined in the analysis.\n",
      "\n",
      "Title: Real-World Case Studies of Advanced Prompting Techniques\n",
      "- Description: This section provides real-world case studies demonstrating the application of advanced prompting techniques such as chain-of-thought, tree-of-thought, and self-consistency. It details the problem, the technique used, and the results achieved.\n",
      "- Relevance: This section directly addresses the need to research real-world examples for advanced prompting techniques, as outlined in the analysis.\n",
      "\n",
      "Title: Impact of Few-Shot Example Quality on LLM Performance\n",
      "- Description: This section details how the choice of examples impacts the LLM's response in few-shot prompting. It provides examples of good and bad few-shot examples and explains why they differ, focusing on clarity, relevance, consistency, diversity, correctness, and representativeness.\n",
      "- Relevance: This section directly addresses the need to research variations of few-shot examples, as outlined in the analysis.\n",
      "</report>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Define Prompt Eng | Addition | Added an introduction section defining prompt engineering, its significance, and a brief overview of LLMs. |\n",
      "| Basic Prompting Tech | Addition | Added a section describing zero-shot, one-shot, and few-shot prompting techniques with definitions, explanations, and examples. |\n",
      "| Advanced Prompting Tech | Addition | Added a section explaining chain-of-thought, tree-of-thought, and self-consistency prompting techniques with definitions, explanations, and examples. |\n",
      "| Prompt Eng Applications | Addition | Added a section detailing how prompt engineering can be used to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving. |\n",
      "| Prompt Opt Tech | Addition | Added a section exploring prompt optimization techniques and their impact on LLM performance. |\n",
      "| Prompt Ensemb Methods | Addition | Added a section discussing prompt ensembling methods and their benefits. |\n",
      "| Prompt Safety & Security | Addition | Added a section focusing on prompt safety and security considerations. |\n",
      "| Multi-Modal Prompting | Addition | Added a section exploring multi-modal prompting techniques and applications. |\n",
      "| Task/Industry Var | Addition | Added a section exploring prompt variations for specific tasks or industries, including examples and use cases. |\n",
      "| Tools & Platforms | Addition | Added a section reviewing tools and platforms for prompt engineering, focusing on functionality, pricing, and user reviews. |\n",
      "| Bias & Fairness | Addition | Added a section discussing bias and fairness issues in prompts and mitigation strategies. |\n",
      "| Prompt Debugging | Addition | Added a section exploring prompt debugging strategies for identifying and fixing issues with prompts. |\n",
      "| Zero-Shot Ex & Var | Addition | Added a section exploring different types of zero-shot prompts, providing examples for each type. |\n",
      "| Adv Prompt Case Stud | Addition | Added a section providing real-world case studies demonstrating the application of advanced prompting techniques. |\n",
      "| Few-Shot Ex Quality | Addition | Added a section detailing how the choice of examples impacts the LLM's response in few-shot prompting. |\n",
      "</actions>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# Knowledge Base\n",
    "for line in research_state['knowledge_base'].split('\\n'):\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99a4b8b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1:\n",
      "Job:  Research and define the core concepts of prompt engineering, its significance in the context of large language models, and briefly touch upon how LLMs work to provide context. Focus on providing a clear and concise definition suitable for both non-technical and technical readers.\n",
      "Restrictions:  Avoid overly technical jargon and deep dives into LLM architecture. Target both technical and non-technical readers.\n",
      "Output Format:  A definition of prompt engineering, explanation of its significance, and a brief overview of how LLMs work (no deep dive).\n",
      "Variables:  ['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 2:\n",
      "Job:  Investigate and describe basic prompting techniques such as zero-shot, one-shot, and few-shot prompting. Provide formal definitions, explanations of why they work, and simple examples for each technique.\n",
      "Restrictions:  Avoid industry-focused content. Keep explanations concise and easy to understand.\n",
      "Output Format:  A description of each technique (zero-shot, one-shot, few-shot) including definition, explanation, and examples.\n",
      "Variables:  ['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 3:\n",
      "Job:  Explore and explain advanced prompting techniques like chain-of-thought, tree-of-thought, and self-consistency prompting. Provide formal definitions, explanations of why they work, and simple examples for each technique.\n",
      "Restrictions:  Avoid overly formal language. Keep explanations concise and easy to understand.\n",
      "Output Format:  A description of each technique (chain-of-thought, tree-of-thought, self-consistency) including definition, explanation, and examples.\n",
      "Variables:  ['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 4:\n",
      "Job:  Research how prompt engineering can be applied to improve factual accuracy, control style/tone, elicit creative content, and enhance reasoning/problem-solving abilities in LLMs. Provide examples for each application.\n",
      "Restrictions:  Avoid deep dives into specific industries. Focus on general techniques and applications.\n",
      "Output Format:  A description of each application (factual accuracy, style/tone, creative content, reasoning/problem-solving) with corresponding examples.\n",
      "Variables:  ['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 5:\n",
      "Job:  Research prompt optimization techniques, including token length optimization and prompt compression, and their impact on LLM performance. Focus on practical examples and measurable improvements.\n",
      "Restrictions:  Avoid deep dives into LLM architecture. Focus on techniques applicable to various LLMs.\n",
      "Output Format:  A summary of prompt optimization techniques, their benefits, and examples of how they improve LLM performance.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 6:\n",
      "Job:  Investigate prompt ensembling methods, including different ensembling strategies and their benefits in terms of accuracy, robustness, and creativity. Provide examples and potential drawbacks.\n",
      "Restrictions:  Avoid overly technical language. Focus on the practical aspects of prompt ensembling.\n",
      "Output Format:  A description of prompt ensembling methods, their advantages, disadvantages, and examples of their use.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 7:\n",
      "Job:  Explore prompt safety and security considerations, including prompt injection and adversarial attacks. Identify mitigation strategies and best practices for developing secure prompts.\n",
      "Restrictions:  Focus on practical security measures and avoid overly theoretical discussions.\n",
      "Output Format:  A report on prompt safety and security risks, along with mitigation techniques and best practices.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 8:\n",
      "Job:  Research multi-modal prompting techniques and their applications, focusing on how prompts can be used with images, audio, and video to elicit specific responses from LLMs. Provide examples and potential use cases.\n",
      "Restrictions:  Avoid deep dives into specific LLM architectures. Focus on general techniques applicable to various multi-modal LLMs.\n",
      "Output Format:  A description of multi-modal prompting techniques, their applications, and examples of their use with different modalities.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 9:\n",
      "Job:  Research prompt variations for specific tasks or industries (e.g., marketing, education, healthcare). Focus on providing examples and use cases for each variation.\n",
      "Restrictions:  Avoid industry-specific jargon.\n",
      "Output Format:  A list of prompt variations for different tasks/industries, with examples and use cases.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 10:\n",
      "Job:  Investigate and describe available tools and platforms for prompt engineering. Focus on functionality, pricing, and user reviews.\n",
      "Restrictions:  Focus on widely available and reputable tools.\n",
      "Output Format:  A list of tools and platforms for prompt engineering, with descriptions, pricing information, and user reviews.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 11:\n",
      "Job:  Explore bias and fairness issues in prompts and mitigation strategies. Focus on identifying common biases and techniques for reducing them.\n",
      "Restrictions:  Avoid overly technical or theoretical explanations.\n",
      "Output Format:  A report on bias and fairness in prompts, including common biases and mitigation strategies.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 12:\n",
      "Job:  Research prompt debugging strategies for identifying and fixing issues. Focus on practical techniques and examples.\n",
      "Restrictions:  Focus on techniques applicable to a wide range of LLMs.\n",
      "Output Format:  A list of prompt debugging strategies with practical techniques and examples.\n",
      "Variables:  ['knowledge_base', 'restrictions']\n",
      "--------------------------------------------------\n",
      "Job 13:\n",
      "Job:  Research specific examples and variations for basic prompting techniques like zero-shot, one-shot, and few-shot prompting. Focus on diverse examples across different domains.\n",
      "Restrictions:  Avoid examples that delve into complex technical details or industry-specific jargon.\n",
      "Output Format:  A list of examples and variations for each technique, including a brief explanation of each.\n",
      "Variables:  []\n",
      "--------------------------------------------------\n",
      "Job 14:\n",
      "Job:  Find real-world case studies demonstrating the application of advanced prompting techniques such as chain-of-thought, tree-of-thought, and self-consistency. Detail the problem, the technique used, and the results achieved.\n",
      "Restrictions:  Case studies should be accessible to both technical and non-technical audiences.\n",
      "Output Format:  Detailed descriptions of case studies, including the problem, technique, and results.\n",
      "Variables:  []\n",
      "--------------------------------------------------\n",
      "Job 15:\n",
      "Job:  Identify and describe different types of zero-shot prompts, providing examples for each type. Focus on the nuances of each type and when they are most effective.\n",
      "Restrictions:  Avoid overly technical explanations.\n",
      "Output Format:  A list of different types of zero-shot prompts with examples and explanations.\n",
      "Variables:  []\n",
      "--------------------------------------------------\n",
      "Job 16:\n",
      "Job:  Research variations of few-shot examples, detailing how the choice of examples impacts the LLM's response. Provide examples of good and bad few-shot examples and explain why they differ.\n",
      "Restrictions:  Focus on clear and concise explanations suitable for a general audience.\n",
      "Output Format:  A comparison of good and bad few-shot examples with explanations of their impact.\n",
      "Variables:  []\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# All delegated jobs\n",
    "for i,job in enumerate(research_state['all_jobs']):\n",
    "    print(f'Job {i+1}:')\n",
    "    print('Job: ', job.job)\n",
    "    print('Restrictions: ', job.restrictions)\n",
    "    print('Output Format: ', job.output_format)\n",
    "    print('Variables: ', job.variables)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc0b89",
   "metadata": {},
   "source": [
    "## Partial execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31f664e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm(llm_model='google')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')\n",
    "\n",
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=llm, memory=memory)\n",
    "]\n",
    "\n",
    "job_handler = JobHandlerSpecTool(\n",
    "    llm=llm,\n",
    "    tool_containers=tool_containers,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44348526",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_solver = PlannedIterativeTaskSolver(\n",
    "    llm=llm,\n",
    "    job_handler=job_handler,\n",
    "    initial_messages_spec=PlannedIterativeTaskSolverConfig.initial_messages_spec,\n",
    "    internal_messages_spec=PlannedIterativeTaskSolverConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    init_values=PlannedIterativeTaskSolverConfig.init_values,\n",
    "    prompt_manager_spec=PlannedIterativeTaskSolverConfig.prompt_manager_spec,\n",
    "    global_inputs=PlannedIterativeTaskSolverConfig.global_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa5301",
   "metadata": {},
   "source": [
    "### planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46335ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread_id = 'planning1'\n",
    "research_state = task_solver.graph.invoke(\n",
    "            input={\n",
    "                'template_inputs': inputs,\n",
    "                'turns': 0,\n",
    "                'knowledge_base': 'Empty'\n",
    "                },\n",
    "            config = {'configurable': {'thread_id': thread_id}},\n",
    "            interrupt_after='planning'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bcf7be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: system\n",
      "\n",
      "# **CONVERSATION PURPOSE**\n",
      "\n",
      "This conversation aims to:\n",
      "\n",
      "1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\n",
      "2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\n",
      "3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\n",
      "\n",
      "---\n",
      "\n",
      "# **WORKFLOW OVERVIEW**\n",
      "\n",
      "## **Workflow nodes**\n",
      "Each node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\n",
      "- Task Specification: The user provides the main task description and all necessary details.\n",
      "- Analysis: Assess the current knowledge base and formulate further research directions.\n",
      "- Jobs Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\n",
      "- Jobs Execution: Agents execute the assigned jobs, gathering data and insights.\n",
      "- Report Extension: Integrate collected results from agents to expand the knowledge base.\n",
      "- Final Report: Compile the comprehensive knowledge base into a final report addressing the main task.\n",
      "\n",
      "## **Workflow Schema**\n",
      "The workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\n",
      "\n",
      "**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "# **AVAILABLE AGENTS**\n",
      "- **external_research**: Conducts web searches including academic papers, news, and other online resources.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **MAIN TASK** \n",
      "*Here is the main goal of the task:*\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "## **RESTRICTIONS** \n",
      "*At every stage of the process bear in mind the following restrictions:*\n",
      "\n",
      "    1. List only real prompting techniques\n",
      "    2. Do not include techniques that are just applications of other techniques\n",
      "    3. Do not include techniques that are not related to CoT prompting\n",
      "\n",
      "## **OUTPUT FORMAT** \n",
      "*The final report should be written in the following format:*\n",
      "List of techniques with very short description of each technique\n",
      "\n",
      "## **CONTEXTUAL DATA** \n",
      "*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\n",
      "```\n",
      "None\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Empty\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 1\n"
     ]
    }
   ],
   "source": [
    "for msg in research_state['current_messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f45eae2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'template_inputs': {'job': 'List all Chain-of-Thought prompting variants',\n",
       "  'restrictions': '\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting',\n",
       "  'output_format': 'List of techniques with very short description of each technique',\n",
       "  'data': 'None'},\n",
       " 'turns': 1,\n",
       " 'knowledge_base': 'Empty',\n",
       " 'current_messages': [SystemMessage(content=\"# **CONVERSATION PURPOSE**\\n\\nThis conversation aims to:\\n\\n1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\\n2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\\n3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\\n\\n---\\n\\n# **WORKFLOW OVERVIEW**\\n\\n## **Workflow nodes**\\nEach node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\\n- Task Specification: The user provides the main task description and all necessary details.\\n- Analysis: Assess the current knowledge base and formulate further research directions.\\n- Jobs Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\\n- Jobs Execution: Agents execute the assigned jobs, gathering data and insights.\\n- Report Extension: Integrate collected results from agents to expand the knowledge base.\\n- Final Report: Compile the comprehensive knowledge base into a final report addressing the main task.\\n\\n## **Workflow Schema**\\nThe workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\\n\\n**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Report**\\n\\n---\\n\\n# **AVAILABLE AGENTS**\\n- **external_research**: Conducts web searches including academic papers, news, and other online resources.\", additional_kwargs={}, response_metadata={}, name='system'),\n",
       "  HumanMessage(content='# **TASK DESCRIPTION**\\n\\n## **MAIN TASK** \\n*Here is the main goal of the task:*\\nList all Chain-of-Thought prompting variants\\n\\n## **RESTRICTIONS** \\n*At every stage of the process bear in mind the following restrictions:*\\n\\n    1. List only real prompting techniques\\n    2. Do not include techniques that are just applications of other techniques\\n    3. Do not include techniques that are not related to CoT prompting\\n\\n## **OUTPUT FORMAT** \\n*The final report should be written in the following format:*\\nList of techniques with very short description of each technique\\n\\n## **CONTEXTUAL DATA** \\n*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\\n```\\nNone\\n```', additional_kwargs={}, response_metadata={}, name='query'),\n",
       "  HumanMessage(content='# CURRENT PHASE:\\n\\nYou are now at the **Analysis** phase of research process.\\n    * Task Specification\\n    -> Analysis\\n    * Jobs Distribution\\n    * Jobs Execution\\n    * Report Extension\\n    * Final Report\\n\\n## **ANALYSIS STEPS**\\n\\n1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\\n    - *focus primarily on the description of the current knowledge base completion level*\\n\\n2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\\n    - *Strategy description: Provide an overview of the overall research approach.*\\n    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\\n    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\\n    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\\n    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\\n\\n3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\\n    - *collect research objectives as simple list based on prior analysis steps*\\n\\n---\\n\\n## **ANALYSIS INSTRUCTIONS**\\n- use descriptive style\\n- follow directly provided analysis steps and output format\\n- perform every action in terms of realization of the main task\\n- focus explicitly on paths for expanding the knowledge base\\n- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\\n\\n---\\n\\n## **ANALYSIS OUTPUT FORMAT**\\n```\\n### **KNOWLEDGE SUMMARY**\\n[knowledge summary description]\\n\\n### **STRATEGICAL REASONING**\\n\\n#### Strategy description\\n[strategical reasoning description]\\n\\n#### Existing areas expansion\\n[explanation of how existing areas should be expanded]\\n\\n#### New areas exploration\\n[explanation of possible new areas to explore]\\n\\n### **THESES FORMULATION**\\n- [thesis 1]\\n- [thesis 2]\\n...\\n- [thesis N]\\n```\\n\\n---\\n\\n## **Knowledge Base**\\nEmpty', additional_kwargs={}, response_metadata={}, name='planning'),\n",
       "  AIMessage(content='Fake LLM response 1', additional_kwargs={}, response_metadata={})],\n",
       " 'branch:to:distribution': None}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task_solver.get_state(thread_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b473de",
   "metadata": {},
   "source": [
    "### jobs distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b65604f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning turn 1...\n",
      "Jobs Distribution turn 1...\n"
     ]
    }
   ],
   "source": [
    "thread_id = 'distribution1'\n",
    "research_state = task_solver.graph.invoke(\n",
    "            input={\n",
    "                'template_inputs': inputs,\n",
    "                'turns': 0,\n",
    "                'knowledge_base': 'Empty'\n",
    "                },\n",
    "            config = {'configurable': {'thread_id': thread_id}},\n",
    "            interrupt_after='distribution'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fc4e3f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: system\n",
      "\n",
      "# **CONVERSATION PURPOSE**\n",
      "\n",
      "This conversation aims to:\n",
      "\n",
      "1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\n",
      "2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\n",
      "3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\n",
      "\n",
      "---\n",
      "\n",
      "# **WORKFLOW OVERVIEW**\n",
      "\n",
      "## **Workflow nodes**\n",
      "Each node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\n",
      "- Task Specification: The user provides the main task description and all necessary details.\n",
      "- Analysis: Assess the current knowledge base and formulate further research directions.\n",
      "- Jobs Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\n",
      "- Jobs Execution: Agents execute the assigned jobs, gathering data and insights.\n",
      "- Report Extension: Integrate collected results from agents to expand the knowledge base.\n",
      "- Final Report: Compile the comprehensive knowledge base into a final report addressing the main task.\n",
      "\n",
      "## **Workflow Schema**\n",
      "The workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\n",
      "\n",
      "**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "# **AVAILABLE AGENTS**\n",
      "- **external_research**: Conducts web searches including academic papers, news, and other online resources.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **MAIN TASK** \n",
      "*Here is the main goal of the task:*\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "## **RESTRICTIONS** \n",
      "*At every stage of the process bear in mind the following restrictions:*\n",
      "\n",
      "    1. List only real prompting techniques\n",
      "    2. Do not include techniques that are just applications of other techniques\n",
      "    3. Do not include techniques that are not related to CoT prompting\n",
      "\n",
      "## **OUTPUT FORMAT** \n",
      "*The final report should be written in the following format:*\n",
      "List of techniques with very short description of each technique\n",
      "\n",
      "## **CONTEXTUAL DATA** \n",
      "*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\n",
      "```\n",
      "None\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Report Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Empty\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "The current knowledge base is empty. Therefore, there is no information about Chain-of-Thought prompting variants. The immediate need is to identify and gather information on various CoT prompting techniques.\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "The research strategy will involve a broad initial search to identify potential CoT variants, followed by more focused investigations into each identified technique. This iterative approach will ensure comprehensive coverage while adhering to the specified restrictions. We will prioritize identifying distinct prompting techniques and avoid including mere applications or unrelated methods.\n",
      "\n",
      "#### Existing areas expansion\n",
      "Since the knowledge base is currently empty, there are no existing areas to expand. The initial research will establish the foundation for subsequent expansion in later iterations.\n",
      "\n",
      "#### New areas exploration\n",
      "The primary area to explore is the landscape of Chain-of-Thought prompting variants. This includes:\n",
      "\n",
      "1.  **Basic CoT**: Understanding the fundamental CoT approach.\n",
      "2.  **Self-Consistency**: Investigating techniques that promote consistent reasoning.\n",
      "3.  **Least-to-Most Prompting**: Exploring methods that break down complex problems into simpler steps.\n",
      "4.  **Tree-of-Thoughts (ToT)**: Researching techniques that involve exploring multiple reasoning paths.\n",
      "5.  **Graph of Thoughts (GoT)**: Researching techniques that generalize ToT.\n",
      "6.  **Program-aided Language Models (PAL)**: Researching techniques that use code generation to aid reasoning.\n",
      "7.  **Chain-of-Verification (CoVe)**: Researching techniques that involve verifying the reasoning steps.\n",
      "8.  **Directional Stimulus Prompting**: Researching techniques that use external knowledge to guide reasoning.\n",
      "\n",
      "These areas will be explored through web searches, academic papers, and other online resources.\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- Research and gather information on the basic Chain-of-Thought (CoT) prompting technique.\n",
      "- Investigate Self-Consistency as a CoT variant.\n",
      "- Explore Least-to-Most Prompting as a CoT variant.\n",
      "- Research Tree-of-Thoughts (ToT) prompting.\n",
      "- Research Graph of Thoughts (GoT) prompting.\n",
      "- Research Program-aided Language Models (PAL).\n",
      "- Research Chain-of-Verification (CoVe) prompting.\n",
      "- Research Directional Stimulus Prompting.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for msg in research_state['current_messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09b91fbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1:\n",
      "Research and summarize the Chain-of-Thought (CoT) prompting technique, including its core principles and variations.\n",
      "Focus on the prompting technique itself, not its applications. Adhere to the general restrictions.\n",
      "A short description of the technique.\n",
      "['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 2:\n",
      "Investigate and summarize Self-Consistency and Least-to-Most Prompting as Chain-of-Thought variants.\n",
      "Focus on the prompting techniques themselves, not their applications. Adhere to the general restrictions.\n",
      "Short descriptions of each technique, highlighting their differences and similarities.\n",
      "['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 3:\n",
      "Research and summarize Tree-of-Thoughts (ToT) and Graph of Thoughts (GoT) prompting techniques.\n",
      "Focus on the prompting techniques themselves, not their applications. Adhere to the general restrictions.\n",
      "Short descriptions of each technique, highlighting their differences and similarities.\n",
      "['restrictions']\n",
      "--------------------------------------------------\n",
      "Job 4:\n",
      "Research and summarize Program-aided Language Models (PAL), Chain-of-Verification (CoVe) and Directional Stimulus Prompting.\n",
      "Focus on the prompting techniques themselves, not their applications. Adhere to the general restrictions.\n",
      "Short descriptions of each technique, highlighting their differences and similarities.\n",
      "['restrictions']\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i,job in enumerate(research_state['current_jobs']):\n",
    "    print(f'Job {i+1}:')\n",
    "    print(job.job)\n",
    "    print(job.restrictions)\n",
    "    print(job.output_format)\n",
    "    print(job.variables)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5a810b9",
   "metadata": {},
   "source": [
    "### knowledge extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2622d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planning turn 1...\n",
      "Jobs Distribution turn 1...\n"
     ]
    }
   ],
   "source": [
    "thread_id = 'base_extension1'\n",
    "research_state = task_solver.graph.invoke(\n",
    "            input={\n",
    "                'template_inputs': inputs,\n",
    "                'turns': 0,\n",
    "                'knowledge_base': 'Empty'\n",
    "                },\n",
    "            config = {'configurable': {'thread_id': thread_id}},\n",
    "            interrupt_after='base_extension'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31927081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "Name: system\n",
      "\n",
      "# **CONVERSATION PURPOSE**\n",
      "\n",
      "This conversation aims to:\n",
      "\n",
      "1.  **Acquire Data**: Systematically gather all data relevant to the research's **MAIN TASK**.\n",
      "2.  **Plan Strategically**: Conduct iterative research, moving from general to specific topics.\n",
      "3.  **Ensure Comprehensive Output**: Continuously analyze the **MAIN TASK** description to ensure all necessary data is collected.\n",
      "\n",
      "---\n",
      "\n",
      "# **WORKFLOW OVERVIEW**\n",
      "\n",
      "## **Workflow nodes**\n",
      "Each node has a specific role. Focus solely on the current node's task without anticipating subsequent steps.\n",
      "- Task Specification: The user provides the main task description and all necessary details.\n",
      "- Analysis: Assess the current knowledge base and formulate further research directions.\n",
      "- Jobs Distribution: Based on the analysis, delegate specific research jobs to specialized agents.\n",
      "- Jobs Execution: Agents execute the assigned jobs, gathering data and insights.\n",
      "- Knowledge Extension: Integrate collected results from agents to expand the knowledge base.\n",
      "- Final Report: Compile the comprehensive knowledge base into a final report addressing the main task.\n",
      "\n",
      "## **Workflow Schema**\n",
      "The workflow operates in a loop: after each knowledge base extension, the process returns to the Analysis step. The loop concludes, and the Final Report is generated, when the main task is fully addressed or the iteration limit of `4` is reached.\n",
      "\n",
      "**Task Specification -> Analysis -> Job Distribution -> Report Extension -> Analysis -> ... -> Final Report**\n",
      "\n",
      "---\n",
      "\n",
      "# **AVAILABLE AGENTS**\n",
      "- **external_research**: Conducts web searches including academic papers, news, and other online resources.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: query\n",
      "\n",
      "# **TASK DESCRIPTION**\n",
      "\n",
      "## **MAIN TASK** \n",
      "*Here is the main goal of the task:*\n",
      "List all Chain-of-Thought prompting variants\n",
      "\n",
      "## **RESTRICTIONS** \n",
      "*At every stage of the process bear in mind the following restrictions:*\n",
      "\n",
      "    1. List only real prompting techniques\n",
      "    2. Do not include techniques that are just applications of other techniques\n",
      "    3. Do not include techniques that are not related to CoT prompting\n",
      "\n",
      "## **OUTPUT FORMAT** \n",
      "*The final report should be written in the following format:*\n",
      "List of techniques with very short description of each technique\n",
      "\n",
      "## **CONTEXTUAL DATA** \n",
      "*This is additional, fixed information provided for your reference during task resolution. Use it to either better planning or knowledge base extension.*\n",
      "```\n",
      "None\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: planning\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Analysis** phase of research process.\n",
      "    * Task Specification\n",
      "    -> Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    * Knowledge Extension\n",
      "    * Final Report\n",
      "\n",
      "## **ANALYSIS STEPS**\n",
      "\n",
      "1. **Knowledge summary**: Summarize the current knowledge base to identify gaps and areas needing further research.\n",
      "    - *focus primarily on the description of the current knowledge base completion level*\n",
      "\n",
      "2. **Strategical reasoning**: Think in a tree based manner, formulating a plan that will spread widely to cover all aspects of the main task.\n",
      "    - *Strategy description: Provide an overview of the overall research approach.*\n",
      "    - *Existing areas expansion: Explain how to deepen understanding in already covered subjects.*\n",
      "    - *New areas exploration: Detail potential new research directions, subjects, or fields not yet covered.*\n",
      "    - *prioritize subjects based on their relevance to the main task and the current knowledge base*\n",
      "    - *take into account that this is an iterative research process and you are currently at 1 turn of maximum 4 iterations*\n",
      "    - *consider prior jobs summarized in the knowledge base to avoid redundancy and ensure new research paths are distinct*\n",
      "\n",
      "3. **Theses Formulation**: Formulate set of specific theses of what subjects should be researched to address the main task.\n",
      "    - *collect research objectives as simple list based on prior analysis steps*\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS INSTRUCTIONS**\n",
      "- use descriptive style\n",
      "- follow directly provided analysis steps and output format\n",
      "- perform every action in terms of realization of the main task\n",
      "- focus explicitly on paths for expanding the knowledge base\n",
      "- in ideal case, the knowledge base should have slighlty more data than needed to address the main task\n",
      "\n",
      "---\n",
      "\n",
      "## **ANALYSIS OUTPUT FORMAT**\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "[knowledge summary description]\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "[strategical reasoning description]\n",
      "\n",
      "#### Existing areas expansion\n",
      "[explanation of how existing areas should be expanded]\n",
      "\n",
      "#### New areas exploration\n",
      "[explanation of possible new areas to explore]\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- [thesis 1]\n",
      "- [thesis 2]\n",
      "...\n",
      "- [thesis N]\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "## **Knowledge Base**\n",
      "Empty\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "### **KNOWLEDGE SUMMARY**\n",
      "The current knowledge base is empty. Therefore, the analysis will focus on identifying and prioritizing potential Chain-of-Thought (CoT) prompting variants to fulfill the main task.\n",
      "\n",
      "### **STRATEGICAL REASONING**\n",
      "\n",
      "#### Strategy description\n",
      "The research strategy will involve a broad initial search for CoT prompting variants, followed by a filtering process to ensure each technique meets the specified restrictions (real, not just applications, and related to CoT). The search will prioritize identifying core CoT techniques before exploring more specialized or less common variants.\n",
      "\n",
      "#### Existing areas expansion\n",
      "Since the knowledge base is currently empty, there are no existing areas to expand. The initial focus will be on establishing a foundation of well-known CoT techniques.\n",
      "\n",
      "#### New areas exploration\n",
      "The exploration will cover several areas:\n",
      "1. **Basic CoT:** Identify the fundamental CoT prompting technique and its core principles.\n",
      "2. **Advanced CoT:** Explore advanced CoT variants, such as those incorporating external knowledge or specialized reasoning strategies.\n",
      "3. **Application-specific CoT:** Investigate CoT techniques tailored for specific tasks or domains (e.g., mathematical reasoning, commonsense reasoning).\n",
      "4. **Theoretical Underpinnings:** Briefly touch upon the theoretical explanations for why CoT works, as this might reveal different ways CoT is implemented.\n",
      "\n",
      "### **THESES FORMULATION**\n",
      "- Research the fundamental principles and implementation of the basic Chain-of-Thought (CoT) prompting technique.\n",
      "- Investigate advanced CoT prompting variants, including those that incorporate external knowledge or specialized reasoning strategies.\n",
      "- Identify application-specific CoT techniques tailored for particular tasks or domains (e.g., mathematical reasoning, commonsense reasoning).\n",
      "- Explore the theoretical explanations for why CoT works, looking for insights into different CoT implementation methods.\n",
      "```\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "Name: base_extension\n",
      "\n",
      "# CURRENT PHASE:\n",
      "\n",
      "You are now at the **Knowledge Extension** phase of research process.\n",
      "    * Task Specification\n",
      "    * Analysis\n",
      "    * Jobs Distribution\n",
      "    * Jobs Execution\n",
      "    -> Knowledge Extension\n",
      "    * Final Report\n",
      "\n",
      "## **KNOWLEDGE EXTENSION PHASE DESCRIPTION**\n",
      "This phase is responsible for integrating the results from the Jobs Execution phase into the knowledge base. The goal is to expand the knowledge base with new data collected by agents.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION INSTRUCTIONS**\n",
      "- **Base on jobs**: Use list of current **JOBS** to determine what is the purpose of the newly collected data so you can add it to knowledge base in proper format.\n",
      "- **Prevent duplicates**: If some parts of **NEW DATA** are already present in the knowledge base, just extend it in-place with new information, except a situation where new piece of information is dedicated to a different section.\n",
      "- **Extend or modify**: \"If some parts of NEW DATA are already present in the knowledge base, integrate new information by extending existing entries. Only create a new section if the new data introduces a distinct topic or a fundamentally different aspect that cannot logically extend an existing section.\"\n",
      "- **Just formatted output**: In your answer include only the formatted output without any additional explanations or comments.\n",
      "- **Keep existing data**: Both **data** and **actions** sections should contain all previously collected data, not just the new one.\n",
      "\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE EXTENSION OUTPUT FORMAT**\n",
      "\n",
      "Knowledge base consist of 2 main parts:\n",
      "- **data**: The main body of knowledge, which is a collection of structured data entries.\n",
      "- **actions**: List of shortened descriptions of modification or extension actions performed to the existing data. Every action should follow the tabular format: \"| [job title] | [Addition/Modification/Verification] | [short description of the action] |\".\n",
      "\n",
      "**Output format:**\n",
      "```\n",
      "<data>\n",
      "### **DATA REPORT**\n",
      "#### [Section 1 title]\n",
      "[section 1 content]\n",
      "#### [Section 2 title]\n",
      "[section 2 content]\n",
      "...\n",
      "</data>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| [Job 1 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 1] |\n",
      "| [Job 2 Title] | [Addition/Modification/Verification] | [Short description of the action performed for Job 2] |\n",
      "| ... | ... | ... |\n",
      "</actions>\n",
      "```\n",
      "---\n",
      "\n",
      "## **KNOWLEDGE BASE**\n",
      "Empty\n",
      "\n",
      "---\n",
      "\n",
      "## **COLLECTED NEW DATA**\n",
      "**Chain-of-Thought (CoT) Prompting: A Summary**\n",
      "\n",
      "Chain-of-Thought (CoT) prompting is a technique that enhances the reasoning abilities of large language models (LLMs). It involves providing the LLM with a few examples demonstrating step-by-step reasoning, then presenting the question. The LLM follows the demonstrated pattern to generate its own chain of thought, leading to the final answer. Core components include demonstrations with step-by-step reasoning and a final question for the model to solve by emulating the demonstrated reasoning process.\n",
      "-----\n",
      "**Advanced Chain-of-Thought (CoT) Prompting Variants**\n",
      "\n",
      "Here are some advanced Chain-of-Thought (CoT) prompting variants that incorporate external knowledge or specialized reasoning strategies, distinct from basic CoT, and have demonstrated effectiveness:\n",
      "\n",
      "1.  **Knowledge-Augmented CoT:** This variant enhances the reasoning process by explicitly providing the model with relevant external knowledge before or during the CoT process. This knowledge can be retrieved from knowledge bases, pre-trained language models, or provided directly in the prompt.\n",
      "\n",
      "    *   **Example:** \"To answer this question about [complex topic], consider these facts: [relevant facts from a knowledge base]. Now, let's think step by step...\"\n",
      "\n",
      "2.  **Graph CoT:** Uses graph structures to represent relationships between concepts or entities within the problem. The model navigates the graph during the reasoning process, leveraging connections to derive the solution.\n",
      "\n",
      "    *   **Example:** \"We can represent the problem as a graph where nodes are [entities] and edges are [relationships]. Starting from [initial node], we traverse the graph by [reasoning steps] to reach [final node], which gives us the answer.\"\n",
      "\n",
      "3.  **Decomposed CoT:** Breaks down complex problems into smaller, more manageable subproblems. The model solves each subproblem independently using CoT and then combines the solutions to answer the original question.\n",
      "\n",
      "    *   **Example:** \"To solve this problem, let's first identify the subproblems: 1) [Subproblem 1], 2) [Subproblem 2], 3) [Subproblem 3]. We solve each subproblem using chain of thought. Finally, we combine the answers to subproblems 1, 2, and 3 to get the final answer.\"\n",
      "-----\n",
      "## Application-Specific Chain-of-Thought Techniques\n",
      "\n",
      "*   **Mathematical Reasoning: Program-of-Thought (PoT)**\n",
      "\n",
      "    *   *Description:* PoT prompting encourages the language model to generate a program (e.g., Python code) that, when executed, produces the answer to a mathematical problem. The \"chain of thought\" is expressed as executable code, allowing for more precise and verifiable reasoning steps.\n",
      "    *   *Target Task/Domain:* Complex mathematical problems, especially those requiring numerical computation or symbolic manipulation.\n",
      "*   **Commonsense Reasoning: Knowledge-augmented CoT**\n",
      "\n",
      "    *   *Description:* This technique incorporates external knowledge (e.g., from knowledge graphs or commonsense databases) into the CoT process. The model retrieves relevant facts or rules and uses them to guide its reasoning steps. For example, when answering a question about why someone might be sad, the model could retrieve facts about events that typically cause sadness.\n",
      "    *   *Target Task/Domain:* Commonsense reasoning tasks, question answering requiring background knowledge.\n",
      "*   **Scientific Reasoning: Theory-of-Mind CoT**\n",
      "\n",
      "    *   *Description:* This approach focuses on modeling the mental states (beliefs, desires, intentions) of agents in a scenario. The model simulates the reasoning process of each agent, taking into account their knowledge and goals, to predict their actions or explain their behavior.\n",
      "    *   *Target Task/Domain:* Social reasoning, understanding intentions, predicting behavior in social contexts.\n",
      "*   **Code Generation: Execution-Guided CoT**\n",
      "\n",
      "    *   *Description:* This technique involves executing the code generated by the language model and using the execution results to refine the CoT process. If the initial code produces an error or an incorrect output, the model analyzes the error message and adjusts its reasoning steps to generate a corrected version of the code.\n",
      "    *   *Target Task/Domain:* Code generation, program synthesis, debugging.\n",
      "*   **Planning: Goal-oriented CoT**\n",
      "\n",
      "    *   *Description:* This method structures the CoT process around a specific goal. The model first identifies the goal, then generates a sequence of actions or steps that lead to the achievement of that goal. Each step in the chain of thought represents a decision or action taken to move closer to the desired outcome.\n",
      "    *   *Target Task/Domain:* Planning, decision-making, problem-solving.\n",
      "-----\n",
      "Title: Theoretical Explanations and Implementation Variations for Chain of Thought (CoT)\n",
      "\n",
      "### Theoretical Explanations for Chain of Thought (CoT) Effectiveness\n",
      "\n",
      "Chain of Thought (CoT) prompting is a technique used to improve the reasoning abilities of large language models (LLMs) by eliciting intermediate reasoning steps. Several theories attempt to explain why CoT is effective.\n",
      "\n",
      "**1. Step-by-Step Reasoning Mimics Human Cognition:**\n",
      "\n",
      "*   **Theory:** CoT prompting encourages the model to break down complex problems into smaller, more manageable steps, mirroring how humans approach problem-solving. This step-by-step approach reduces cognitive load and allows the model to focus on each sub-problem individually.\n",
      "*   **Mechanism:** By explicitly generating intermediate reasoning steps, the model is guided to follow a logical path towards the final answer. This process helps the model avoid \"jumping\" to conclusions based on superficial patterns in the input.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Curriculum Learning:** Gradually increase the complexity of the problems presented to the model during training, along with corresponding CoT examples. This helps the model learn to decompose problems effectively.\n",
      "    *   **Self-Consistency Decoding:** Generate multiple CoT paths for a single question and select the most consistent answer across these paths. This can improve the robustness of the model's reasoning.\n",
      "\n",
      "**2. Enhanced Representation Learning:**\n",
      "\n",
      "*   **Theory:** CoT prompting forces the model to generate more detailed and structured representations of the problem and its solution. These richer representations facilitate better understanding and reasoning.\n",
      "*   **Mechanism:** The intermediate reasoning steps act as a form of \"self-explanation,\" which helps the model to refine its internal representation of the problem. This can be seen as a form of implicit fine-tuning, where the model adapts its knowledge to the specific task at hand.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Knowledge Integration:** Incorporate external knowledge sources (e.g., knowledge graphs, databases) into the CoT process. This can provide the model with additional information and context to support its reasoning.\n",
      "    *   **Attention Mechanisms:** Use attention mechanisms to highlight the most relevant parts of the input and intermediate reasoning steps. This can help the model focus on the most important information and improve its reasoning accuracy.\n",
      "\n",
      "**3. Improved Gradient Flow During Training:**\n",
      "\n",
      "*   **Theory:** During training, the presence of intermediate reasoning steps in CoT examples can improve the flow of gradients through the model's network. This can lead to better learning and generalization.\n",
      "*   **Mechanism:** The intermediate steps provide more \"supervisory signals\" to the model, guiding it towards the correct solution. This can be particularly helpful for complex problems where the relationship between the input and output is not immediately obvious.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Reinforcement Learning:** Use reinforcement learning to train the model to generate CoT paths that lead to the correct answer. This can help the model learn to explore different reasoning strategies and find the most effective ones.\n",
      "    *   **Adversarial Training:** Train the model to be robust to adversarial examples that are designed to disrupt its reasoning process. This can improve the model's ability to generalize to unseen problems.\n",
      "\n",
      "**4. Alignment with Human-Interpretable Reasoning:**\n",
      "\n",
      "*   **Theory:** CoT's effectiveness stems from its alignment with human-understandable reasoning processes. By generating explicit reasoning steps, the model's thought process becomes more transparent and interpretable.\n",
      "*   **Mechanism:** This alignment can improve trust and acceptance of the model's outputs, particularly in high-stakes applications where explainability is crucial.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Explanation Generation:** Train the model to generate explanations for its reasoning steps, providing further insights into its thought process.\n",
      "    *   **Interactive Reasoning:** Allow users to interact with the model during the CoT process, providing feedback and guidance to improve its reasoning.\n",
      "\n",
      "These theories provide a foundation for understanding the effectiveness of CoT prompting. Further research is needed to fully elucidate the underlying mechanisms and to develop more effective CoT techniques.\n",
      "\n",
      "---\n",
      "\n",
      "## **JOBS**\n",
      "These are the jobs from the current iteration:\n",
      "Job 1: Research and summarize the fundamental principles and implementation of the basic Chain-of-Thought (CoT) prompting technique.\n",
      "Job 2: Investigate and describe advanced CoT prompting variants, focusing on techniques that incorporate external knowledge or specialized reasoning strategies. Provide examples of each variant.\n",
      "Job 3: Identify and describe application-specific CoT techniques tailored for particular tasks or domains, such as mathematical reasoning or commonsense reasoning. Provide the task or domain that each technique is designed for.\n",
      "Job 4: Explore and summarize the theoretical explanations for why CoT works. Identify if these explanations suggest different implementation methods or variations of CoT.\n",
      "\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "```\n",
      "<data>\n",
      "### **DATA REPORT**\n",
      "#### **Chain-of-Thought (CoT) Prompting: A Summary**\n",
      "Chain-of-Thought (CoT) prompting is a technique that enhances the reasoning abilities of large language models (LLMs). It involves providing the LLM with a few examples demonstrating step-by-step reasoning, then presenting the question. The LLM follows the demonstrated pattern to generate its own chain of thought, leading to the final answer. Core components include demonstrations with step-by-step reasoning and a final question for the model to solve by emulating the demonstrated reasoning process.\n",
      "\n",
      "#### **Advanced Chain-of-Thought (CoT) Prompting Variants**\n",
      "Here are some advanced Chain-of-Thought (CoT) prompting variants that incorporate external knowledge or specialized reasoning strategies, distinct from basic CoT, and have demonstrated effectiveness:\n",
      "\n",
      "1.  **Knowledge-Augmented CoT:** This variant enhances the reasoning process by explicitly providing the model with relevant external knowledge before or during the CoT process. This knowledge can be retrieved from knowledge bases, pre-trained language models, or provided directly in the prompt.\n",
      "\n",
      "    *   **Example:** \"To answer this question about [complex topic], consider these facts: [relevant facts from a knowledge base]. Now, let's think step by step...\"\n",
      "\n",
      "2.  **Graph CoT:** Uses graph structures to represent relationships between concepts or entities within the problem. The model navigates the graph during the reasoning process, leveraging connections to derive the solution.\n",
      "\n",
      "    *   **Example:** \"We can represent the problem as a graph where nodes are [entities] and edges are [relationships]. Starting from [initial node], we traverse the graph by [reasoning steps] to reach [final node], which gives us the answer.\"\n",
      "\n",
      "3.  **Decomposed CoT:** Breaks down complex problems into smaller, more manageable subproblems. The model solves each subproblem independently using CoT and then combines the solutions to answer the original question.\n",
      "\n",
      "    *   **Example:** \"To solve this problem, let's first identify the subproblems: 1) [Subproblem 1], 2) [Subproblem 2], 3) [Subproblem 3]. We solve each subproblem using chain of thought. Finally, we combine the answers to subproblems 1, 2, and 3 to get the final answer.\"\n",
      "\n",
      "#### **Application-Specific Chain-of-Thought Techniques**\n",
      "*   **Mathematical Reasoning: Program-of-Thought (PoT)**\n",
      "\n",
      "    *   *Description:* PoT prompting encourages the language model to generate a program (e.g., Python code) that, when executed, produces the answer to a mathematical problem. The \"chain of thought\" is expressed as executable code, allowing for more precise and verifiable reasoning steps.\n",
      "    *   *Target Task/Domain:* Complex mathematical problems, especially those requiring numerical computation or symbolic manipulation.\n",
      "*   **Commonsense Reasoning: Knowledge-augmented CoT**\n",
      "\n",
      "    *   *Description:* This technique incorporates external knowledge (e.g., from knowledge graphs or commonsense databases) into the CoT process. The model retrieves relevant facts or rules and uses them to guide its reasoning steps. For example, when answering a question about why someone might be sad, the model could retrieve facts about events that typically cause sadness.\n",
      "    *   *Target Task/Domain:* Commonsense reasoning tasks, question answering requiring background knowledge.\n",
      "*   **Scientific Reasoning: Theory-of-Mind CoT**\n",
      "\n",
      "    *   *Description:* This approach focuses on modeling the mental states (beliefs, desires, intentions) of agents in a scenario. The model simulates the reasoning process of each agent, taking into account their knowledge and goals, to predict their actions or explain their behavior.\n",
      "    *   *Target Task/Domain:* Social reasoning, understanding intentions, predicting behavior in social contexts.\n",
      "*   **Code Generation: Execution-Guided CoT**\n",
      "\n",
      "    *   *Description:* This technique involves executing the code generated by the language model and using the execution results to refine the CoT process. If the initial code produces an error or an incorrect output, the model analyzes the error message and adjusts its reasoning steps to generate a corrected version of the code.\n",
      "    *   *Target Task/Domain:* Code generation, program synthesis, debugging.\n",
      "*   **Planning: Goal-oriented CoT**\n",
      "\n",
      "    *   *Description:* This method structures the CoT process around a specific goal. The model first identifies the goal, then generates a sequence of actions or steps that lead to the achievement of that goal. Each step in the chain of thought represents a decision or action taken to move closer to the desired outcome.\n",
      "    *   *Target Task/Domain:* Planning, decision-making, problem-solving.\n",
      "\n",
      "#### **Theoretical Explanations and Implementation Variations for Chain of Thought (CoT)**\n",
      "\n",
      "### Theoretical Explanations for Chain of Thought (CoT) Effectiveness\n",
      "\n",
      "Chain of Thought (CoT) prompting is a technique used to improve the reasoning abilities of large language models (LLMs) by eliciting intermediate reasoning steps. Several theories attempt to explain why CoT is effective.\n",
      "\n",
      "**1. Step-by-Step Reasoning Mimics Human Cognition:**\n",
      "\n",
      "*   **Theory:** CoT prompting encourages the model to break down complex problems into smaller, more manageable steps, mirroring how humans approach problem-solving. This step-by-step approach reduces cognitive load and allows the model to focus on each sub-problem individually.\n",
      "*   **Mechanism:** By explicitly generating intermediate reasoning steps, the model is guided to follow a logical path towards the final answer. This process helps the model avoid \"jumping\" to conclusions based on superficial patterns in the input.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Curriculum Learning:** Gradually increase the complexity of the problems presented to the model during training, along with corresponding CoT examples. This helps the model learn to decompose problems effectively.\n",
      "    *   **Self-Consistency Decoding:** Generate multiple CoT paths for a single question and select the most consistent answer across these paths. This can improve the robustness of the model's reasoning.\n",
      "\n",
      "**2. Enhanced Representation Learning:**\n",
      "\n",
      "*   **Theory:** CoT prompting forces the model to generate more detailed and structured representations of the problem and its solution. These richer representations facilitate better understanding and reasoning.\n",
      "*   **Mechanism:** The intermediate reasoning steps act as a form of \"self-explanation,\" which helps the model to refine its internal representation of the problem. This can be seen as a form of implicit fine-tuning, where the model adapts its knowledge to the specific task at hand.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Knowledge Integration:** Incorporate external knowledge sources (e.g., knowledge graphs, databases) into the CoT process. This can provide the model with additional information and context to support its reasoning.\n",
      "    *   **Attention Mechanisms:** Use attention mechanisms to highlight the most relevant parts of the input and intermediate reasoning steps. This can help the model focus on the most important information and improve its reasoning accuracy.\n",
      "\n",
      "**3. Improved Gradient Flow During Training:**\n",
      "\n",
      "*   **Theory:** During training, the presence of intermediate reasoning steps in CoT examples can improve the flow of gradients through the model's network. This can lead to better learning and generalization.\n",
      "*   **Mechanism:** The intermediate steps provide more \"supervisory signals\" to the model, guiding it towards the correct solution. This can be particularly helpful for complex problems where the relationship between the input and output is not immediately obvious.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Reinforcement Learning:** Use reinforcement learning to train the model to generate CoT paths that lead to the correct answer. This can help the model learn to explore different reasoning strategies and find the most effective ones.\n",
      "    *   **Adversarial Training:** Train the model to be robust to adversarial examples that are designed to disrupt its reasoning process. This can improve the model's ability to generalize to unseen problems.\n",
      "\n",
      "**4. Alignment with Human-Interpretable Reasoning:**\n",
      "\n",
      "*   **Theory:** CoT's effectiveness stems from its alignment with human-understandable reasoning processes. By generating explicit reasoning steps, the model's thought process becomes more transparent and interpretable.\n",
      "*   **Mechanism:** This alignment can improve trust and acceptance of the model's outputs, particularly in high-stakes applications where explainability is crucial.\n",
      "*   **Implementation Variations:**\n",
      "    *   **Explanation Generation:** Train the model to generate explanations for its reasoning steps, providing further insights into its thought process.\n",
      "    *   **Interactive Reasoning:** Allow users to interact with the model during the CoT process, providing feedback and guidance to improve its reasoning.\n",
      "\n",
      "These theories provide a foundation for understanding the effectiveness of CoT prompting. Further research is needed to fully elucidate the underlying mechanisms and to develop more effective CoT techniques.\n",
      "</data>\n",
      "<actions>\n",
      "### **ACTION LOGS**\n",
      "| Job Title | Action Type | Description |\n",
      "| --- | --- | --- |\n",
      "| Research and summarize the fundamental principles and implementation of the basic Chain-of-Thought (CoT) prompting technique. | Addition | Added a section summarizing the basic principles of Chain-of-Thought prompting. |\n",
      "| Investigate and describe advanced CoT prompting variants, focusing on techniques that incorporate external knowledge or specialized reasoning strategies. Provide examples of each variant. | Addition | Added a section detailing advanced CoT variants like Knowledge-Augmented CoT, Graph CoT, and Decomposed CoT, including examples. |\n",
      "| Identify and describe application-specific CoT techniques tailored for particular tasks or domains, such as mathematical reasoning or commonsense reasoning. Provide the task or domain that each technique is designed for. | Addition | Added a section outlining application-specific CoT techniques, including Program-of-Thought (PoT) for mathematical reasoning and Knowledge-augmented CoT for commonsense reasoning. |\n",
      "| Explore and summarize the theoretical explanations for why CoT works. Identify if these explanations suggest different implementation methods or variations of CoT. | Addition | Added a section discussing the theoretical explanations behind CoT's effectiveness, such as mimicking human cognition and enhanced representation learning, and their corresponding implementation variations. |\n",
      "</actions>\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "for msg in research_state['current_messages']:\n",
    "    msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
