{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b9f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.cfg.precompiled import get_llm, get_checkpointer\n",
    "from fcgb.tools.spectools import PhantomResearcherSpecTool, JobHandlerSpecTool, JobHandler\n",
    "from fcgb.cfg.chat_inputs_spec import JobHanlderConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fab678",
   "metadata": {},
   "source": [
    "## Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab4fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_llm = get_llm(llm_model='fake')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66637a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=fake_llm, memory=memory)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfbceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_handler = JobHandlerSpecTool(\n",
    "    llm=fake_llm,\n",
    "    tool_containers=tool_containers,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce74a647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thread_id': 'ff74dc11cf3040219dd4b43bab2bcd40', 'output': 'Fake LLM response 3'}\n"
     ]
    }
   ],
   "source": [
    "outputs = job_handler.run(job_description='some job description')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68c1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_state = job_handler.get_state(thread_id=outputs['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ce20af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_description': 'some job description',\n",
       " 'turns': 3,\n",
       " 'messages': [SystemMessage(content='Your purpose is to conduct a single job that will be provided to you by the user.\\nYou are also equipped with a set of tools that you can use to complete the job.\\n\\nPut attention on the job description as well as output format if specified.\\nYou have maximum of 4 turns to call the tools and complete the job.\\nYou can call the same tool multiple times (even within single turn) with different parameters to solve the job.\\nIf you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.', additional_kwargs={}, response_metadata={}, id='eef432a9-385a-4725-8f5a-de0ce26a85cb'),\n",
       "  HumanMessage(content='Process the following job:\\n\\nsome job description\\n\\nBe aware of provided restrictions and output format.\\nStick to the job description and do not provide any additional information or context.\\nUse the motivation description for better understanding of the job.\\n\\nIn your final answer also write a title that summarizes the output.', additional_kwargs={}, response_metadata={}, id='e21c64ee-5526-48ff-9977-8b84cd84c7bc'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='4d4cb0e9-7917-47d2-91b0-709124256325', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string izlnp', 'motivation': 'Fake string zumdw', 'restrictions': 'Fake string poihz', 'output_format': 'Fake string nfdko'}, 'id': 'call_11d0fe0cf4094f2aa71143a206005b1f', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Fake LLM response 1', name='external_research', id='b18b43cc-62a3-47a4-b15b-cb0b2b35c666', tool_call_id='call_11d0fe0cf4094f2aa71143a206005b1f'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='405c5575-31fe-46a9-b4ac-c79d5785de2a', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string kklnp', 'motivation': 'Fake string jhhal', 'restrictions': 'Fake string fdpxk', 'output_format': 'Fake string srzto'}, 'id': 'call_d22331520b2546c9b981dc502da55027', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Fake LLM response 2', name='external_research', id='2eb98423-a98e-412f-bb21-03aae3c4cf77', tool_call_id='call_d22331520b2546c9b981dc502da55027'),\n",
       "  AIMessage(content='Fake LLM response 3', additional_kwargs={}, response_metadata={}, id='23030b99-e675-4916-ab08-c7c9f42db4b4')],\n",
       " 'tools_threads': ['419a5471359448548bfd77ead14e701c',\n",
       "  '9d26d1729aa244a189b88da4ba84ba07'],\n",
       " 'thread_id': 'ff74dc11cf3040219dd4b43bab2bcd40',\n",
       " 'output': 'Fake LLM response 3'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b59197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Your purpose is to conduct a single job that will be provided to you by the user.\n",
      "You are also equipped with a set of tools that you can use to complete the job.\n",
      "\n",
      "Put attention on the job description as well as output format if specified.\n",
      "You have maximum of 4 turns to call the tools and complete the job.\n",
      "You can call the same tool multiple times (even within single turn) with different parameters to solve the job.\n",
      "If you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Process the following job:\n",
      "\n",
      "some job description\n",
      "\n",
      "Be aware of provided restrictions and output format.\n",
      "Stick to the job description and do not provide any additional information or context.\n",
      "Use the motivation description for better understanding of the job.\n",
      "\n",
      "In your final answer also write a title that summarizes the output.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  external_research (call_11d0fe0cf4094f2aa71143a206005b1f)\n",
      " Call ID: call_11d0fe0cf4094f2aa71143a206005b1f\n",
      "  Args:\n",
      "    job: Fake string izlnp\n",
      "    motivation: Fake string zumdw\n",
      "    restrictions: Fake string poihz\n",
      "    output_format: Fake string nfdko\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: external_research\n",
      "\n",
      "Fake LLM response 1\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  external_research (call_d22331520b2546c9b981dc502da55027)\n",
      " Call ID: call_d22331520b2546c9b981dc502da55027\n",
      "  Args:\n",
      "    job: Fake string kklnp\n",
      "    motivation: Fake string jhhal\n",
      "    restrictions: Fake string fdpxk\n",
      "    output_format: Fake string srzto\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: external_research\n",
      "\n",
      "Fake LLM response 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 3\n"
     ]
    }
   ],
   "source": [
    "for msg in job_state['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38efa06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': 'Fake string lbpin', 'motivation': 'Fake string avehv', 'restrictions': 'Fake string nkazf', 'output_format': 'Fake string zhkkh', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='7e05c4d4-bdad-487b-a1c6-67939951bd12'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Fake string lbpin\\n\\nTo help you understand underlaying motivation of the job, here is the **motivation**: Fake string avehv\\nYour answer should be a detailed response that addresses the research job and its motivation. Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements and motivation.\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Fake string nkazf\\n\\nThere is also specified output format of your answer:\\n**output format**: Fake string zhkkh\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\", additional_kwargs={}, response_metadata={}, id='b380865b-a968-40e2-aef4-74a05ffc875c'), AIMessage(content='', additional_kwargs={}, response_metadata={}, id='0d58a599-50db-4cce-b6e6-75fbcd4b4cc0', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string zvqop', 'motivation': 'Fake string gtuth', 'restrictions': 'Fake string wrryp', 'output_format': 'Fake string pjywn'}, 'id': 'call_b4ea6d617e4f4b7780a65a4a01622d03', 'type': 'tool_call'}, {'name': 'external_research', 'args': {'job': 'Fake string xhtwz', 'motivation': 'Fake string yjwft', 'restrictions': 'Fake string ibetc', 'output_format': 'Fake string umgyx'}, 'id': 'call_6cd352d4c5fe420e92b359a6a792f071', 'type': 'tool_call'}])], 'thread_id': '704eb52d9ce04d328b2ad5ae6b2cda00', 'output': ''}\n",
      "--------------------------------------------------\n",
      "{'job': 'Fake string bdzcn', 'motivation': 'Fake string flbye', 'restrictions': 'Fake string lfeep', 'output_format': 'Fake string wmrpz', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='d8ccb3fe-86ab-49a6-909a-9cc0eea7ee04'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Fake string bdzcn\\n\\nTo help you understand underlaying motivation of the job, here is the **motivation**: Fake string flbye\\nYour answer should be a detailed response that addresses the research job and its motivation. Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements and motivation.\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Fake string lfeep\\n\\nThere is also specified output format of your answer:\\n**output format**: Fake string wmrpz\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\", additional_kwargs={}, response_metadata={}, id='3471622c-c7fa-485b-8267-9ed8107b2d90'), AIMessage(content='', additional_kwargs={}, response_metadata={}, id='de1ad738-9f08-48b1-aadf-13151c4b5357', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string pgtel', 'motivation': 'Fake string ygjri', 'restrictions': 'Fake string zsjqv', 'output_format': 'Fake string vkjeu'}, 'id': 'call_bc923c7c8d664a68a86329048fbafcfc', 'type': 'tool_call'}])], 'thread_id': 'ae9a94a23529445fbc81d26cdd4fd3bf', 'output': ''}\n",
      "--------------------------------------------------\n",
      "{'job': 'Fake string gopgh', 'motivation': 'Fake string wxjcy', 'restrictions': 'Fake string ntzcp', 'output_format': 'Fake string mpqvx', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='60e808bf-513e-42b2-8418-977db9849f68'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Fake string gopgh\\n\\nTo help you understand underlaying motivation of the job, here is the **motivation**: Fake string wxjcy\\nYour answer should be a detailed response that addresses the research job and its motivation. Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements and motivation.\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Fake string ntzcp\\n\\nThere is also specified output format of your answer:\\n**output format**: Fake string mpqvx\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\", additional_kwargs={}, response_metadata={}, id='250ba7d2-3954-4846-a2c9-69cb9b9d6a4b'), AIMessage(content='', additional_kwargs={}, response_metadata={}, id='8d719350-5e29-44f3-8d9b-8af3a68a0896', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string biygt', 'motivation': 'Fake string phdms', 'restrictions': 'Fake string toalo', 'output_format': 'Fake string osdrr'}, 'id': 'call_67716fd6805343ec864f057968c37940', 'type': 'tool_call'}])], 'thread_id': '78d3b0a16ebe4d6aabbc4e70b9b1740a', 'output': ''}\n",
      "--------------------------------------------------\n",
      "{'job': 'Fake string xpcuq', 'motivation': 'Fake string oicdw', 'restrictions': 'Fake string ukqth', 'output_format': 'Fake string sqdgd', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='90ffd3ca-d31f-4dca-ae89-ab60085ead04'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Fake string xpcuq\\n\\nTo help you understand underlaying motivation of the job, here is the **motivation**: Fake string oicdw\\nYour answer should be a detailed response that addresses the research job and its motivation. Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements and motivation.\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Fake string ukqth\\n\\nThere is also specified output format of your answer:\\n**output format**: Fake string sqdgd\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\", additional_kwargs={}, response_metadata={}, id='b1d50051-7592-4e1a-b6be-11c4acf9eddd'), AIMessage(content='', additional_kwargs={}, response_metadata={}, id='f7f2c4bb-cb07-4673-857a-09a3ff2f2b37', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string zhzwc', 'motivation': 'Fake string slgpf', 'restrictions': 'Fake string byyap', 'output_format': 'Fake string sbsof'}, 'id': 'call_d306fd03ca0440d5ac415e23e5819b82', 'type': 'tool_call'}, {'name': 'external_research', 'args': {'job': 'Fake string ghsnx', 'motivation': 'Fake string rwpzp', 'restrictions': 'Fake string mpqnv', 'output_format': 'Fake string zszxa'}, 'id': 'call_e8d8005423c94574bd7757946764939c', 'type': 'tool_call'}])], 'thread_id': 'e5320467fd854781a12ec4e0054c0672', 'output': ''}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for tool_thread in job_state['tools_threads']:\n",
    "    tool_state = job_handler.get_state(thread_id=tool_thread)\n",
    "    print(tool_state)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa71fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\n",
      "If you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\n",
      "\n",
      "You are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\n",
      "\n",
      "Avoid any unnecessary comments that are not a integral part of the answer.\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Provide an answer for a research job which is:\n",
      "**research job**: Fake string lbpin\n",
      "\n",
      "To help you understand underlaying motivation of the job, here is the **motivation**: Fake string avehv\n",
      "Your answer should be a detailed response that addresses the research job and its motivation. Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements and motivation.\n",
      "\n",
      "When writing your answer be aware of provided restrictions:\n",
      "**restrictions**: Fake string nkazf\n",
      "\n",
      "There is also specified output format of your answer:\n",
      "**output format**: Fake string zhkkh\n",
      "Your response should be structured according to the output format provided, ensuring clarity and organization in your answer.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  external_research (call_b4ea6d617e4f4b7780a65a4a01622d03)\n",
      " Call ID: call_b4ea6d617e4f4b7780a65a4a01622d03\n",
      "  Args:\n",
      "    job: Fake string zvqop\n",
      "    motivation: Fake string gtuth\n",
      "    restrictions: Fake string wrryp\n",
      "    output_format: Fake string pjywn\n",
      "  external_research (call_6cd352d4c5fe420e92b359a6a792f071)\n",
      " Call ID: call_6cd352d4c5fe420e92b359a6a792f071\n",
      "  Args:\n",
      "    job: Fake string xhtwz\n",
      "    motivation: Fake string yjwft\n",
      "    restrictions: Fake string ibetc\n",
      "    output_format: Fake string umgyx\n"
     ]
    }
   ],
   "source": [
    "tool_thread = job_state['tools_threads'][0]\n",
    "tool_state = job_handler.get_state(thread_id=tool_thread)\n",
    "for msg in tool_state['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79056a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tooled_llm = fake_llm.bind_tools([container.get_tool() for container in tool_containers], parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b08281f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tooled_llm().tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351a477",
   "metadata": {},
   "source": [
    "## Real LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ffd87ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'job_description': \"\"\"\n",
    "    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\n",
    "    motivation: To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\n",
    "    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\n",
    "    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02e1c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm(llm_model='google')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "15cde8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=llm, memory=memory)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f8e4fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_handler = JobHandler(\n",
    "    llm=llm,\n",
    "    tool_containers=tool_containers,\n",
    "    initial_messages_spec=JobHanlderConfig.initial_messages_spec,\n",
    "    internal_messages_spec=JobHanlderConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    init_values=JobHanlderConfig.init_values,\n",
    "    prompt_manager_spec=JobHanlderConfig.prompt_manager_spec,\n",
    "    global_inputs=JobHanlderConfig.global_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "444db580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thread_id': 'b7b5641305764ecfa36864f1f71366a4', 'output': 'Foundational Chain-of-Thought Prompting Variants:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let\\'s think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model\\'s pre-existing knowledge and reasoning abilities.\\n\\n*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\\n\\n*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\\n\\n*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.'}\n"
     ]
    }
   ],
   "source": [
    "outputs = job_handler.run(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3b0174e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_state = job_handler.get_state(thread_id=outputs['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a07ac45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_description': '\\n    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\\n    motivation: To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\\n    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\\n    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\\n    ',\n",
       " 'turns': 2,\n",
       " 'messages': [SystemMessage(content='Your purpose is to conduct a single job that will be provided to you by the user.\\nYou are also equipped with a set of tools that you can use to complete the job.\\n\\nPut attention on the job description as well as output format if specified.\\nYou have maximum of 4 turns to call the tools and complete the job.\\nYou can call the same tool multiple times (even within single turn) with different parameters to solve the job.\\nIf you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.', additional_kwargs={}, response_metadata={}, id='eb5b056f-b7d6-4827-9fff-660aac9395c5'),\n",
       "  HumanMessage(content='Process the following job:\\n\\n\\n    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\\n    motivation: To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\\n    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\\n    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\\n    \\n\\nBe aware of provided restrictions and output format.\\nStick to the job description and do not provide any additional information or context.\\nUse the motivation description for better understanding of the job.\\n\\nIn your final answer also write a title that summarizes the output.', additional_kwargs={}, response_metadata={}, id='4056fd49-dac8-4b64-af42-4205da130c7b'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'external_research', 'arguments': '{\"restrictions\": \"Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\", \"motivation\": \"To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\", \"job\": \"Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\", \"output_format\": \"A list of variant names, each with a brief (1-2 sentence) description of its core idea.\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--ddefd80e-a08d-4b56-9ad2-45ea944fcf69-0', tool_calls=[{'name': 'external_research', 'args': {'restrictions': 'Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.', 'motivation': 'To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task', 'job': 'Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants', 'output_format': 'A list of variant names, each with a brief (1-2 sentence) description of its core idea.'}, 'id': 'bad25cf5-c9c2-42c7-aaae-daf8cb9efa6d', 'type': 'tool_call'}], usage_metadata={'input_tokens': 394, 'output_tokens': 120, 'total_tokens': 514, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of relevant research papers:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let\\'s think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model\\'s pre-existing knowledge and reasoning abilities.\\n\\n*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\\n\\n*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\\n\\n*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.', name='external_research', id='5579ab8e-3cb3-42db-9344-7bdeedb622bd', tool_call_id='bad25cf5-c9c2-42c7-aaae-daf8cb9efa6d'),\n",
       "  AIMessage(content='Foundational Chain-of-Thought Prompting Variants:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let\\'s think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model\\'s pre-existing knowledge and reasoning abilities.\\n\\n*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\\n\\n*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\\n\\n*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--41b6aa7b-70d6-412f-b9cb-5d5b46617500-0', usage_metadata={'input_tokens': 859, 'output_tokens': 322, 'total_tokens': 1181, 'input_token_details': {'cache_read': 0}})],\n",
       " 'tools_threads': ['6f71c7a24dbc4579b8c5202d966d50ad'],\n",
       " 'thread_id': 'b7b5641305764ecfa36864f1f71366a4',\n",
       " 'output': 'Foundational Chain-of-Thought Prompting Variants:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let\\'s think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model\\'s pre-existing knowledge and reasoning abilities.\\n\\n*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\\n\\n*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\\n\\n*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f6c063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Your purpose is to conduct a single job that will be provided to you by the user.\n",
      "You are also equipped with a set of tools that you can use to complete the job.\n",
      "\n",
      "Put attention on the job description as well as output format if specified.\n",
      "You have maximum of 4 turns to call the tools and complete the job.\n",
      "You can call the same tool multiple times (even within single turn) with different parameters to solve the job.\n",
      "If you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Process the following job:\n",
      "\n",
      "\n",
      "    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\n",
      "    motivation: To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\n",
      "    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\n",
      "    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\n",
      "    \n",
      "\n",
      "Be aware of provided restrictions and output format.\n",
      "Stick to the job description and do not provide any additional information or context.\n",
      "Use the motivation description for better understanding of the job.\n",
      "\n",
      "In your final answer also write a title that summarizes the output.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  external_research (bad25cf5-c9c2-42c7-aaae-daf8cb9efa6d)\n",
      " Call ID: bad25cf5-c9c2-42c7-aaae-daf8cb9efa6d\n",
      "  Args:\n",
      "    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\n",
      "    motivation: To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\n",
      "    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\n",
      "    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: external_research\n",
      "\n",
      "Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of relevant research papers:\n",
      "\n",
      "*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\n",
      "\n",
      "*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let's think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model's pre-existing knowledge and reasoning abilities.\n",
      "\n",
      "*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\n",
      "\n",
      "*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\n",
      "\n",
      "*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Foundational Chain-of-Thought Prompting Variants:\n",
      "\n",
      "*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\n",
      "\n",
      "*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let's think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model's pre-existing knowledge and reasoning abilities.\n",
      "\n",
      "*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\n",
      "\n",
      "*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\n",
      "\n",
      "*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.\n"
     ]
    }
   ],
   "source": [
    "for msg in job_state['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd78568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': 'Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants', 'motivation': 'To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task', 'restrictions': 'Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.', 'output_format': 'A list of variant names, each with a brief (1-2 sentence) description of its core idea.', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='0b67b4be-de76-4560-9f82-30c4d5dadd7f'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\\n\\nTo help you understand underlaying motivation of the job, here is the **motivation**: To establish a baseline understanding of the well-known and widely adopted CoT variants, providing a strong foundation for the research task\\nYour answer should be a detailed response that addresses the research job and its motivation. Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements and motivation.\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\\n\\nThere is also specified output format of your answer:\\n**output format**: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\", additional_kwargs={}, response_metadata={}, id='0b356f50-265d-41cb-b05c-4b3d9ec91aab'), AIMessage(content='Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of relevant research papers:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let\\'s think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model\\'s pre-existing knowledge and reasoning abilities.\\n\\n*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\\n\\n*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\\n\\n*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--aab6b8a7-c643-40e8-8355-936b35dd3dc7-0', usage_metadata={'input_tokens': 401, 'output_tokens': 342, 'total_tokens': 743, 'input_token_details': {'cache_read': 0}})], 'thread_id': '6f71c7a24dbc4579b8c5202d966d50ad', 'output': 'Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of relevant research papers:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes in the prompt, guiding the language model to generate similar reasoning steps for new, unseen questions. The core idea is to elicit intermediate reasoning steps, leading to improved accuracy in complex reasoning tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** This variant leverages the \"Let\\'s think step by step\" prompt, or similar variations, to encourage the model to generate a chain of thought without requiring any explicit examples in the prompt. It relies on the model\\'s pre-existing knowledge and reasoning abilities.\\n\\n*   **Self-Consistency for Chain-of-Thought Prompting:** This approach involves generating multiple independent reasoning paths for a single question using CoT prompting. The final answer is then determined by aggregating the answers from these diverse reasoning paths, typically through a majority vote.\\n\\n*   **Least-to-Most Prompting:** This method breaks down a complex problem into a sequence of simpler subproblems that are solved in order, with the solutions to earlier subproblems used to inform the solutions to later ones. This encourages a structured, hierarchical reasoning process.\\n\\n*   **Tree-of-Thoughts (ToT):** ToT extends CoT by exploring multiple reasoning paths at each step and evaluating the intermediate thoughts to decide which path to explore further. This allows for backtracking and strategic exploration of the solution space, making it suitable for more complex tasks.'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for tool_thread in job_state['tools_threads']:\n",
    "    tool_state = job_handler.get_state(thread_id=tool_thread)\n",
    "    print(tool_state)\n",
    "    print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
