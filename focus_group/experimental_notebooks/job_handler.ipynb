{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b9f1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fcgb.cfg.precompiled import get_llm, get_checkpointer\n",
    "from fcgb.tools.spectools import PhantomResearcherSpecTool, JobHandlerSpecTool, JobHandler\n",
    "from fcgb.cfg.chat_inputs_spec import JobHanlderConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fab678",
   "metadata": {},
   "source": [
    "## Fake LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab4fc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_llm = get_llm(llm_model='fake')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66637a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=fake_llm, memory=memory)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfbceba",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_handler = JobHandlerSpecTool(\n",
    "    llm=fake_llm,\n",
    "    tool_containers=tool_containers,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce74a647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thread_id': '3e132091992a4d38af5ab16923d05857', 'output': 'Fake LLM response 2'}\n"
     ]
    }
   ],
   "source": [
    "outputs = job_handler.run(job_description='some job description')\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c68c1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_state = job_handler.get_state(thread_id=outputs['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88ce20af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_description': 'some job description',\n",
       " 'turns': 2,\n",
       " 'messages': [SystemMessage(content='Your purpose is to conduct a single job that will be provided to you by the user.\\nYou are also equipped with a set of tools that you can use to complete the job.\\n\\nPut attention on the job description as well as output format if specified.\\nYou have maximum of 4 turns to call the tools and complete the job.\\nYou can call the same tool multiple times (even within single turn) with different parameters to solve the job.\\nIf you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.', additional_kwargs={}, response_metadata={}, id='350022a1-bcaa-4180-a285-ebbcc6d2540d'),\n",
       "  HumanMessage(content='Process the following job:\\n\\nsome job description\\n\\nBe aware of provided restrictions and output format.\\nStick to the job description and do not provide any additional information or context.\\nIf there is any additional data provided use it for your answer. You can also pass it directly to tools if they allows it.\\n\\nIn your final answer also write a title that summarizes the output.', additional_kwargs={}, response_metadata={}, id='d827bfd5-ca3e-4905-b297-6266a0c219e1'),\n",
       "  AIMessage(content='', additional_kwargs={}, response_metadata={}, id='aeb0e0cd-ec99-4a47-b531-4b3643e3164a', tool_calls=[{'name': 'external_research', 'args': {'job': 'Fake string xcror', 'restrictions': 'Fake string fdppx', 'output_format': 'Fake string axtqd', 'data': 'Fake string rrsgl'}, 'id': 'call_8e9d08afcb004071b9fc34b038bb9679', 'type': 'tool_call'}, {'name': 'external_research', 'args': {'job': 'Fake string oidiq', 'restrictions': 'Fake string eiwkw', 'output_format': 'Fake string mkkgt', 'data': 'Fake string vuyjz'}, 'id': 'call_9bcc25d8c6154831be1770a03e13aa11', 'type': 'tool_call'}]),\n",
       "  ToolMessage(content='Fake LLM response 1', name='external_research', id='dfa2a2f1-83a1-4f4e-8cd8-636afc624f41', tool_call_id='call_8e9d08afcb004071b9fc34b038bb9679'),\n",
       "  ToolMessage(content='Fake LLM response 2', name='external_research', id='e51b2680-c4a6-45d3-8ca7-768c2a15d569', tool_call_id='call_9bcc25d8c6154831be1770a03e13aa11'),\n",
       "  AIMessage(content='Fake LLM response 2', additional_kwargs={}, response_metadata={}, id='6e5eff22-1112-4551-b981-7bce2402011e')],\n",
       " 'tools_threads': ['3ef7ac6888594237975f75f41140334f',\n",
       "  '68be493ec4354c1180d530ab913a47aa'],\n",
       " 'thread_id': '3e132091992a4d38af5ab16923d05857',\n",
       " 'output': 'Fake LLM response 2'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b59197d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Your purpose is to conduct a single job that will be provided to you by the user.\n",
      "You are also equipped with a set of tools that you can use to complete the job.\n",
      "\n",
      "Put attention on the job description as well as output format if specified.\n",
      "You have maximum of 4 turns to call the tools and complete the job.\n",
      "You can call the same tool multiple times (even within single turn) with different parameters to solve the job.\n",
      "If you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Process the following job:\n",
      "\n",
      "some job description\n",
      "\n",
      "Be aware of provided restrictions and output format.\n",
      "Stick to the job description and do not provide any additional information or context.\n",
      "If there is any additional data provided use it for your answer. You can also pass it directly to tools if they allows it.\n",
      "\n",
      "In your final answer also write a title that summarizes the output.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  external_research (call_8e9d08afcb004071b9fc34b038bb9679)\n",
      " Call ID: call_8e9d08afcb004071b9fc34b038bb9679\n",
      "  Args:\n",
      "    job: Fake string xcror\n",
      "    restrictions: Fake string fdppx\n",
      "    output_format: Fake string axtqd\n",
      "    data: Fake string rrsgl\n",
      "  external_research (call_9bcc25d8c6154831be1770a03e13aa11)\n",
      " Call ID: call_9bcc25d8c6154831be1770a03e13aa11\n",
      "  Args:\n",
      "    job: Fake string oidiq\n",
      "    restrictions: Fake string eiwkw\n",
      "    output_format: Fake string mkkgt\n",
      "    data: Fake string vuyjz\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: external_research\n",
      "\n",
      "Fake LLM response 1\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: external_research\n",
      "\n",
      "Fake LLM response 2\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 2\n"
     ]
    }
   ],
   "source": [
    "for msg in job_state['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38efa06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': 'Fake string xcror', 'restrictions': 'Fake string fdppx', 'output_format': 'Fake string axtqd', 'data': 'Fake string rrsgl', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='bbc613d3-6cfc-47a4-b3bb-12a7c611c064'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Fake string xcror\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Fake string fdppx\\n\\nThere is also specified output format of your answer:\\n**output format**: Fake string axtqd\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\\n\\nIn addition, you can use the following additional data, that the job may relate to, to support your answer:\\n**additional data**:\\nFake string rrsgl\\n\\n--------------------\\n\\nYour answer should be a detailed response that addresses the research job. \\nUse your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. \\nRemember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements.\\n\", additional_kwargs={}, response_metadata={}, id='a496ace4-e91a-4b0c-b87a-e542d4f9f30a'), AIMessage(content='Fake LLM response 1', additional_kwargs={}, response_metadata={}, id='d3b513fd-29a4-45c1-be92-0fe2d56ed540')], 'thread_id': '3ef7ac6888594237975f75f41140334f', 'output': 'Fake LLM response 1'}\n",
      "--------------------------------------------------\n",
      "{'job': 'Fake string oidiq', 'restrictions': 'Fake string eiwkw', 'output_format': 'Fake string mkkgt', 'data': 'Fake string vuyjz', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='923debb3-f644-4082-b6bf-b93b1e079de6'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Fake string oidiq\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Fake string eiwkw\\n\\nThere is also specified output format of your answer:\\n**output format**: Fake string mkkgt\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\\n\\nIn addition, you can use the following additional data, that the job may relate to, to support your answer:\\n**additional data**:\\nFake string vuyjz\\n\\n--------------------\\n\\nYour answer should be a detailed response that addresses the research job. \\nUse your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. \\nRemember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements.\\n\", additional_kwargs={}, response_metadata={}, id='ae453abb-06df-4100-b0dd-f7ee07c52327'), AIMessage(content='Fake LLM response 2', additional_kwargs={}, response_metadata={}, id='615bf013-6e40-4c51-b2bc-4833657d043d')], 'thread_id': '68be493ec4354c1180d530ab913a47aa', 'output': 'Fake LLM response 2'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for tool_thread in job_state['tools_threads']:\n",
    "    tool_state = job_handler.get_state(thread_id=tool_thread)\n",
    "    print(tool_state)\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa71fce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\n",
      "If you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\n",
      "\n",
      "You are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\n",
      "\n",
      "Avoid any unnecessary comments that are not a integral part of the answer.\n",
      "\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Provide an answer for a research job which is:\n",
      "**research job**: Fake string xcror\n",
      "\n",
      "When writing your answer be aware of provided restrictions:\n",
      "**restrictions**: Fake string fdppx\n",
      "\n",
      "There is also specified output format of your answer:\n",
      "**output format**: Fake string axtqd\n",
      "Your response should be structured according to the output format provided, ensuring clarity and organization in your answer.\n",
      "\n",
      "In addition, you can use the following additional data, that the job may relate to, to support your answer:\n",
      "**additional data**:\n",
      "Fake string rrsgl\n",
      "\n",
      "--------------------\n",
      "\n",
      "Your answer should be a detailed response that addresses the research job. \n",
      "Use your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. \n",
      "Remember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements.\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Fake LLM response 1\n"
     ]
    }
   ],
   "source": [
    "tool_thread = job_state['tools_threads'][0]\n",
    "tool_state = job_handler.get_state(thread_id=tool_thread)\n",
    "for msg in tool_state['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79056a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_tooled_llm = fake_llm.bind_tools([container.get_tool() for container in tool_containers], parallel_tool_calls=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b08281f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_tooled_llm().tool_calls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c351a477",
   "metadata": {},
   "source": [
    "## Real LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd87ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    'job_description': \"\"\"\n",
    "    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\n",
    "    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\n",
    "    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\n",
    "    \"\"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e1c8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = get_llm(llm_model='google')\n",
    "memory = get_checkpointer(checkpointer_mode='local', mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cde8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_containers = [\n",
    "    PhantomResearcherSpecTool(llm=llm, memory=memory)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8e4fe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_handler = JobHandler(\n",
    "    llm=llm,\n",
    "    tool_containers=tool_containers,\n",
    "    initial_messages_spec=JobHanlderConfig.initial_messages_spec,\n",
    "    internal_messages_spec=JobHanlderConfig.internal_messages_spec,\n",
    "    memory=memory,\n",
    "    init_values=JobHanlderConfig.init_values,\n",
    "    prompt_manager_spec=JobHanlderConfig.prompt_manager_spec,\n",
    "    global_inputs=JobHanlderConfig.global_inputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444db580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'thread_id': '5c97c752afcb4a2db15d68ada7e07d74', 'output': 'Foundational Chain-of-Thought Prompting Variants:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let\\'s think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\\n\\n*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.'}\n"
     ]
    }
   ],
   "source": [
    "outputs = job_handler.run(**inputs)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0174e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_state = job_handler.get_state(thread_id=outputs['thread_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a07ac45f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'job_description': '\\n    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\\n    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\\n    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\\n    ',\n",
       " 'turns': 2,\n",
       " 'messages': [SystemMessage(content='Your purpose is to conduct a single job that will be provided to you by the user.\\nYou are also equipped with a set of tools that you can use to complete the job.\\n\\nPut attention on the job description as well as output format if specified.\\nYou have maximum of 4 turns to call the tools and complete the job.\\nYou can call the same tool multiple times (even within single turn) with different parameters to solve the job.\\nIf you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.', additional_kwargs={}, response_metadata={}, id='fea94304-0b72-472b-aeca-07af82b01834'),\n",
       "  HumanMessage(content='Process the following job:\\n\\n\\n    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\\n    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\\n    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\\n    \\n\\nBe aware of provided restrictions and output format.\\nStick to the job description and do not provide any additional information or context.\\nIf there is any additional data provided use it for your answer. You can also pass it directly to tools if they allows it.\\n\\nIn your final answer also write a title that summarizes the output.', additional_kwargs={}, response_metadata={}, id='a11a98ee-164d-4429-998c-26ff101acd76'),\n",
       "  AIMessage(content='', additional_kwargs={'function_call': {'name': 'external_research', 'arguments': '{\"restrictions\": \"Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\", \"job\": \"Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\", \"data\": \"\", \"output_format\": \"A list of variant names, each with a brief (1-2 sentence) description of its core idea.\"}'}}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--35320f34-edac-4d39-b6d7-fb9f7aa527b6-0', tool_calls=[{'name': 'external_research', 'args': {'restrictions': 'Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.', 'job': 'Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants', 'data': '', 'output_format': 'A list of variant names, each with a brief (1-2 sentence) description of its core idea.'}, 'id': '20d816ae-f405-4f62-b3f7-4521caeea1e4', 'type': 'tool_call'}], usage_metadata={'input_tokens': 379, 'output_tokens': 95, 'total_tokens': 474, 'input_token_details': {'cache_read': 0}}),\n",
       "  ToolMessage(content='Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of research papers:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let\\'s think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\\n\\n*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.', name='external_research', id='c91ba7bc-6556-4b04-b108-ce862cc0eb7a', tool_call_id='20d816ae-f405-4f62-b3f7-4521caeea1e4'),\n",
       "  AIMessage(content='Foundational Chain-of-Thought Prompting Variants:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let\\'s think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\\n\\n*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--832d7139-db0c-4d39-804c-d5bcff92305c-0', usage_metadata={'input_tokens': 692, 'output_tokens': 196, 'total_tokens': 888, 'input_token_details': {'cache_read': 0}})],\n",
       " 'tools_threads': ['76f7d9efeeed4becab624b796de33510'],\n",
       " 'thread_id': '5c97c752afcb4a2db15d68ada7e07d74',\n",
       " 'output': 'Foundational Chain-of-Thought Prompting Variants:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let\\'s think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\\n\\n*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6c063c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m System Message \u001b[0m================================\n",
      "\n",
      "Your purpose is to conduct a single job that will be provided to you by the user.\n",
      "You are also equipped with a set of tools that you can use to complete the job.\n",
      "\n",
      "Put attention on the job description as well as output format if specified.\n",
      "You have maximum of 4 turns to call the tools and complete the job.\n",
      "You can call the same tool multiple times (even within single turn) with different parameters to solve the job.\n",
      "If you will exceed the maximum number of turns, tools will be disabled and you will have to answer with the information you have at that moment.\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Process the following job:\n",
      "\n",
      "\n",
      "    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\n",
      "    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\n",
      "    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\n",
      "    \n",
      "\n",
      "Be aware of provided restrictions and output format.\n",
      "Stick to the job description and do not provide any additional information or context.\n",
      "If there is any additional data provided use it for your answer. You can also pass it directly to tools if they allows it.\n",
      "\n",
      "In your final answer also write a title that summarizes the output.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  external_research (20d816ae-f405-4f62-b3f7-4521caeea1e4)\n",
      " Call ID: 20d816ae-f405-4f62-b3f7-4521caeea1e4\n",
      "  Args:\n",
      "    restrictions: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\n",
      "    job: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\n",
      "    data: \n",
      "    output_format: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: external_research\n",
      "\n",
      "Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of research papers:\n",
      "\n",
      "*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\n",
      "\n",
      "*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let's think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\n",
      "\n",
      "*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Foundational Chain-of-Thought Prompting Variants:\n",
      "\n",
      "*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\n",
      "\n",
      "*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let's think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\n",
      "\n",
      "*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.\n"
     ]
    }
   ],
   "source": [
    "for msg in job_state['messages']:\n",
    "    msg.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd78568e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'job': 'Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants', 'restrictions': 'Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.', 'output_format': 'A list of variant names, each with a brief (1-2 sentence) description of its core idea.', 'data': '', 'messages': [SystemMessage(content='Your purpose is to mimic a research tool that uses external resources like web pages, research papers, wikipedia etc. to answer questions and provide information.\\nIf you will be asked to use those external resources use your best knowledge to provide the most accurate and relevant information whitout using any external resources but within your answer you can pretend that you are using them.\\n\\nYou are a part of a testing tool so accuracy is not that important but try to be as accurate as possible.\\n\\nAvoid any unnecessary comments that are not a integral part of the answer.\\n\\n', additional_kwargs={}, response_metadata={}, id='207641f6-e034-4b8d-bb7b-9b48e1521ea2'), HumanMessage(content=\"Provide an answer for a research job which is:\\n**research job**: Explore research papers to identify and list the most commonly cited and foundational Chain-of-Thought prompting variants\\n\\nWhen writing your answer be aware of provided restrictions:\\n**restrictions**: Focus on variants that are widely recognized and have substantial documentation or research backing them. Avoid niche or experimental variants that lack sufficient information. Also do not include fine-tuning methods or techniques that are not directly related to prompting.\\n\\nThere is also specified output format of your answer:\\n**output format**: A list of variant names, each with a brief (1-2 sentence) description of its core idea.\\nYour response should be structured according to the output format provided, ensuring clarity and organization in your answer.\\n\\nIn addition, you can use the following additional data, that the job may relate to, to support your answer:\\n**additional data**:\\n\\n\\n--------------------\\n\\nYour answer should be a detailed response that addresses the research job. \\nUse your best knowledge to provide relevant information, and if necessary, you can pretend to use external resources like web pages, research papers, or Wikipedia to support your answer. \\nRemember, accuracy is important, but since this is a testing tool, it doesn't have to be perfect. Focus on delivering a comprehensive and informative response that aligns with the research job's requirements.\\n\", additional_kwargs={}, response_metadata={}, id='e501aa7e-c952-49c3-9a45-8de36d69809f'), AIMessage(content='Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of research papers:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let\\'s think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\\n\\n*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': []}, id='run--4c787220-8140-468a-81ed-b7ce505895e2-0', usage_metadata={'input_tokens': 390, 'output_tokens': 215, 'total_tokens': 605, 'input_token_details': {'cache_read': 0}})], 'thread_id': '76f7d9efeeed4becab624b796de33510', 'output': 'Here are some of the most commonly cited and foundational Chain-of-Thought (CoT) prompting variants, based on a review of research papers:\\n\\n*   **Standard Chain-of-Thought Prompting:** This involves providing a few example questions along with their step-by-step reasoning processes to guide the model in generating coherent and logical explanations for new, unseen questions. The core idea is to elicit reasoning traces from the model, improving its ability to solve complex tasks.\\n\\n*   **Zero-Shot Chain-of-Thought Prompting:** In this variant, instead of providing examples, the prompt simply includes the phrase \"Let\\'s think step by step.\" This surprisingly effective technique encourages the model to generate a chain of reasoning without any explicit demonstrations.\\n\\n*   **Self-Consistency with Chain-of-Thought Prompting:** This approach generates multiple independent reasoning paths for a single question using CoT prompting. The final answer is then selected by aggregating the answers from these different reasoning chains, typically through a majority voting scheme, to improve robustness and accuracy.'}\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for tool_thread in job_state['tools_threads']:\n",
    "    tool_state = job_handler.get_state(thread_id=tool_thread)\n",
    "    print(tool_state)\n",
    "    print('-'*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lang_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
